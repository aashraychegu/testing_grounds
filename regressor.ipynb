{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['BAM:0136', 'R04', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0037', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0027', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0036', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0019', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0085', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0076', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0084', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0100', 'R29', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['THC:0084', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0087', 'R06', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0072', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0014', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0057', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0057', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0097', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0123', 'R05', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0141', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0035', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0143', 'R01', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0095', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0061', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0147', 'R02', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0018', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0117', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0124', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0031', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0072', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0048', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0021', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0095', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0130', 'R04', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0147', 'R04', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['THC:0083', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0058', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0001', 'R02', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['BAM:0100', 'R03', 'rh_22', 'Rh_l2_m2_r00800.txt', 0], ['BAM:0129', 'R03', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0145', 'R04', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0085', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0052', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0068', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0090', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0064', 'R04', 'rh_22', 'Rh_l2_m2_r01300.txt', 0], ['THC:0085', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0066', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0062', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0090', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0044', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0130', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0087', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0015', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0045', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0138', 'R03', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['THC:0001', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0089', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0039', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0114', 'R04', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0079', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0137', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0097', 'R10', 'rh_22', 'Rh_l2_m2_r01100.txt', 0], ['THC:0093', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0070', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0063', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0026', 'R05', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0010', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0125', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0117', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0086', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0060', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0100', 'R23', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0098', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0004', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0011', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0089', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0093', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0052', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0056', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0021', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0104', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0007', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0122', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0100', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0099', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0066', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0024', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0017', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0006', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0030', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0131', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0044', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0127', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0007', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0111', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0136', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0024', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0082', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0034', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0022', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0106', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0123', 'R06', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0006', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0028', 'R03', 'rh_22', 'Rh_l2_m2_r00600.txt', 0], ['BAM:0084', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0056', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0113', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0034', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0068', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0026', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0049', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0142', 'R02', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0121', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0087', 'R05', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0026', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0043', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0101', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0081', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0093', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0126', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0127', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0046', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0074', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0104', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0014', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0068', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0010', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0029', 'R02', 'rh_22', 'Rh_l2_m2_rInf.txt', 0], ['BAM:0142', 'R03', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0051', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0099', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0039', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0002', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0111', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0066', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0036', 'R04', 'rh_22', 'Rh_l2_m2_rInf.txt', 0], ['THC:0008', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0047', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0042', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0035', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0137', 'R05', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0142', 'R01', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['THC:0101', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0054', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0077', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0092', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0018', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0125', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R16', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0078', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0100', 'R05', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0007', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0077', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0142', 'R04', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['THC:0022', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0104', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0136', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0050', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0030', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0037', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0099', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0052', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0059', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0110', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0061', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0068', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0146', 'R02', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0137', 'R04', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0062', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0101', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0005', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0113', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0105', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0003', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0038', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0135', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0102', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0097', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0137', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0076', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0043', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0068', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0070', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0016', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R09', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0046', 'R02', 'rh_22', 'Rh_l2_m2_r01200.txt', 0], ['BAM:0052', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0036', 'R02', 'rh_22', 'Rh_l2_m2_rInf.txt', 0], ['BAM:0030', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0057', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0103', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R08', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0025', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0032', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0096', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0064', 'R03', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['THC:0104', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0132', 'R05', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['BAM:0134', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0100', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0107', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0091', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0108', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0003', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0048', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0033', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0026', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0097', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R14', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0003', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0018', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0112', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0069', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0117', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0146', 'R01', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['THC:0052', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0070', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0029', 'R04', 'rh_22', 'Rh_l2_m2_rInf.txt', 0], ['BAM:0143', 'R02', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['THC:0054', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0004', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0097', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0005', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0089', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0017', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0054', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0124', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0101', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0096', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0017', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0029', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0106', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0061', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0097', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0097', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0082', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0103', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0029', 'R03', 'rh_22', 'Rh_l2_m2_rInf.txt', 0], ['BAM:0011', 'R02', 'rh_22', 'Rh_l2_m2_r00800.txt', 0], ['THC:0041', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0036', 'R01', 'rh_22', 'Rh_l2_m2_rInf.txt', 0], ['BAM:0080', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0065', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R25', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0069', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0081', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0035', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0107', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0065', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0065', 'R09', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0070', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0131', 'R04', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0001', 'R03', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['BAM:0019', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0062', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0001', 'R04', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0106', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0043', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0119', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0028', 'R01', 'rh_22', 'Rh_l2_m2_r00600.txt', 0], ['BAM:0087', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R11', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0130', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0103', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0056', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0088', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0071', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0081', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0061', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R26', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0113', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0042', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0037', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0020', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0045', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0094', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0136', 'R05', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0100', 'R15', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0103', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0107', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0130', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0140', 'R03', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['THC:0027', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0107', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0100', 'R24', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0128', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0097', 'R09', 'rh_22', 'Rh_l2_m2_r01100.txt', 0], ['BAM:0039', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0105', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0087', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0099', 'R04', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0021', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0091', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0046', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0002', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0060', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0055', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0072', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0067', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0133', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0013', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0089', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0139', 'R03', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['THC:0011', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0144', 'R03', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0090', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0044', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0108', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0065', 'R05', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0052', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0063', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0123', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0045', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0095', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0004', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0050', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0059', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0044', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0088', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0055', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0095', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0109', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0013', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0020', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0047', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0037', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0087', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0094', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0141', 'R04', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0037', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0140', 'R02', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['BAM:0091', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R07', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0038', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0144', 'R04', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0136', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0089', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0019', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0050', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0110', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0109', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0120', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0056', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0123', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0032', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0039', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0107', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0076', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0067', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0040', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0087', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0071', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0025', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0091', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0132', 'R08', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['BAM:0100', 'R31', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0129', 'R02', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['THC:0019', 'R04', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0073', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0012', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0035', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0039', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0005', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0065', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0088', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0090', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0132', 'R02', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['BAM:0131', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0014', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0062', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0092', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0019', 'R05', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0048', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0120', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0058', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0041', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0144', 'R02', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['THC:0010', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0066', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0110', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0049', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0058', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0134', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0094', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R12', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0104', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0100', 'R28', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['THC:0088', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0093', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0132', 'R04', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['BAM:0002', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0054', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0040', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0075', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0120', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0038', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0026', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0132', 'R06', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['BAM:0089', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R06', 'rh_22', 'Rh_l2_m2_r00800.txt', 0], ['BAM:0009', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0064', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0065', 'R08', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0064', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0058', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0071', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0039', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0091', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0038', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0069', 'R01', 'rh_22', 'Rh_l2_m2_r00500.txt', 0], ['BAM:0046', 'R01', 'rh_22', 'Rh_l2_m2_r01200.txt', 0], ['THC:0063', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0080', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0037', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0088', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0022', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0139', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0114', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0086', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0041', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0022', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0008', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0078', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0139', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0055', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0019', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0074', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0037', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0047', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0060', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0116', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0068', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0023', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0114', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0081', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0049', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0132', 'R01', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['BAM:0070', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0059', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0012', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0030', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0131', 'R05', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0071', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0047', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0129', 'R01', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0057', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0009', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0123', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0090', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0051', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0078', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0031', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0095', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0028', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0042', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0140', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0006', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0053', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0036', 'R03', 'rh_22', 'Rh_l2_m2_rInf.txt', 0], ['BAM:0008', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0108', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0091', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0137', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0015', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0051', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0100', 'R10', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0123', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R13', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0083', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0102', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0078', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0146', 'R03', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0066', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0145', 'R03', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0100', 'R17', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0129', 'R04', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0060', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0141', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0092', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0065', 'R06', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0097', 'R08', 'rh_22', 'Rh_l2_m2_r01100.txt', 0], ['THC:0075', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0104', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0126', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0135', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0045', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0028', 'R02', 'rh_22', 'Rh_l2_m2_r00600.txt', 0], ['BAM:0118', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0131', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0053', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0050', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0062', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0003', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0094', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0144', 'R01', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0065', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R30', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['THC:0042', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0015', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0147', 'R01', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0062', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R18', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0075', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0100', 'R21', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0024', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0109', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0097', 'R05', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0100', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0082', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0100', 'R27', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0088', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0019', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0019', 'R06', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0147', 'R03', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['THC:0054', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0049', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0022', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R19', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0102', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0100', 'R01', 'rh_22', 'Rh_l2_m2_r00600.txt', 0], ['BAM:0100', 'R20', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0088', 'R03', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0132', 'R07', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['BAM:0100', 'R22', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0081', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0067', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0064', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0098', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0033', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0094', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0126', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0097', 'R07', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0097', 'R06', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['BAM:0016', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0043', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0115', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0006', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0124', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0039', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0141', 'R02', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0072', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0132', 'R03', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['BAM:0095', 'R05', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0055', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0053', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0065', 'R04', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0073', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0096', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0012', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0135', 'R03', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0111', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0105', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0101', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0036', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0074', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0100', 'R04', 'rh_22', 'Rh_l2_m2_r00450.txt', 0], ['BAM:0127', 'R03', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0099', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0138', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0063', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0051', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0130', 'R05', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['THC:0052', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0073', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0016', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['THC:0086', 'R02', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0064', 'R01', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['BAM:0023', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0065', 'R07', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0013', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0020', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0001', 'R01', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['BAM:0145', 'R02', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['BAM:0145', 'R01', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0], ['THC:0016', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0128', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0073', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0013', 'R01', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0133', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0079', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0026', 'R04', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0064', 'R02', 'rh_22', 'Rh_l2_m2_r01400.txt', 0], ['BAM:0138', 'R02', 'rh_22', 'Rh_l2_m2_r00850.txt', 0], ['THC:0059', 'R01', 'rh_22', 'Rh_l2_m2_r00400.txt', 0], ['BAM:0048', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0114', 'R01', 'rh_22', 'Rh_l2_m2_r00900.txt', 0], ['BAM:0035', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['BAM:0043', 'R02', 'rh_22', 'Rh_l2_m2_r01000.txt', 0], ['THC:0029', 'R01', 'rh_22', 'Rh_l2_m2_rInf.txt', 0], ['BAM:0099', 'R01', 'rh_22', 'Rh_l2_m2_r00650.txt', 0], ['BAM:0146', 'R04', 'rh_22', 'Rh_l2_mm2_r01400.txt', 0]]\n"
     ]
    }
   ],
   "source": [
    "from CoRe_Dataloader_From_Files_With_OvGN import (\n",
    "    get_new_train_validation_test_datasets,\n",
    "    get_new_train_validation_test_dataloaders\n",
    ")\n",
    "from CoRe_Dataloader_ECSG import dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "import torchinfo\n",
    "import time\n",
    "import numpy as np\n",
    "import wandb\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as metrics\n",
    "import pandas as pd\n",
    "\n",
    "mae = metrics.MeanAbsoluteError()\n",
    "mse = metrics.MeanSquaredError()\n",
    "combined = metrics.MetricCollection(\n",
    "    [mae, mse, metrics.MeanAbsolutePercentageError(), metrics.MeanSquaredLogError()]\n",
    ")\n",
    "\n",
    "\n",
    "def get_df_from_rdict(rdict):\n",
    "    return pd.DataFrame(pd.Series(rdict).map(lambda x: x.cpu().item())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vit\n",
    "# import vit_pytorch\n",
    "from vit_pytorch import vit_for_small_dataset as vit_sd\n",
    "from vit_pytorch import vit as simple_vit\n",
    "from vit_pytorch.deepvit import DeepViT\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    # return simple_vit.ViT(image_size=400,\n",
    "    #                patch_size=20,\n",
    "    #                num_classes=19,\n",
    "    #                dim=int(1024/2),\n",
    "    #                depth=2,\n",
    "    #                heads=8,\n",
    "    #                mlp_dim=int(2048/2),\n",
    "    #                channels=1).to(\"cuda:0\")\n",
    "    # return vit_sd.ViT(image_size=400,\n",
    "    #                patch_size=20,\n",
    "    #                num_classes=19,\n",
    "    #                dim=1024,\n",
    "    #                depth=4,\n",
    "    #                heads=16,\n",
    "    #                mlp_dim=int(2048/2),\n",
    "    #                dropout = 0.1,\n",
    "    #                emb_dropout = 0,\n",
    "    #                channels=1).to(\"cuda:0\")\n",
    "    return DeepViT(\n",
    "        image_size=400,\n",
    "        patch_size=20,\n",
    "        num_classes=2,\n",
    "        dim=1024,\n",
    "        depth=4,\n",
    "        heads=16,\n",
    "        mlp_dim=int(2048 / 2),\n",
    "        dropout=0.1,\n",
    "        emb_dropout=0.1,\n",
    "        channels=1,\n",
    "    ).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumstring = \" \"\n",
    "def calc_metrics(model: torch.nn.Module, dl: DataLoader):\n",
    "    model.eval()\n",
    "    raw_output = []\n",
    "    parameters = []\n",
    "    with torch.no_grad():\n",
    "        for batch, (sg, params) in enumerate(dl):\n",
    "            sg = sg.to(\"cuda:0\").float()\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "\n",
    "            params = params[:, 1:3].to(\"cuda:0\")\n",
    "            raw_output.append(model(sg).detach().cpu())\n",
    "            parameters.append(params.cpu())\n",
    "            print(f\"{batch+1} / {len(dl)} { dumstring  * 20 }\", end=\"\\r\")\n",
    "    model.train()\n",
    "    output = torch.vstack(raw_output)\n",
    "    parameters = torch.concat(parameters,dim = 0)\n",
    "    return combined(output.cpu(), parameters.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507990 length of original set\n",
      "length of testval set 50800\n",
      "length of train set 457190\n",
      "length of test set 50799\n",
      "length of valid set 1\n",
      "50799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashr\\AppData\\Local\\Temp\\ipykernel_15588\\3674700284.py:5: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with autograd.detect_anomaly(check_nan=True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(-0.0116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.3699, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:197: UserWarning: Error detected in AddmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 724, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 600, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1896, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 512, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 501, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 408, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 731, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 417, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Local\\Temp\\ipykernel_15588\\3674700284.py\", line 7, in <module>\n",
      "    out = torch.mean(test_model(sg.to(\"cuda:0\").float().view(1,1,400,400)))\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1480, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\vit_pytorch\\deepvit.py\", line 141, in forward\n",
      "    return self.mlp_head(x)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1480, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\container.py\", line 204, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1480, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      " (Triggered internally at ..\\torch\\csrc\\autograd\\python_anomaly_mode.cpp:119.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Function 'AddmmBackward0' returned nan values in its 2th output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m batch, (sg,params) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(testdl):\n\u001b[0;32m      7\u001b[0m     out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(test_model(sg\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m400\u001b[39m,\u001b[39m400\u001b[39m)))\n\u001b[1;32m----> 8\u001b[0m     out\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(out)    \n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:484\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    476\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    477\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    483\u001b[0m     )\n\u001b[1;32m--> 484\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    485\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    486\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Function 'AddmmBackward0' returned nan values in its 2th output."
     ]
    }
   ],
   "source": [
    "test_model = init_model()\n",
    "_,_,testds = get_new_train_validation_test_datasets(0.1,0.000001)\n",
    "testdl = DataLoader(testds, batch_size=1, shuffle=True)\n",
    "print(len(testdl))\n",
    "with autograd.detect_anomaly(check_nan=True):\n",
    "    for batch, (sg,params) in enumerate(testdl):\n",
    "        out = torch.mean(test_model(sg.to(\"cuda:0\").float().view(1,1,400,400)))\n",
    "        out.backward()\n",
    "        print(out)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(testds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "startlr = 3e-5\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=startlr)\n",
    "optimizer1 = optim.NAdam(params=model.parameters(), lr=startlr)\n",
    "step_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[1, 2, 3, 4], gamma=0.5\n",
    ")\n",
    "# at the end of 600 epochs, the learning rate is 0.000,002,62\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
    "scheduler_pl = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer, mode=\"max\", factor=0.7, patience=35, verbose=True\n",
    ")\n",
    "l1 = nn.L1Loss(reduction=\"sum\")\n",
    "l2 = nn.MSELoss(reduction=\"sum\")\n",
    "lossfn = lambda x, y: l1(x, y) + l2(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds(s):\n",
    "    return f\"{s//3600}H:{(s%3600)//60}M:{round(s%60,3)}S\"\n",
    "\n",
    "\n",
    "def ismult(n, div):\n",
    "    return bool(1 >> (n % div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(best_model, config, m1, m2, m1name=\"l1\", m2name=\"l2\"):\n",
    "    try:\n",
    "        torch.save(\n",
    "            best_model,\n",
    "            f\"./saved_models/ViT/WithNoise/best_model_state_dict_ViT_regressor_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__{m1name}_{m1}__{m2name}_{m2}.pt\",\n",
    "        )\n",
    "        print(\"\\nSAVING MODEL\")\n",
    "    except:\n",
    "        wandb.alert(level=\"warning\", title=\"OUT OF MEMORY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(config, train_dl, test_dl, adam=True, nadam=False):\n",
    "    min_mae, min_mse = float(\"inf\"), float(\"inf\")\n",
    "    ldl = len(train_dl)\n",
    "    results = pd.DataFrame()\n",
    "    best_model = OrderedDict()\n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        print(\"Pre-Evaluation Finished; Starting Training\")\n",
    "        etime = time.time()\n",
    "        for batch, (sg, params) in enumerate(train_dl):\n",
    "            stime = time.time()\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.to(\"cuda:0\").to(torch.float).view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "            params = params[:, 1:3].to(\"cuda:0\").to(torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sg)\n",
    "            loss = lossfn(outputs, params)\n",
    "            loss.backward()\n",
    "            optimizer.step() if adam else None\n",
    "            optimizer1.step() if nadam else None\n",
    "            #\n",
    "            torch.cuda.empty_cache()\n",
    "            #\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"loss\": loss.item(),\n",
    "                    \"batch_mae\": mae(outputs.to(\"cpu\"), params.to(\"cpu\")),\n",
    "                    \"batch_mse\": mse(outputs.to(\"cpu\"), params.to(\"cpu\")),\n",
    "                    \"lr\": scheduler.get_last_lr()[0],\n",
    "                    \"epoch\": epoch,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"{epoch:5}/{config.epochs:5} // {batch:5}/{ldl:5} | Loss: {loss.item():2.4},batch_mae:{mae(outputs.to('cpu'),params.to('cpu')):3.4}, lr:{scheduler.get_last_lr()[0]:1.5}, Time per Batch: {time.time()-stime:.3} seconds, Accumulated Time {to_seconds(round(time.time()-etime,3))}    \",\n",
    "                end=\"\\r\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "            if (batch - 1) % 5000 == 0:\n",
    "                epoch_results = calc_metrics(model, test_dl)\n",
    "                results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "                min_mae = min(results[\"MeanAbsoluteError\"])\n",
    "                min_mse = min(results[\"MeanSquaredError\"])\n",
    "                #\n",
    "                if epoch_results[\"MeanAbsoluteError\"] == min_mae:\n",
    "                    best_model = model.state_dict()\n",
    "                    save_model(\n",
    "                        best_model,\n",
    "                        config,\n",
    "                        list(epoch_results.values())[0],\n",
    "                        list(epoch_results.values())[1],\n",
    "                    )\n",
    "\n",
    "                wandb.log(\n",
    "                    {\"epoch\": epoch, \"lr\": scheduler.get_last_lr()[0]}\n",
    "                    | epoch_results\n",
    "                    | {\"MinimumMAE\": min_mae, \"MinimumMSE\": min_mse}\n",
    "                    | {\"EpochTime\": time.time() - etime}\n",
    "                )\n",
    "        #\n",
    "        epoch_results = calc_metrics(model, test_dl)\n",
    "        results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "        #\n",
    "        min_mae = min(results[\"MeanAbsoluteError\"])\n",
    "        min_mse = min(results[\"MeanSquaredError\"])\n",
    "        #\n",
    "        scheduler.step()\n",
    "        step_scheduler.step()\n",
    "        scheduler_pl.step(min_mae)\n",
    "\n",
    "        if epoch_results[\"MeanAbsoluteError\"] == min_mae:\n",
    "            best_model = model.state_dict()\n",
    "            save_model(\n",
    "                best_model,\n",
    "                config,\n",
    "                list(epoch_results.values())[0],\n",
    "                list(epoch_results.values())[1],\n",
    "            )\n",
    "        #\n",
    "\n",
    "        wandb.log(\n",
    "            {\"epoch\": epoch, \"lr\": scheduler.get_last_lr()[0]}\n",
    "            | epoch_results\n",
    "            | {\"MinimumMAE\": min_mae, \"MinimumMSE\": min_mse}\n",
    "            | {\"EpochTime\": time.time() - etime}\n",
    "        )\n",
    "\n",
    "    epoch_results = calc_metrics(model, test_dl)\n",
    "    results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "    return min_mae, min_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for training\n",
    "results = []\n",
    "trials = 1\n",
    "for i in range(trials):\n",
    "    wandb.init(\n",
    "        project=\"ViT-Regressor-With-Noise\",\n",
    "    )\n",
    "    config = wandb.config\n",
    "    config.run_name = wandb.run._run_id\n",
    "    config = wandb.config\n",
    "    config.epochs = 3\n",
    "    config.inx = 400\n",
    "    config.iny = 400\n",
    "    config.lr = startlr\n",
    "    config.trial = i + 1\n",
    "    config.total_trials = trials\n",
    "    config.best_model = OrderedDict()\n",
    "    config.start_time = datetime.datetime.now().isoformat()\n",
    "    config.savename = f\"best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__acc_max_acc__auc_auc.pt\"\n",
    "    train_dl, valid_dl, test_dl = get_new_train_validation_train_dataloaders()\n",
    "    train_eval_model(wandb.config, train_dl, valid_dl, nadam=True)\n",
    "    results.append(calc_metrics(model, test_dl))  # type: ignore\n",
    "    if i != (trials - 1):\n",
    "        model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    f\"./saved_models/ViT/WithNoise/best_model_state_dict_ViT_regressor_11_07_2023\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldl = test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "totout = []\n",
    "with torch.no_grad():\n",
    "    for batch, (sg, params) in enumerate(evaldl):\n",
    "        sg = sg.to(\"cuda:0\").to(torch.float)\n",
    "        sgsh = sg.shape\n",
    "        sg = sg.view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "        modelout = (model(sg).detach().cpu())\n",
    "        params = params.to(\"cpu\").to(torch.float)\n",
    "        comb = torch.concat([modelout, params], dim=1)\n",
    "        print(comb[1],modelout[1],params[1])\n",
    "        print(batch, \"finished\")\n",
    "        totout.append(comb)\n",
    "model.train()\n",
    "print(len(totout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = torch.cat(totout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_params.numpy())\n",
    "df = df.rename(columns={0: \"PM1\", 1: \"PM2\", 2: \"EOS\", 3: \"M1\", 4: \"M2\", 5: \"SNR\",})\n",
    "df[\"combined\"] = df[\"M1\"] + df[\"M2\"]\n",
    "df[\"DiffM1\"] = abs(df[\"M1\"] - df[\"PM1\"])\n",
    "df[\"DiffM2\"] = abs(df[\"M2\"] - df[\"PM2\"])\n",
    "df[\"totDiff\"] = df[\"DiffM1\"] + df[\"DiffM2\"]\n",
    "df[\"avgDiff\"] = df[\"totDiff\"] / 2\n",
    "df.to_csv(\"results.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffhist = sns.histplot(df[\"avgDiff\"])\n",
    "diffhist.set(title = \"Difference between predicted and actual masses\", xlabel = \"Difference (solar masses)\", ylabel = \"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = df[\"combined\"], y = df[\"avgDiff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df[\"M1\"], y=df[\"DiffM1\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df[\"M2\"], y=df[\"DiffM2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temparray = pd.melt(\n",
    "    df[[\"SNR\", \"DiffM2\", \"DiffM1\", \"avgDiff\"]].rename(columns = {\"SNR\": \"Signal to Noise Ratio\", \"DiffM2\": \"Difference between predicted and actual for Mass 2\", \"DiffM1\": \"Difference between predicted and actual for Mass 1\", \"avgDiff\": \"Average Difference between predicted and actual for both masses\", }), id_vars=[\"Signal to Noise Ratio\"])\n",
    "a = sns.lineplot(data=temparray, x = \"Signal to Noise Ratio\", y = \"value\", hue = \"variable\")\n",
    "a.set(title = \"Difference between predicted and actual masses\", xlabel = \"Signal to Noise Ratio\", ylabel = \"Difference between predicted and actual (solar masses)\")\n",
    "new_title = 'Legend:'\n",
    "# replace labels\n",
    "plt.legend(title='Legend', loc='upper right')\n",
    "sns.set(rc={'figure.figsize': (16, 9)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sns.lineplot(data=pd.melt(df[[\"combined\", \"DiffM2\", \"DiffM1\", \"avgDiff\"]], id_vars=[\n",
    "                 \"combined\"]), x=\"combined\", y=\"value\", hue=\"variable\")\n",
    "a.set(title=\"Difference between predicted and actual masses\",xlabel=\"Combined Mass (solar masses)\", ylabel=\"Difference between predicted and actual (solar masses)\")\n",
    "sns.set(rc={'figure.figsize': (16, 9)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sns.violinplot(x=df[\"EOS\"], y=df[\"avgDiff\"])\n",
    "a.set(title = \"Difference between predicted and actual masses vs EOS\", xlabel = \"Equation of State\", ylabel = \"Difference between predicted and actual (solar masses)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(dataset.eosmap.items()):\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = get_new_test_train_validation_datasets(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(16):\n",
    "    print(a[i][1])\n",
    "    plt.imshow(a[i][0].cpu().numpy())\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
