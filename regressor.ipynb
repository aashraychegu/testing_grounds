{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoRe_Dataloader_ECSG import load_pth_file,load_raw_from_pth_file\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import torchinfo\n",
    "import time\n",
    "import numpy as np\n",
    "import wandb\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "# trainds = get_dataset()\n",
    "# train_dl = DataLoader(trainds,batch_size=6,shuffle = True,)\n",
    "# test_dl = DataLoader(trainds,batch_size=16*2,shuffle = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl = load_pth_file(train_dl_batch_size=8)\n",
    "raw_train_ds, raw_test_ds = load_raw_from_pth_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3506,  1.3506],\n",
       "        [16.0000,  1.3750,  1.3750],\n",
       "        [14.0000,  1.3509,  1.3509],\n",
       "        [ 3.0000,  1.4000,  1.4000],\n",
       "        [10.0000,  1.3754,  1.3754],\n",
       "        [16.0000,  1.6201,  1.0801],\n",
       "        [ 8.0000,  1.5150,  1.5150],\n",
       "        [ 8.0000,  1.5150,  1.5150],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [14.0000,  1.3504,  1.3504],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [10.0000,  1.3754,  1.3754],\n",
       "        [16.0000,  1.8002,  0.9001],\n",
       "        [16.0000,  1.8002,  0.9001],\n",
       "        [16.0000,  1.6500,  1.0979],\n",
       "        [18.0000,  1.3500,  1.3500],\n",
       "        [ 2.0000,  1.3510,  1.3510],\n",
       "        [10.0000,  1.6500,  1.1000],\n",
       "        [14.0000,  1.5000,  1.5000],\n",
       "        [ 2.0000,  1.1000,  1.4000],\n",
       "        [16.0000,  1.3501,  1.3501],\n",
       "        [14.0000,  1.3509,  1.3509],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [10.0000,  1.5000,  1.5000],\n",
       "        [16.0000,  1.3501,  1.3501],\n",
       "        [ 2.0000,  1.6500,  1.1000],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.3581,  1.3581],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [10.0000,  1.5284,  1.2222],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [ 0.0000,  1.3500,  1.3500],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3581,  1.3581],\n",
       "        [16.0000,  1.3501,  1.3501],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [14.0000,  1.6500,  1.1000],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3576,  1.3576],\n",
       "        [14.0000,  1.4500,  1.3700],\n",
       "        [16.0000,  1.3553,  1.1072],\n",
       "        [16.0000,  1.6500,  1.0979],\n",
       "        [10.0000,  1.6000,  1.6000],\n",
       "        [16.0000,  1.5002,  1.5002],\n",
       "        [16.0000,  1.6201,  1.0801],\n",
       "        [16.0000,  1.7183,  0.9819],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [18.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3750,  1.3750],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [ 2.0000,  1.3510,  1.3510],\n",
       "        [ 2.0000,  1.5285,  1.2226],\n",
       "        [14.0000,  1.3504,  1.3504],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.3581,  1.3581],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3553,  1.1072],\n",
       "        [10.0000,  1.3505,  1.3505],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [ 5.0000,  1.3640,  1.3640],\n",
       "        [16.0000,  1.3501,  1.3501],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.7183,  0.9819],\n",
       "        [10.0000,  1.5000,  1.5000],\n",
       "        [16.0000,  1.7183,  0.9819],\n",
       "        [10.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.3501,  1.3501],\n",
       "        [10.0000,  1.5284,  1.2222],\n",
       "        [ 2.0000,  1.5000,  1.5000],\n",
       "        [10.0000,  1.6500,  1.1000],\n",
       "        [14.0000,  1.6500,  1.1000],\n",
       "        [16.0000,  1.3576,  1.3576],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [ 2.0000,  1.5285,  1.2226],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [15.0000,  1.5270,  1.7950],\n",
       "        [14.0000,  1.5278,  1.2222],\n",
       "        [16.0000,  1.2505,  1.4495],\n",
       "        [16.0000,  1.2505,  1.4495],\n",
       "        [14.0000,  1.5000,  1.5000],\n",
       "        [18.0000,  1.3500,  1.3500],\n",
       "        [13.0000,  1.2499,  1.4501],\n",
       "        [14.0000,  1.9440,  0.9440],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [14.0000,  1.0000,  1.5000],\n",
       "        [10.0000,  1.5284,  1.2225],\n",
       "        [ 2.0000,  1.6000,  1.6000],\n",
       "        [16.0000,  1.3506,  1.3506],\n",
       "        [ 8.0000,  1.5149,  1.5149],\n",
       "        [ 2.0000,  1.5278,  1.2222],\n",
       "        [16.0000,  1.3576,  1.3576],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [ 2.0000,  1.3755,  1.3755],\n",
       "        [ 2.0000,  1.3750,  1.3750],\n",
       "        [ 4.0000,  1.5000,  1.5000],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [10.0000,  1.3505,  1.3505],\n",
       "        [10.0000,  1.3500,  1.3500],\n",
       "        [10.0000,  1.3717,  1.3717],\n",
       "        [16.0000,  1.3547,  1.1067],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.7183,  0.9819],\n",
       "        [16.0000,  1.3581,  1.3581],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.3507,  1.3507],\n",
       "        [16.0000,  1.3501,  1.3501],\n",
       "        [13.0000,  1.3515,  1.3515],\n",
       "        [ 3.0000,  1.3640,  1.3640],\n",
       "        [ 2.0000,  1.3755,  1.3750],\n",
       "        [ 4.0000,  1.3640,  1.3640],\n",
       "        [16.0000,  1.5000,  1.0000],\n",
       "        [16.0000,  1.3501,  1.3501],\n",
       "        [14.0000,  1.9440,  0.9440],\n",
       "        [16.0000,  1.3507,  1.3507],\n",
       "        [ 2.0000,  1.6500,  1.1000],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [ 2.0000,  1.5285,  1.2226],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [10.0000,  1.3754,  1.3754],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [14.0000,  1.0000,  1.5000],\n",
       "        [14.0000,  1.5000,  1.0000],\n",
       "        [16.0000,  1.3547,  1.1067],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [18.0000,  1.3500,  1.3500],\n",
       "        [ 5.0000,  1.3325,  1.3325],\n",
       "        [ 2.0000,  1.3755,  1.3755],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [10.0000,  1.6508,  1.1002],\n",
       "        [14.0000,  1.3504,  1.3504],\n",
       "        [16.0000,  1.3581,  1.3581],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [10.0000,  1.3726,  1.3726],\n",
       "        [16.0000,  1.2505,  1.4495],\n",
       "        [10.0000,  1.5284,  1.2225],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [18.0000,  1.3500,  1.3500],\n",
       "        [ 8.0000,  1.5150,  1.5150],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [14.0000,  1.6000,  1.6000],\n",
       "        [14.0000,  1.3504,  1.3504],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [ 6.0000,  1.2000,  1.2000],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.5001,  1.2001],\n",
       "        [ 4.0000,  1.8560,  1.0200],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [17.0000,  1.6350,  1.1460],\n",
       "        [16.0000,  1.3544,  1.1065],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [14.0000,  1.1000,  1.4000],\n",
       "        [14.0000,  1.7000,  1.7000],\n",
       "        [16.0000,  1.3506,  1.3506],\n",
       "        [16.0000,  1.5270,  1.7950],\n",
       "        [16.0000,  1.3553,  1.1072],\n",
       "        [ 2.0000,  1.5000,  1.5000],\n",
       "        [ 6.0000,  1.5090,  1.2350],\n",
       "        [ 4.0000,  1.3325,  1.3325],\n",
       "        [16.0000,  1.8002,  0.9001],\n",
       "        [18.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3544,  1.1065],\n",
       "        [16.0000,  1.2000,  1.4000],\n",
       "        [10.0000,  1.3717,  1.3717],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [14.0000,  1.5000,  1.5000],\n",
       "        [10.0000,  1.3717,  1.3717],\n",
       "        [ 2.0000,  1.6509,  1.1000],\n",
       "        [14.0000,  1.3754,  1.3750],\n",
       "        [10.0000,  1.3726,  1.3726],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.2505,  1.4495],\n",
       "        [13.0000,  1.2499,  1.4501],\n",
       "        [ 9.0000,  1.5148,  1.5148],\n",
       "        [16.0000,  1.8002,  0.9001],\n",
       "        [16.0000,  1.8002,  0.9001],\n",
       "        [10.0000,  1.3717,  1.3717],\n",
       "        [14.0000,  1.5000,  1.0000],\n",
       "        [14.0000,  1.9440,  0.9440],\n",
       "        [14.0000,  1.0000,  1.5000],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [10.0000,  1.5284,  1.2222],\n",
       "        [11.0000,  1.3650,  1.2500],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [10.0000,  1.6500,  1.1000],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [ 8.0000,  1.5150,  1.5150],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.5001,  1.2001],\n",
       "        [10.0000,  1.7500,  1.0000],\n",
       "        [14.0000,  1.3808,  1.3808],\n",
       "        [14.0000,  1.5000,  1.5000],\n",
       "        [ 6.0000,  1.3000,  1.3000],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [10.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [14.0000,  1.3808,  1.3808],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.6201,  1.0801],\n",
       "        [10.0000,  1.6508,  1.1002],\n",
       "        [ 8.0000,  1.5153,  1.5153],\n",
       "        [16.0000,  1.5002,  1.5002],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.1003,  1.3996],\n",
       "        [16.0000,  1.8002,  0.9001],\n",
       "        [14.0000,  1.5000,  1.5000],\n",
       "        [10.0000,  1.7500,  1.0000],\n",
       "        [16.0000,  1.3553,  1.1072],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [10.0000,  1.5284,  1.2225],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3506,  1.3506],\n",
       "        [16.0000,  1.3509,  1.3509],\n",
       "        [14.0000,  1.5000,  1.0000],\n",
       "        [16.0000,  1.3576,  1.3576],\n",
       "        [14.0000,  1.7500,  1.0000],\n",
       "        [16.0000,  1.3506,  1.3506],\n",
       "        [ 2.0000,  1.3750,  1.3750],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [ 1.0000,  1.3500,  1.3500],\n",
       "        [10.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3544,  1.1065],\n",
       "        [13.0000,  1.3500,  1.3500],\n",
       "        [ 2.0000,  1.5285,  1.2226],\n",
       "        [10.0000,  1.2505,  1.4498],\n",
       "        [ 2.0000,  1.7500,  1.0000],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [10.0000,  1.3750,  1.3750],\n",
       "        [ 0.0000,  1.3500,  1.3500],\n",
       "        [10.0000,  1.3754,  1.3754],\n",
       "        [16.0000,  1.7183,  0.9819],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [17.0000,  1.3640,  1.3640],\n",
       "        [13.0000,  1.3500,  1.3500],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3500,  1.3500],\n",
       "        [16.0000,  1.3505,  1.3505],\n",
       "        [15.0000,  1.4000,  1.2000],\n",
       "        [14.0000,  1.3500,  1.3500],\n",
       "        [ 2.0000,  1.3755,  1.3750],\n",
       "        [15.0000,  1.4520,  1.2830],\n",
       "        [14.0000,  1.5000,  1.5000],\n",
       "        [ 9.0000,  1.5148,  1.5148],\n",
       "        [14.0000,  1.5000,  1.0000],\n",
       "        [14.0000,  1.5000,  1.5000]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_dl))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as metrics\n",
    "acc = metrics.Accuracy(task=\"multiclass\",num_classes=19).to(\"cuda:0\")\n",
    "auroc = metrics.AUROC(task = \"multiclass\",num_classes=19).to(\"cuda:0\")\n",
    "l1e = metrics.MeanAbsoluteError().to(\"cuda:0\")\n",
    "l2e = metrics.MeanSquaredError().to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vit\n",
    "import vit_pytorch as nl_vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2071,  0.4427]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = vit.ViT(image_size=400,\n",
    "                        patch_size=20,\n",
    "                        num_classes=2,\n",
    "                        dim=int(1024/2),\n",
    "                        depth=2,\n",
    "                        heads=8,\n",
    "                        mlp_dim=int(2048/2),\n",
    "                        channels=1).to(\"cuda:0\")\n",
    "\n",
    "\n",
    "img = torch.randn(1,1, 400,400).to(\"cuda:0\")\n",
    "\n",
    "preds = model(img)  # (1, 1000)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "startlr = 3e-5\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=startlr)\n",
    "optimizer1 = optim.NAdam(params=model.parameters(), lr=startlr)\n",
    "step_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[5, 15, 45, 135], gamma=0.9)\n",
    "# at the end of 600 epochs, the learning rate is 0.000,002,62\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=5, gamma=0.986)\n",
    "scheduler_pl = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', factor=0.7, patience=30, verbose=True)\n",
    "lossfn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_accuracy(model:torch.nn.Module,dl:DataLoader):\n",
    "    model.eval()\n",
    "    raw_output = []\n",
    "    parameters = []\n",
    "    with torch.no_grad():\n",
    "        for batch,(sg,params) in enumerate(dl):\n",
    "            sg = sg.to(\"cuda:0\").to(torch.float)\n",
    "            # print(params[:,1:])\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "\n",
    "            params = params[:,1:].to(\"cuda:0\").to(torch.float)\n",
    "            \n",
    "            raw_output.append(model(sg).detach())\n",
    "            parameters.append(params)\n",
    "            \n",
    "    model.train()\n",
    "    output = torch.concat(raw_output,dim=0)\n",
    "    parameters = torch.concat(parameters,dim=0)\n",
    "    accuracy = l1e(output,parameters)\n",
    "    auc = l2e(output,parameters)\n",
    "    return accuracy,auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_err, mse = new_accuracy(model=model, dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(config,adam = True,nadam = False):\n",
    "    tot_err,mse = new_accuracy(model=model,dl = test_dl)\n",
    "    max_err = float(\"inf\")\n",
    "    max_mse = float(\"inf\")\n",
    "    for epoch in range(1,config.epochs+2):\n",
    "        btime = time.time()\n",
    "        ldl = len(train_dl)\n",
    "        for batch,(sg,params) in enumerate(train_dl):\n",
    "            stime = time.time()\n",
    "            sg = sg.to(\"cuda:0\").to(torch.float)\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.view(sgsh[0],1,sgsh[1],sgsh[2])\n",
    "            params = params[:,1:].to(\"cuda:0\").to(torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sg)\n",
    "            loss = lossfn(outputs,params)\n",
    "            loss.backward()\n",
    "            optimizer.step() if adam else None\n",
    "            optimizer1.step() if nadam else None\n",
    "            wandb.log({\"loss\":loss.item(),\"lr\":scheduler.get_last_lr()[0],\"epoch\":epoch})\n",
    "            print(f\"{epoch:5}/{config.epochs:5} // {batch:5}/{ldl:5} | Loss: {loss.item():2.4}, last_total_error: {tot_err}, Maximum Error {max_err} last MSE {mse} Max MSE {max_mse} lr:{scheduler.get_last_lr()[0]:1.5},Time per Batch: {time.time()-stime:1.2} seconds     \",end = \"\\r\",flush=True)\n",
    "            torch.cuda.empty_cache()\n",
    "        tot_err, mse = new_accuracy(model=model, dl=test_dl)\n",
    "        scheduler.step()\n",
    "        step_scheduler.step()\n",
    "        scheduler_pl.step(tot_err)\n",
    "        if(tot_err < max_err):\n",
    "            max_err = tot_err\n",
    "            config.best_model = model.state_dict()\n",
    "            try:\n",
    "                torch.save(config.best_model, f\"./saved_models/cnns/best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__acc_{max_acc}__auc_{auc}.pt\")\n",
    "            except:  pass    \n",
    "            print(\"\\nSAVING MODEL\")\n",
    "        max_mse = min(max_mse,mse)\n",
    "        print(f\"\\nEpoch {epoch+1}/{config.epochs} finished. Total error: {tot_err:3.5} MSE: {mse} Time per Epoch: {time.time()-btime:1.5}\")\n",
    "\n",
    "        wandb.log({\"epoch\":epoch,\"error\":tot_err,\"max_accuracy\":max_err,\"lr\":scheduler.get_last_lr()[0],\"MSE\":mse,\"MaxMSE\":max_mse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maashraychegu\u001b[0m (\u001b[33malabs\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\aashr\\Desktop\\research\\testing_grounds\\wandb\\run-20230305_200145-ipq9d3vn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/alabs/simple_vision_transformer_regressor/runs/ipq9d3vn\" target=\"_blank\">generous-puddle-2</a></strong> to <a href=\"https://wandb.ai/alabs/simple_vision_transformer_regressor\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/alabs/simple_vision_transformer_regressor\" target=\"_blank\">https://wandb.ai/alabs/simple_vision_transformer_regressor</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/alabs/simple_vision_transformer_regressor/runs/ipq9d3vn\" target=\"_blank\">https://wandb.ai/alabs/simple_vision_transformer_regressor/runs/ipq9d3vn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1/ 1000 //   295/  296 | Loss: 0.03619, last_total_error: 1.207710862159729, Maximum Accuracy inf last MSE 1.5725191831588745 Max MSE inf lr:3e-05,Time per Batch: 0.027 seconds       \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 2/1000 finished. Total error: 0.15745 MSE: 0.034464865922927856 Time per Epoch: 20.676\n",
      "    2/ 1000 //   295/  296 | Loss: 0.02543, last_total_error: 0.1574515998363495, Maximum Accuracy inf last MSE 0.034464865922927856 Max MSE 0.034464865922927856 lr:3e-05,Time per Batch: 0.025 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 3/1000 finished. Total error: 0.11566 MSE: 0.021198676899075508 Time per Epoch: 16.315\n",
      "    3/ 1000 //   295/  296 | Loss: 0.01799, last_total_error: 0.11566206067800522, Maximum Accuracy inf last MSE 0.021198676899075508 Max MSE 0.021198676899075508 lr:3e-05,Time per Batch: 0.024 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 4/1000 finished. Total error: 0.098527 MSE: 0.016187112778425217 Time per Epoch: 16.423\n",
      "    4/ 1000 //   295/  296 | Loss: 0.01163, last_total_error: 0.09852689504623413, Maximum Accuracy inf last MSE 0.016187112778425217 Max MSE 0.016187112778425217 lr:3e-05,Time per Batch: 0.026 seconds       \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 5/1000 finished. Total error: 0.084752 MSE: 0.012763009406626225 Time per Epoch: 15.333\n",
      "    5/ 1000 //   295/  296 | Loss: 0.008062, last_total_error: 0.0847516879439354, Maximum Accuracy inf last MSE 0.012763009406626225 Max MSE 0.012763009406626225 lr:3e-05,Time per Batch: 0.037 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 6/1000 finished. Total error: 0.075043 MSE: 0.010414641350507736 Time per Epoch: 14.9\n",
      "    6/ 1000 //   295/  296 | Loss: 0.005549, last_total_error: 0.07504274696111679, Maximum Accuracy inf last MSE 0.010414641350507736 Max MSE 0.010414641350507736 lr:2.958e-05,Time per Batch: 0.052 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 7/1000 finished. Total error: 0.066293 MSE: 0.008485177531838417 Time per Epoch: 15.178\n",
      "    7/ 1000 //   295/  296 | Loss: 0.004565, last_total_error: 0.06629322469234467, Maximum Accuracy inf last MSE 0.008485177531838417 Max MSE 0.008485177531838417 lr:2.6622e-05,Time per Batch: 0.023 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 8/1000 finished. Total error: 0.06122 MSE: 0.007304031401872635 Time per Epoch: 14.463\n",
      "    8/ 1000 //   295/  296 | Loss: 0.0042, last_total_error: 0.06121975928544998, Maximum Accuracy inf last MSE 0.007304031401872635 Max MSE 0.007304031401872635 lr:2.6622e-05,Time per Batch: 0.042 seconds       \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 9/1000 finished. Total error: 0.058459 MSE: 0.006548455450683832 Time per Epoch: 13.823\n",
      "    9/ 1000 //   295/  296 | Loss: 0.003866, last_total_error: 0.058459021151065826, Maximum Accuracy inf last MSE 0.006548455450683832 Max MSE 0.006548455450683832 lr:2.6622e-05,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 10/1000 finished. Total error: 0.055658 MSE: 0.005855160299688578 Time per Epoch: 14.283\n",
      "   10/ 1000 //   295/  296 | Loss: 0.00327, last_total_error: 0.055657804012298584, Maximum Accuracy inf last MSE 0.005855160299688578 Max MSE 0.005855160299688578 lr:2.6622e-05,Time per Batch: 0.023 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 11/1000 finished. Total error: 0.053101 MSE: 0.005275181028991938 Time per Epoch: 14.167\n",
      "   11/ 1000 //   295/  296 | Loss: 0.003002, last_total_error: 0.05310065299272537, Maximum Accuracy inf last MSE 0.005275181028991938 Max MSE 0.005275181028991938 lr:2.6249e-05,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 12/1000 finished. Total error: 0.05127 MSE: 0.004819904919713736 Time per Epoch: 13.681\n",
      "   12/ 1000 //   295/  296 | Loss: 0.002692, last_total_error: 0.05126991495490074, Maximum Accuracy inf last MSE 0.004819904919713736 Max MSE 0.004819904919713736 lr:2.6249e-05,Time per Batch: 0.025 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 13/1000 finished. Total error: 0.050626 MSE: 0.004547702614217997 Time per Epoch: 13.617\n",
      "   13/ 1000 //   295/  296 | Loss: 0.002165, last_total_error: 0.050625983625650406, Maximum Accuracy inf last MSE 0.004547702614217997 Max MSE 0.004547702614217997 lr:2.6249e-05,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 14/1000 finished. Total error: 0.050543 MSE: 0.004411155823618174 Time per Epoch: 13.932\n",
      "   14/ 1000 //   295/  296 | Loss: 0.001533, last_total_error: 0.05054323375225067, Maximum Accuracy inf last MSE 0.004411155823618174 Max MSE 0.004411155823618174 lr:2.6249e-05,Time per Batch: 0.023 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 15/1000 finished. Total error: 0.049856 MSE: 0.0042649367824196815 Time per Epoch: 14.827\n",
      "   15/ 1000 //   295/  296 | Loss: 0.001025, last_total_error: 0.04985605925321579, Maximum Accuracy inf last MSE 0.0042649367824196815 Max MSE 0.0042649367824196815 lr:2.6249e-05,Time per Batch: 0.022 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 16/1000 finished. Total error: 0.049199 MSE: 0.004155038855969906 Time per Epoch: 14.541\n",
      "   16/ 1000 //   295/  296 | Loss: 0.0008027, last_total_error: 0.04919889196753502, Maximum Accuracy inf last MSE 0.004155038855969906 Max MSE 0.004155038855969906 lr:2.5882e-05,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 17/1000 finished. Total error: 0.048241 MSE: 0.00401146849617362 Time per Epoch: 14.585\n",
      "   17/ 1000 //   295/  296 | Loss: 0.0007607, last_total_error: 0.048240769654512405, Maximum Accuracy inf last MSE 0.00401146849617362 Max MSE 0.00401146849617362 lr:2.3294e-05,Time per Batch: 0.021 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 18/1000 finished. Total error: 0.047554 MSE: 0.0038883306551724672 Time per Epoch: 13.895\n",
      "   18/ 1000 //   295/  296 | Loss: 0.000718, last_total_error: 0.047553908079862595, Maximum Accuracy inf last MSE 0.0038883306551724672 Max MSE 0.0038883306551724672 lr:2.3294e-05,Time per Batch: 0.027 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 19/1000 finished. Total error: 0.046816 MSE: 0.0037682780530303717 Time per Epoch: 13.873\n",
      "   19/ 1000 //   295/  296 | Loss: 0.000613, last_total_error: 0.046816468238830566, Maximum Accuracy inf last MSE 0.0037682780530303717 Max MSE 0.0037682780530303717 lr:2.3294e-05,Time per Batch: 0.037 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 20/1000 finished. Total error: 0.045268 MSE: 0.0035553574562072754 Time per Epoch: 13.711\n",
      "   20/ 1000 //   295/  296 | Loss: 0.0007624, last_total_error: 0.045268286019563675, Maximum Accuracy inf last MSE 0.0035553574562072754 Max MSE 0.0035553574562072754 lr:2.3294e-05,Time per Batch: 0.035 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 21/1000 finished. Total error: 0.044644 MSE: 0.003421157132834196 Time per Epoch: 14.511\n",
      "   21/ 1000 //   295/  296 | Loss: 0.001727, last_total_error: 0.04464397206902504, Maximum Accuracy inf last MSE 0.003421157132834196 Max MSE 0.003421157132834196 lr:2.2968e-05,Time per Batch: 0.032 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 22/1000 finished. Total error: 0.047965 MSE: 0.003794528543949127 Time per Epoch: 12.896\n",
      "   22/ 1000 //   295/  296 | Loss: 0.001693, last_total_error: 0.0479651615023613, Maximum Accuracy inf last MSE 0.003794528543949127 Max MSE 0.003421157132834196 lr:2.2968e-05,Time per Batch: 0.024 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 23/1000 finished. Total error: 0.046238 MSE: 0.0035573444329202175 Time per Epoch: 13.447\n",
      "   23/ 1000 //   295/  296 | Loss: 0.001096, last_total_error: 0.046238403767347336, Maximum Accuracy inf last MSE 0.0035573444329202175 Max MSE 0.003421157132834196 lr:2.2968e-05,Time per Batch: 0.028 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 24/1000 finished. Total error: 0.043751 MSE: 0.0032419594936072826 Time per Epoch: 13.495\n",
      "   24/ 1000 //   295/  296 | Loss: 0.001277, last_total_error: 0.04375063255429268, Maximum Accuracy inf last MSE 0.0032419594936072826 Max MSE 0.0032419594936072826 lr:2.2968e-05,Time per Batch: 0.024 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 25/1000 finished. Total error: 0.044976 MSE: 0.003392512211576104 Time per Epoch: 13.847\n",
      "   25/ 1000 //   295/  296 | Loss: 0.00236, last_total_error: 0.044975824654102325, Maximum Accuracy inf last MSE 0.003392512211576104 Max MSE 0.0032419594936072826 lr:2.2968e-05,Time per Batch: 0.023 seconds       \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 26/1000 finished. Total error: 0.04395 MSE: 0.00322427018545568 Time per Epoch: 14.194\n",
      "   26/ 1000 //   295/  296 | Loss: 0.001134, last_total_error: 0.04395024850964546, Maximum Accuracy inf last MSE 0.00322427018545568 Max MSE 0.00322427018545568 lr:2.2646e-05,Time per Batch: 0.03 seconds       \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 27/1000 finished. Total error: 0.04495 MSE: 0.003412034595385194 Time per Epoch: 15.255\n",
      "   27/ 1000 //   295/  296 | Loss: 0.001732, last_total_error: 0.044949721544981, Maximum Accuracy inf last MSE 0.003412034595385194 Max MSE 0.00322427018545568 lr:2.2646e-05,Time per Batch: 0.027 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 28/1000 finished. Total error: 0.041493 MSE: 0.0029183493461459875 Time per Epoch: 13.402\n",
      "   28/ 1000 //   295/  296 | Loss: 0.001517, last_total_error: 0.04149294272065163, Maximum Accuracy inf last MSE 0.0029183493461459875 Max MSE 0.0029183493461459875 lr:2.2646e-05,Time per Batch: 0.024 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 29/1000 finished. Total error: 0.045238 MSE: 0.0034196285996586084 Time per Epoch: 13.397\n",
      "   29/ 1000 //   295/  296 | Loss: 0.001733, last_total_error: 0.0452384315431118, Maximum Accuracy inf last MSE 0.0034196285996586084 Max MSE 0.0029183493461459875 lr:2.2646e-05,Time per Batch: 0.025 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 30/1000 finished. Total error: 0.039711 MSE: 0.0026915359776467085 Time per Epoch: 12.799\n",
      "   30/ 1000 //   295/  296 | Loss: 0.001239, last_total_error: 0.03971071168780327, Maximum Accuracy inf last MSE 0.0026915359776467085 Max MSE 0.0026915359776467085 lr:2.2646e-05,Time per Batch: 0.037 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 31/1000 finished. Total error: 0.043611 MSE: 0.0031940387561917305 Time per Epoch: 12.873\n",
      "   31/ 1000 //   295/  296 | Loss: 0.0007388, last_total_error: 0.04361116886138916, Maximum Accuracy inf last MSE 0.0031940387561917305 Max MSE 0.0026915359776467085 lr:2.2329e-05,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 32/1000 finished. Total error: 0.041713 MSE: 0.0028821832966059446 Time per Epoch: 13.645\n",
      "Epoch 00032: reducing learning rate of group 0 to 1.5630e-05.r: 0.04171323403716087, Maximum Accuracy inf last MSE 0.0028821832966059446 Max MSE 0.0026915359776467085 lr:2.2329e-05,Time per Batch: 0.039 seconds     \n",
      "\n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 33/1000 finished. Total error: 0.042268 MSE: 0.003036331385374069 Time per Epoch: 13.668\n",
      "   33/ 1000 //   295/  296 | Loss: 0.001061, last_total_error: 0.04226824641227722, Maximum Accuracy inf last MSE 0.003036331385374069 Max MSE 0.0026915359776467085 lr:2.2329e-05,Time per Batch: 0.045 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 34/1000 finished. Total error: 0.041386 MSE: 0.002791614504531026 Time per Epoch: 13.659\n",
      "   34/ 1000 //   295/  296 | Loss: 0.001186, last_total_error: 0.041386064141988754, Maximum Accuracy inf last MSE 0.002791614504531026 Max MSE 0.0026915359776467085 lr:1.563e-05,Time per Batch: 0.032 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 35/1000 finished. Total error: 0.035743 MSE: 0.0021477218251675367 Time per Epoch: 13.582\n",
      "   35/ 1000 //   295/  296 | Loss: 0.0008852, last_total_error: 0.03574258089065552, Maximum Accuracy inf last MSE 0.0021477218251675367 Max MSE 0.0021477218251675367 lr:1.563e-05,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 36/1000 finished. Total error: 0.038796 MSE: 0.002511008409783244 Time per Epoch: 13.69\n",
      "   36/ 1000 //   295/  296 | Loss: 0.0005673, last_total_error: 0.038796182721853256, Maximum Accuracy inf last MSE 0.002511008409783244 Max MSE 0.0021477218251675367 lr:1.5411e-05,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 37/1000 finished. Total error: 0.033733 MSE: 0.001967113930732012 Time per Epoch: 13.728\n",
      "   37/ 1000 //   295/  296 | Loss: 0.0006808, last_total_error: 0.03373316302895546, Maximum Accuracy inf last MSE 0.001967113930732012 Max MSE 0.001967113930732012 lr:1.5411e-05,Time per Batch: 0.036 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 38/1000 finished. Total error: 0.034675 MSE: 0.002028875285759568 Time per Epoch: 13.79\n",
      "   38/ 1000 //   295/  296 | Loss: 0.0009178, last_total_error: 0.034675102680921555, Maximum Accuracy inf last MSE 0.002028875285759568 Max MSE 0.001967113930732012 lr:1.5411e-05,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 39/1000 finished. Total error: 0.03259 MSE: 0.0018252604641020298 Time per Epoch: 13.6\n",
      "   39/ 1000 //   295/  296 | Loss: 0.000647, last_total_error: 0.03258991613984108, Maximum Accuracy inf last MSE 0.0018252604641020298 Max MSE 0.0018252604641020298 lr:1.5411e-05,Time per Batch: 0.024 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 40/1000 finished. Total error: 0.033075 MSE: 0.0018453565426170826 Time per Epoch: 13.883\n",
      "   40/ 1000 //   295/  296 | Loss: 0.0005842, last_total_error: 0.033075377345085144, Maximum Accuracy inf last MSE 0.0018453565426170826 Max MSE 0.0018252604641020298 lr:1.5411e-05,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 41/1000 finished. Total error: 0.032703 MSE: 0.0018472051015123725 Time per Epoch: 13.365\n",
      "   41/ 1000 //   295/  296 | Loss: 0.0006751, last_total_error: 0.03270317614078522, Maximum Accuracy inf last MSE 0.0018472051015123725 Max MSE 0.0018252604641020298 lr:1.5196e-05,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 42/1000 finished. Total error: 0.03147 MSE: 0.0016516665928065777 Time per Epoch: 13.467\n",
      "   42/ 1000 //   295/  296 | Loss: 0.002216, last_total_error: 0.03147030621767044, Maximum Accuracy inf last MSE 0.0016516665928065777 Max MSE 0.0016516665928065777 lr:1.5196e-05,Time per Batch: 0.023 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 43/1000 finished. Total error: 0.033193 MSE: 0.001873427419923246 Time per Epoch: 13.52\n",
      "   43/ 1000 //   295/  296 | Loss: 0.000521, last_total_error: 0.03319269418716431, Maximum Accuracy inf last MSE 0.001873427419923246 Max MSE 0.0016516665928065777 lr:1.5196e-05,Time per Batch: 0.023 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 44/1000 finished. Total error: 0.028169 MSE: 0.0013889397960156202 Time per Epoch: 13.584\n",
      "   44/ 1000 //   295/  296 | Loss: 0.0006474, last_total_error: 0.028168821707367897, Maximum Accuracy inf last MSE 0.0013889397960156202 Max MSE 0.0013889397960156202 lr:1.5196e-05,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 45/1000 finished. Total error: 0.028281 MSE: 0.0013976451009511948 Time per Epoch: 13.173\n",
      "   45/ 1000 //   295/  296 | Loss: 0.0006715, last_total_error: 0.028281116858124733, Maximum Accuracy inf last MSE 0.0013976451009511948 Max MSE 0.0013889397960156202 lr:1.5196e-05,Time per Batch: 0.026 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 46/1000 finished. Total error: 0.02872 MSE: 0.001409726100973785 Time per Epoch: 13.671\n",
      "   46/ 1000 //   295/  296 | Loss: 0.0006037, last_total_error: 0.02871999517083168, Maximum Accuracy inf last MSE 0.001409726100973785 Max MSE 0.0013889397960156202 lr:1.4983e-05,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 47/1000 finished. Total error: 0.026621 MSE: 0.0012896088883280754 Time per Epoch: 13.032\n",
      "   47/ 1000 //   295/  296 | Loss: 0.0003472, last_total_error: 0.026620855554938316, Maximum Accuracy inf last MSE 0.0012896088883280754 Max MSE 0.0012896088883280754 lr:1.3485e-05,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 48/1000 finished. Total error: 0.024486 MSE: 0.0010696965036913753 Time per Epoch: 13.177\n",
      "   48/ 1000 //   295/  296 | Loss: 0.000183, last_total_error: 0.0244856309145689, Maximum Accuracy inf last MSE 0.0010696965036913753 Max MSE 0.0010696965036913753 lr:1.3485e-05,Time per Batch: 0.023 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 49/1000 finished. Total error: 0.027598 MSE: 0.0013286317698657513 Time per Epoch: 14.98\n",
      "   49/ 1000 //   295/  296 | Loss: 0.0009366, last_total_error: 0.027597881853580475, Maximum Accuracy inf last MSE 0.0013286317698657513 Max MSE 0.0010696965036913753 lr:1.3485e-05,Time per Batch: 0.038 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 50/1000 finished. Total error: 0.033914 MSE: 0.0018690817523747683 Time per Epoch: 13.441\n",
      "   50/ 1000 //   295/  296 | Loss: 0.0002892, last_total_error: 0.03391405567526817, Maximum Accuracy inf last MSE 0.0018690817523747683 Max MSE 0.0010696965036913753 lr:1.3485e-05,Time per Batch: 0.034 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 51/1000 finished. Total error: 0.028301 MSE: 0.0013970047002658248 Time per Epoch: 14.485\n",
      "   51/ 1000 //   295/  296 | Loss: 0.0005566, last_total_error: 0.028301307931542397, Maximum Accuracy inf last MSE 0.0013970047002658248 Max MSE 0.0010696965036913753 lr:1.3296e-05,Time per Batch: 0.027 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 52/1000 finished. Total error: 0.026841 MSE: 0.001223622472025454 Time per Epoch: 13.276\n",
      "   52/ 1000 //   295/  296 | Loss: 0.0004965, last_total_error: 0.026841217651963234, Maximum Accuracy inf last MSE 0.001223622472025454 Max MSE 0.0010696965036913753 lr:1.3296e-05,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 53/1000 finished. Total error: 0.027551 MSE: 0.0012924070470035076 Time per Epoch: 14.113\n",
      "   53/ 1000 //   295/  296 | Loss: 0.0002153, last_total_error: 0.02755083702504635, Maximum Accuracy inf last MSE 0.0012924070470035076 Max MSE 0.0010696965036913753 lr:1.3296e-05,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 54/1000 finished. Total error: 0.025553 MSE: 0.0011385232210159302 Time per Epoch: 13.668\n",
      "   54/ 1000 //   295/  296 | Loss: 0.0001351, last_total_error: 0.025552773848176003, Maximum Accuracy inf last MSE 0.0011385232210159302 Max MSE 0.0010696965036913753 lr:1.3296e-05,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 55/1000 finished. Total error: 0.024939 MSE: 0.001086618984118104 Time per Epoch: 14.563\n",
      "   55/ 1000 //   295/  296 | Loss: 0.000578, last_total_error: 0.024938665330410004, Maximum Accuracy inf last MSE 0.001086618984118104 Max MSE 0.0010696965036913753 lr:1.3296e-05,Time per Batch: 0.037 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 56/1000 finished. Total error: 0.028859 MSE: 0.00140054477378726 Time per Epoch: 13.696\n",
      "   56/ 1000 //   295/  296 | Loss: 0.0003562, last_total_error: 0.028858628123998642, Maximum Accuracy inf last MSE 0.00140054477378726 Max MSE 0.0010696965036913753 lr:1.311e-05,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 57/1000 finished. Total error: 0.029304 MSE: 0.0014167901827022433 Time per Epoch: 13.902\n",
      "   57/ 1000 //   295/  296 | Loss: 0.0003517, last_total_error: 0.029304223135113716, Maximum Accuracy inf last MSE 0.0014167901827022433 Max MSE 0.0010696965036913753 lr:1.311e-05,Time per Batch: 0.035 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 58/1000 finished. Total error: 0.022884 MSE: 0.0009080201270990074 Time per Epoch: 14.975\n",
      "   58/ 1000 //   295/  296 | Loss: 0.0003795, last_total_error: 0.022884266451001167, Maximum Accuracy inf last MSE 0.0009080201270990074 Max MSE 0.0009080201270990074 lr:1.311e-05,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 59/1000 finished. Total error: 0.023934 MSE: 0.0009752293699420989 Time per Epoch: 13.159\n",
      "   59/ 1000 //   295/  296 | Loss: 0.0006548, last_total_error: 0.023933522403240204, Maximum Accuracy inf last MSE 0.0009752293699420989 Max MSE 0.0009080201270990074 lr:1.311e-05,Time per Batch: 0.029 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 60/1000 finished. Total error: 0.033412 MSE: 0.0017058164812624454 Time per Epoch: 13.714\n",
      "   60/ 1000 //   295/  296 | Loss: 0.0003412, last_total_error: 0.03341188281774521, Maximum Accuracy inf last MSE 0.0017058164812624454 Max MSE 0.0009080201270990074 lr:1.311e-05,Time per Batch: 0.027 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 61/1000 finished. Total error: 0.026344 MSE: 0.0011680099414661527 Time per Epoch: 13.652\n",
      "   61/ 1000 //   295/  296 | Loss: 0.0004565, last_total_error: 0.026344314217567444, Maximum Accuracy inf last MSE 0.0011680099414661527 Max MSE 0.0009080201270990074 lr:1.2926e-05,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 62/1000 finished. Total error: 0.024027 MSE: 0.0009710607118904591 Time per Epoch: 13.939\n",
      "   62/ 1000 //   295/  296 | Loss: 0.0002344, last_total_error: 0.02402745746076107, Maximum Accuracy inf last MSE 0.0009710607118904591 Max MSE 0.0009080201270990074 lr:1.2926e-05,Time per Batch: 0.027 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 63/1000 finished. Total error: 0.023344 MSE: 0.0009702736861072481 Time per Epoch: 13.459\n",
      "Epoch 00063: reducing learning rate of group 0 to 9.0483e-06.: 0.023344488814473152, Maximum Accuracy inf last MSE 0.0009702736861072481 Max MSE 0.0009080201270990074 lr:1.2926e-05,Time per Batch: 0.03 seconds       \n",
      "\n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 64/1000 finished. Total error: 0.021891 MSE: 0.0008218888542614877 Time per Epoch: 13.928\n",
      "   64/ 1000 //   295/  296 | Loss: 0.0001765, last_total_error: 0.021891091018915176, Maximum Accuracy inf last MSE 0.0008218888542614877 Max MSE 0.0008218888542614877 lr:1.2926e-05,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 65/1000 finished. Total error: 0.023819 MSE: 0.0009209507843479514 Time per Epoch: 13.465\n",
      "   65/ 1000 //   295/  296 | Loss: 0.0001214, last_total_error: 0.02381889522075653, Maximum Accuracy inf last MSE 0.0009209507843479514 Max MSE 0.0008218888542614877 lr:9.0483e-06,Time per Batch: 0.026 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 66/1000 finished. Total error: 0.021298 MSE: 0.0007791401585564017 Time per Epoch: 13.492\n",
      "   66/ 1000 //   295/  296 | Loss: 0.0002176, last_total_error: 0.02129751443862915, Maximum Accuracy inf last MSE 0.0007791401585564017 Max MSE 0.0007791401585564017 lr:8.9216e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 67/1000 finished. Total error: 0.020417 MSE: 0.0007307862979359925 Time per Epoch: 13.044\n",
      "   67/ 1000 //   295/  296 | Loss: 0.0002283, last_total_error: 0.02041693776845932, Maximum Accuracy inf last MSE 0.0007307862979359925 Max MSE 0.0007307862979359925 lr:8.9216e-06,Time per Batch: 0.027 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 68/1000 finished. Total error: 0.020155 MSE: 0.0007061561336740851 Time per Epoch: 13.207\n",
      "   68/ 1000 //   295/  296 | Loss: 0.0005379, last_total_error: 0.020155468955636024, Maximum Accuracy inf last MSE 0.0007061561336740851 Max MSE 0.0007061561336740851 lr:8.9216e-06,Time per Batch: 0.021 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 69/1000 finished. Total error: 0.030699 MSE: 0.0014276726869866252 Time per Epoch: 12.64\n",
      "   69/ 1000 //   295/  296 | Loss: 0.0004293, last_total_error: 0.030699051916599274, Maximum Accuracy inf last MSE 0.0014276726869866252 Max MSE 0.0007061561336740851 lr:8.9216e-06,Time per Batch: 0.029 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 70/1000 finished. Total error: 0.024227 MSE: 0.0009311496396549046 Time per Epoch: 12.838\n",
      "   70/ 1000 //   295/  296 | Loss: 0.0002996, last_total_error: 0.024226536974310875, Maximum Accuracy inf last MSE 0.0009311496396549046 Max MSE 0.0007061561336740851 lr:8.9216e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 71/1000 finished. Total error: 0.024146 MSE: 0.001006396021693945 Time per Epoch: 13.007\n",
      "   71/ 1000 //   295/  296 | Loss: 0.0001954, last_total_error: 0.024146389216184616, Maximum Accuracy inf last MSE 0.001006396021693945 Max MSE 0.0007061561336740851 lr:8.7967e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 72/1000 finished. Total error: 0.023664 MSE: 0.0009091722313314676 Time per Epoch: 13.144\n",
      "   72/ 1000 //   295/  296 | Loss: 0.0003442, last_total_error: 0.02366422675549984, Maximum Accuracy inf last MSE 0.0009091722313314676 Max MSE 0.0007061561336740851 lr:8.7967e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 73/1000 finished. Total error: 0.021981 MSE: 0.0008196470444090664 Time per Epoch: 13.429\n",
      "   73/ 1000 //   295/  296 | Loss: 0.0001953, last_total_error: 0.021981142461299896, Maximum Accuracy inf last MSE 0.0008196470444090664 Max MSE 0.0007061561336740851 lr:8.7967e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 74/1000 finished. Total error: 0.019604 MSE: 0.0006793032516725361 Time per Epoch: 13.062\n",
      "   74/ 1000 //   295/  296 | Loss: 0.000226, last_total_error: 0.01960413157939911, Maximum Accuracy inf last MSE 0.0006793032516725361 Max MSE 0.0006793032516725361 lr:8.7967e-06,Time per Batch: 0.022 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 75/1000 finished. Total error: 0.020961 MSE: 0.0007715507526881993 Time per Epoch: 13.016\n",
      "   75/ 1000 //   295/  296 | Loss: 0.0001108, last_total_error: 0.020960841327905655, Maximum Accuracy inf last MSE 0.0007715507526881993 Max MSE 0.0006793032516725361 lr:8.7967e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 76/1000 finished. Total error: 0.019477 MSE: 0.0006531575345434248 Time per Epoch: 13.301\n",
      "   76/ 1000 //   295/  296 | Loss: 0.0001745, last_total_error: 0.019477464258670807, Maximum Accuracy inf last MSE 0.0006531575345434248 Max MSE 0.0006531575345434248 lr:8.6736e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 77/1000 finished. Total error: 0.022627 MSE: 0.0008466459694318473 Time per Epoch: 13.448\n",
      "   77/ 1000 //   295/  296 | Loss: 0.0003114, last_total_error: 0.022627273574471474, Maximum Accuracy inf last MSE 0.0008466459694318473 Max MSE 0.0006531575345434248 lr:8.6736e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 78/1000 finished. Total error: 0.019664 MSE: 0.0006942931213416159 Time per Epoch: 13.89\n",
      "   78/ 1000 //   295/  296 | Loss: 0.0002161, last_total_error: 0.01966436207294464, Maximum Accuracy inf last MSE 0.0006942931213416159 Max MSE 0.0006531575345434248 lr:8.6736e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 79/1000 finished. Total error: 0.023502 MSE: 0.0008770865970291197 Time per Epoch: 13.003\n",
      "   79/ 1000 //   295/  296 | Loss: 0.0003599, last_total_error: 0.023501982912421227, Maximum Accuracy inf last MSE 0.0008770865970291197 Max MSE 0.0006531575345434248 lr:8.6736e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 80/1000 finished. Total error: 0.019937 MSE: 0.0007168400916270912 Time per Epoch: 13.155\n",
      "   80/ 1000 //   295/  296 | Loss: 0.0003043, last_total_error: 0.01993713714182377, Maximum Accuracy inf last MSE 0.0007168400916270912 Max MSE 0.0006531575345434248 lr:8.6736e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 81/1000 finished. Total error: 0.0211 MSE: 0.0007201428525149822 Time per Epoch: 13.377\n",
      "   81/ 1000 //   295/  296 | Loss: 0.0003032, last_total_error: 0.02110009454190731, Maximum Accuracy inf last MSE 0.0007201428525149822 Max MSE 0.0006531575345434248 lr:8.5522e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 82/1000 finished. Total error: 0.018631 MSE: 0.000599874125327915 Time per Epoch: 12.674\n",
      "   82/ 1000 //   295/  296 | Loss: 0.0002893, last_total_error: 0.01863054372370243, Maximum Accuracy inf last MSE 0.000599874125327915 Max MSE 0.000599874125327915 lr:8.5522e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 83/1000 finished. Total error: 0.026922 MSE: 0.001088630175217986 Time per Epoch: 12.782\n",
      "   83/ 1000 //   295/  296 | Loss: 0.0002453, last_total_error: 0.026922477409243584, Maximum Accuracy inf last MSE 0.001088630175217986 Max MSE 0.000599874125327915 lr:8.5522e-06,Time per Batch: 0.021 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 84/1000 finished. Total error: 0.017051 MSE: 0.0005172861274331808 Time per Epoch: 12.747\n",
      "   84/ 1000 //   295/  296 | Loss: 0.0002827, last_total_error: 0.017051273956894875, Maximum Accuracy inf last MSE 0.0005172861274331808 Max MSE 0.0005172861274331808 lr:8.5522e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 85/1000 finished. Total error: 0.020441 MSE: 0.0006785510340705514 Time per Epoch: 12.75\n",
      "   85/ 1000 //   295/  296 | Loss: 0.0005914, last_total_error: 0.020440835505723953, Maximum Accuracy inf last MSE 0.0006785510340705514 Max MSE 0.0005172861274331808 lr:8.5522e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 86/1000 finished. Total error: 0.022464 MSE: 0.0008398184436373413 Time per Epoch: 13.181\n",
      "   86/ 1000 //   295/  296 | Loss: 0.0005808, last_total_error: 0.02246447280049324, Maximum Accuracy inf last MSE 0.0008398184436373413 Max MSE 0.0005172861274331808 lr:8.4324e-06,Time per Batch: 0.029 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 87/1000 finished. Total error: 0.019597 MSE: 0.0006795892841182649 Time per Epoch: 13.29\n",
      "   87/ 1000 //   295/  296 | Loss: 0.0001505, last_total_error: 0.019597377628087997, Maximum Accuracy inf last MSE 0.0006795892841182649 Max MSE 0.0005172861274331808 lr:8.4324e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 88/1000 finished. Total error: 0.022212 MSE: 0.0007905713864602149 Time per Epoch: 13.859\n",
      "   88/ 1000 //   295/  296 | Loss: 9.121e-05, last_total_error: 0.02221229299902916, Maximum Accuracy inf last MSE 0.0007905713864602149 Max MSE 0.0005172861274331808 lr:8.4324e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 89/1000 finished. Total error: 0.022958 MSE: 0.000816824147477746 Time per Epoch: 13.401\n",
      "   89/ 1000 //   295/  296 | Loss: 0.0002012, last_total_error: 0.02295764535665512, Maximum Accuracy inf last MSE 0.000816824147477746 Max MSE 0.0005172861274331808 lr:8.4324e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 90/1000 finished. Total error: 0.019675 MSE: 0.0006312382174655795 Time per Epoch: 13.028\n",
      "   90/ 1000 //   295/  296 | Loss: 0.0001502, last_total_error: 0.01967533305287361, Maximum Accuracy inf last MSE 0.0006312382174655795 Max MSE 0.0005172861274331808 lr:8.4324e-06,Time per Batch: 0.028 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 91/1000 finished. Total error: 0.019908 MSE: 0.0006515874993056059 Time per Epoch: 12.944\n",
      "   91/ 1000 //   295/  296 | Loss: 0.0002485, last_total_error: 0.019907984882593155, Maximum Accuracy inf last MSE 0.0006515874993056059 Max MSE 0.0005172861274331808 lr:8.3144e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 92/1000 finished. Total error: 0.020822 MSE: 0.0007010444533079863 Time per Epoch: 13.133\n",
      "   92/ 1000 //   295/  296 | Loss: 0.0001764, last_total_error: 0.02082238905131817, Maximum Accuracy inf last MSE 0.0007010444533079863 Max MSE 0.0005172861274331808 lr:8.3144e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 93/1000 finished. Total error: 0.022138 MSE: 0.0007861728081479669 Time per Epoch: 13.167\n",
      "   93/ 1000 //   295/  296 | Loss: 0.0002992, last_total_error: 0.022137559950351715, Maximum Accuracy inf last MSE 0.0007861728081479669 Max MSE 0.0005172861274331808 lr:8.3144e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 94/1000 finished. Total error: 0.016614 MSE: 0.0004830587131436914 Time per Epoch: 13.856\n",
      "Epoch 00094: reducing learning rate of group 0 to 5.8201e-06.r: 0.016613859683275223, Maximum Accuracy inf last MSE 0.0004830587131436914 Max MSE 0.0004830587131436914 lr:8.3144e-06,Time per Batch: 0.022 seconds     \n",
      "\n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 95/1000 finished. Total error: 0.020828 MSE: 0.0007179930689744651 Time per Epoch: 13.326\n",
      "   95/ 1000 //   295/  296 | Loss: 0.0002354, last_total_error: 0.020827868953347206, Maximum Accuracy inf last MSE 0.0007179930689744651 Max MSE 0.0004830587131436914 lr:8.3144e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 96/1000 finished. Total error: 0.018808 MSE: 0.0005769779090769589 Time per Epoch: 13.758\n",
      "   96/ 1000 //   295/  296 | Loss: 0.0002218, last_total_error: 0.018808040767908096, Maximum Accuracy inf last MSE 0.0005769779090769589 Max MSE 0.0004830587131436914 lr:5.7386e-06,Time per Batch: 0.028 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 97/1000 finished. Total error: 0.017702 MSE: 0.0005212099058553576 Time per Epoch: 13.357\n",
      "   97/ 1000 //   295/  296 | Loss: 0.0001091, last_total_error: 0.017702165991067886, Maximum Accuracy inf last MSE 0.0005212099058553576 Max MSE 0.0004830587131436914 lr:5.7386e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 98/1000 finished. Total error: 0.016826 MSE: 0.0004790537932422012 Time per Epoch: 13.749\n",
      "   98/ 1000 //   295/  296 | Loss: 0.000239, last_total_error: 0.01682611182332039, Maximum Accuracy inf last MSE 0.0004790537932422012 Max MSE 0.0004790537932422012 lr:5.7386e-06,Time per Batch: 0.025 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 99/1000 finished. Total error: 0.019958 MSE: 0.0006353481439873576 Time per Epoch: 13.488\n",
      "   99/ 1000 //   295/  296 | Loss: 0.0002406, last_total_error: 0.01995798945426941, Maximum Accuracy inf last MSE 0.0006353481439873576 Max MSE 0.0004790537932422012 lr:5.7386e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 100/1000 finished. Total error: 0.015759 MSE: 0.00044780230382457376 Time per Epoch: 13.423\n",
      "  100/ 1000 //   295/  296 | Loss: 0.0002521, last_total_error: 0.015758663415908813, Maximum Accuracy inf last MSE 0.00044780230382457376 Max MSE 0.00044780230382457376 lr:5.7386e-06,Time per Batch: 0.029 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 101/1000 finished. Total error: 0.017864 MSE: 0.0005428853328339756 Time per Epoch: 13.337\n",
      "  101/ 1000 //   295/  296 | Loss: 0.0003117, last_total_error: 0.01786429062485695, Maximum Accuracy inf last MSE 0.0005428853328339756 Max MSE 0.00044780230382457376 lr:5.6582e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 102/1000 finished. Total error: 0.017193 MSE: 0.000525742128957063 Time per Epoch: 13.06\n",
      "  102/ 1000 //   295/  296 | Loss: 0.0001441, last_total_error: 0.01719347946345806, Maximum Accuracy inf last MSE 0.000525742128957063 Max MSE 0.00044780230382457376 lr:5.6582e-06,Time per Batch: 0.026 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 103/1000 finished. Total error: 0.015258 MSE: 0.0004122199898120016 Time per Epoch: 13.133\n",
      "  103/ 1000 //   295/  296 | Loss: 0.0001527, last_total_error: 0.015257866121828556, Maximum Accuracy inf last MSE 0.0004122199898120016 Max MSE 0.0004122199898120016 lr:5.6582e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 104/1000 finished. Total error: 0.016579 MSE: 0.00047453658771701157 Time per Epoch: 12.98\n",
      "  104/ 1000 //   295/  296 | Loss: 0.0001329, last_total_error: 0.016578828915953636, Maximum Accuracy inf last MSE 0.00047453658771701157 Max MSE 0.0004122199898120016 lr:5.6582e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 105/1000 finished. Total error: 0.020441 MSE: 0.0006939633749425411 Time per Epoch: 13.057\n",
      "  105/ 1000 //   295/  296 | Loss: 0.0001008, last_total_error: 0.020441044121980667, Maximum Accuracy inf last MSE 0.0006939633749425411 Max MSE 0.0004122199898120016 lr:5.6582e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 106/1000 finished. Total error: 0.018289 MSE: 0.0005452996701933444 Time per Epoch: 12.872\n",
      "  106/ 1000 //   295/  296 | Loss: 0.0001293, last_total_error: 0.018288830295205116, Maximum Accuracy inf last MSE 0.0005452996701933444 Max MSE 0.0004122199898120016 lr:5.579e-06,Time per Batch: 0.028 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 107/1000 finished. Total error: 0.016903 MSE: 0.0004826416552532464 Time per Epoch: 13.098\n",
      "  107/ 1000 //   295/  296 | Loss: 0.0002176, last_total_error: 0.016902785748243332, Maximum Accuracy inf last MSE 0.0004826416552532464 Max MSE 0.0004122199898120016 lr:5.579e-06,Time per Batch: 0.031 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 108/1000 finished. Total error: 0.017377 MSE: 0.0005242693587206304 Time per Epoch: 13.654\n",
      "  108/ 1000 //   295/  296 | Loss: 0.0001887, last_total_error: 0.017377199605107307, Maximum Accuracy inf last MSE 0.0005242693587206304 Max MSE 0.0004122199898120016 lr:5.579e-06,Time per Batch: 0.029 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 109/1000 finished. Total error: 0.015383 MSE: 0.0004207235178910196 Time per Epoch: 13.556\n",
      "  109/ 1000 //   295/  296 | Loss: 0.0003082, last_total_error: 0.01538265123963356, Maximum Accuracy inf last MSE 0.0004207235178910196 Max MSE 0.0004122199898120016 lr:5.579e-06,Time per Batch: 0.021 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 110/1000 finished. Total error: 0.016569 MSE: 0.00046775562805123627 Time per Epoch: 13.169\n",
      "  110/ 1000 //   295/  296 | Loss: 0.0003007, last_total_error: 0.016569234430789948, Maximum Accuracy inf last MSE 0.00046775562805123627 Max MSE 0.0004122199898120016 lr:5.579e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 111/1000 finished. Total error: 0.014278 MSE: 0.0003709572192747146 Time per Epoch: 13.278\n",
      "  111/ 1000 //   295/  296 | Loss: 2.673e-05, last_total_error: 0.014278390444815159, Maximum Accuracy inf last MSE 0.0003709572192747146 Max MSE 0.0003709572192747146 lr:5.5009e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 112/1000 finished. Total error: 0.014297 MSE: 0.0003693404723890126 Time per Epoch: 13.409\n",
      "  112/ 1000 //   295/  296 | Loss: 0.0003361, last_total_error: 0.014297465793788433, Maximum Accuracy inf last MSE 0.0003693404723890126 Max MSE 0.0003693404723890126 lr:5.5009e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 113/1000 finished. Total error: 0.01524 MSE: 0.00040702178375795484 Time per Epoch: 12.843\n",
      "  113/ 1000 //   295/  296 | Loss: 0.0002982, last_total_error: 0.015239867381751537, Maximum Accuracy inf last MSE 0.00040702178375795484 Max MSE 0.0003693404723890126 lr:5.5009e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 114/1000 finished. Total error: 0.016735 MSE: 0.0004822524497285485 Time per Epoch: 12.944\n",
      "  114/ 1000 //   295/  296 | Loss: 0.000169, last_total_error: 0.01673491671681404, Maximum Accuracy inf last MSE 0.0004822524497285485 Max MSE 0.0003693404723890126 lr:5.5009e-06,Time per Batch: 0.028 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 115/1000 finished. Total error: 0.014866 MSE: 0.00041100670932792127 Time per Epoch: 13.188\n",
      "  115/ 1000 //   295/  296 | Loss: 0.000139, last_total_error: 0.014866286888718605, Maximum Accuracy inf last MSE 0.00041100670932792127 Max MSE 0.0003693404723890126 lr:5.5009e-06,Time per Batch: 0.029 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 116/1000 finished. Total error: 0.013903 MSE: 0.00036538878339342773 Time per Epoch: 13.052\n",
      "  116/ 1000 //   295/  296 | Loss: 0.0004219, last_total_error: 0.013903403654694557, Maximum Accuracy inf last MSE 0.00036538878339342773 Max MSE 0.00036538878339342773 lr:5.4239e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 117/1000 finished. Total error: 0.014025 MSE: 0.0003594666486606002 Time per Epoch: 12.752\n",
      "  117/ 1000 //   295/  296 | Loss: 0.0005105, last_total_error: 0.01402478851377964, Maximum Accuracy inf last MSE 0.0003594666486606002 Max MSE 0.0003594666486606002 lr:5.4239e-06,Time per Batch: 0.026 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 118/1000 finished. Total error: 0.015266 MSE: 0.00040622829692438245 Time per Epoch: 13.145\n",
      "  118/ 1000 //   295/  296 | Loss: 0.0001739, last_total_error: 0.01526568178087473, Maximum Accuracy inf last MSE 0.00040622829692438245 Max MSE 0.0003594666486606002 lr:5.4239e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 119/1000 finished. Total error: 0.013582 MSE: 0.0003373066720087081 Time per Epoch: 12.924\n",
      "  119/ 1000 //   295/  296 | Loss: 7.681e-05, last_total_error: 0.013582400046288967, Maximum Accuracy inf last MSE 0.0003373066720087081 Max MSE 0.0003373066720087081 lr:5.4239e-06,Time per Batch: 0.029 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 120/1000 finished. Total error: 0.013969 MSE: 0.0003573389840312302 Time per Epoch: 13.731\n",
      "  120/ 1000 //   295/  296 | Loss: 0.0002162, last_total_error: 0.013968524523079395, Maximum Accuracy inf last MSE 0.0003573389840312302 Max MSE 0.0003373066720087081 lr:5.4239e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 121/1000 finished. Total error: 0.014046 MSE: 0.0003680280642583966 Time per Epoch: 13.237\n",
      "  121/ 1000 //   295/  296 | Loss: 0.0001716, last_total_error: 0.014045652002096176, Maximum Accuracy inf last MSE 0.0003680280642583966 Max MSE 0.0003373066720087081 lr:5.348e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 122/1000 finished. Total error: 0.014553 MSE: 0.00038617977406829596 Time per Epoch: 13.581\n",
      "  122/ 1000 //   295/  296 | Loss: 5.372e-05, last_total_error: 0.014553277753293514, Maximum Accuracy inf last MSE 0.00038617977406829596 Max MSE 0.0003373066720087081 lr:5.348e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 123/1000 finished. Total error: 0.013917 MSE: 0.00036710736458189785 Time per Epoch: 13.266\n",
      "  123/ 1000 //   295/  296 | Loss: 6.905e-05, last_total_error: 0.013916957192122936, Maximum Accuracy inf last MSE 0.00036710736458189785 Max MSE 0.0003373066720087081 lr:5.348e-06,Time per Batch: 0.035 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 124/1000 finished. Total error: 0.013068 MSE: 0.00031819374999031425 Time per Epoch: 13.5\n",
      "  124/ 1000 //   295/  296 | Loss: 9.411e-05, last_total_error: 0.013067517429590225, Maximum Accuracy inf last MSE 0.00031819374999031425 Max MSE 0.00031819374999031425 lr:5.348e-06,Time per Batch: 0.026 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 125/1000 finished. Total error: 0.014857 MSE: 0.0003775613440666348 Time per Epoch: 13.512\n",
      "Epoch 00125: reducing learning rate of group 0 to 3.6912e-06.r: 0.014856679365038872, Maximum Accuracy inf last MSE 0.0003775613440666348 Max MSE 0.00031819374999031425 lr:5.348e-06,Time per Batch: 0.045 seconds     \n",
      "\n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 126/1000 finished. Total error: 0.015765 MSE: 0.00043465601629577577 Time per Epoch: 13.643\n",
      "  126/ 1000 //   295/  296 | Loss: 0.0002741, last_total_error: 0.01576530933380127, Maximum Accuracy inf last MSE 0.00043465601629577577 Max MSE 0.00031819374999031425 lr:5.2731e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 127/1000 finished. Total error: 0.013648 MSE: 0.000352558126905933 Time per Epoch: 13.297\n",
      "  127/ 1000 //   295/  296 | Loss: 8.096e-05, last_total_error: 0.013648211024701595, Maximum Accuracy inf last MSE 0.000352558126905933 Max MSE 0.00031819374999031425 lr:3.6912e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 128/1000 finished. Total error: 0.017827 MSE: 0.0005097787361592054 Time per Epoch: 13.887\n",
      "  128/ 1000 //   295/  296 | Loss: 8.057e-05, last_total_error: 0.017826635390520096, Maximum Accuracy inf last MSE 0.0005097787361592054 Max MSE 0.00031819374999031425 lr:3.6912e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 129/1000 finished. Total error: 0.012768 MSE: 0.00030650690314359963 Time per Epoch: 13.211\n",
      "  129/ 1000 //   295/  296 | Loss: 0.0002601, last_total_error: 0.012767592445015907, Maximum Accuracy inf last MSE 0.00030650690314359963 Max MSE 0.00030650690314359963 lr:3.6912e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 130/1000 finished. Total error: 0.01446 MSE: 0.00035930299782194197 Time per Epoch: 13.432\n",
      "  130/ 1000 //   295/  296 | Loss: 2.123e-05, last_total_error: 0.014459670521318913, Maximum Accuracy inf last MSE 0.00035930299782194197 Max MSE 0.00030650690314359963 lr:3.6912e-06,Time per Batch: 0.032 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 131/1000 finished. Total error: 0.011776 MSE: 0.00026967874146066606 Time per Epoch: 13.57\n",
      "  131/ 1000 //   295/  296 | Loss: 0.0001325, last_total_error: 0.011775948107242584, Maximum Accuracy inf last MSE 0.00026967874146066606 Max MSE 0.00026967874146066606 lr:3.6395e-06,Time per Batch: 0.03 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 132/1000 finished. Total error: 0.011892 MSE: 0.00026646218611858785 Time per Epoch: 13.728\n",
      "  132/ 1000 //   295/  296 | Loss: 0.0002093, last_total_error: 0.011892290785908699, Maximum Accuracy inf last MSE 0.00026646218611858785 Max MSE 0.00026646218611858785 lr:3.6395e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 133/1000 finished. Total error: 0.013662 MSE: 0.00034334181691519916 Time per Epoch: 13.375\n",
      "  133/ 1000 //   295/  296 | Loss: 8.102e-05, last_total_error: 0.013662313111126423, Maximum Accuracy inf last MSE 0.00034334181691519916 Max MSE 0.00026646218611858785 lr:3.6395e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 134/1000 finished. Total error: 0.013871 MSE: 0.00034174174652434886 Time per Epoch: 13.378\n",
      "  134/ 1000 //   295/  296 | Loss: 0.000178, last_total_error: 0.013870920054614544, Maximum Accuracy inf last MSE 0.00034174174652434886 Max MSE 0.00026646218611858785 lr:3.6395e-06,Time per Batch: 0.024 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 135/1000 finished. Total error: 0.013141 MSE: 0.0003159681800752878 Time per Epoch: 14.245\n",
      "  135/ 1000 //   295/  296 | Loss: 7.269e-05, last_total_error: 0.013140697963535786, Maximum Accuracy inf last MSE 0.0003159681800752878 Max MSE 0.00026646218611858785 lr:3.6395e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 136/1000 finished. Total error: 0.01275 MSE: 0.0003021314914803952 Time per Epoch: 13.867\n",
      "  136/ 1000 //   295/  296 | Loss: 0.0002379, last_total_error: 0.01275046169757843, Maximum Accuracy inf last MSE 0.0003021314914803952 Max MSE 0.00026646218611858785 lr:3.5885e-06,Time per Batch: 0.03 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 137/1000 finished. Total error: 0.01269 MSE: 0.00029729329980909824 Time per Epoch: 13.314\n",
      "  137/ 1000 //   295/  296 | Loss: 7.557e-05, last_total_error: 0.012689822353422642, Maximum Accuracy inf last MSE 0.00029729329980909824 Max MSE 0.00026646218611858785 lr:3.2297e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 138/1000 finished. Total error: 0.014456 MSE: 0.0003527481749188155 Time per Epoch: 13.584\n",
      "  138/ 1000 //   295/  296 | Loss: 4.579e-05, last_total_error: 0.014455952681601048, Maximum Accuracy inf last MSE 0.0003527481749188155 Max MSE 0.00026646218611858785 lr:3.2297e-06,Time per Batch: 0.027 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 139/1000 finished. Total error: 0.011277 MSE: 0.00023831186990719289 Time per Epoch: 13.538\n",
      "  139/ 1000 //   295/  296 | Loss: 8.823e-05, last_total_error: 0.011277236044406891, Maximum Accuracy inf last MSE 0.00023831186990719289 Max MSE 0.00023831186990719289 lr:3.2297e-06,Time per Batch: 0.034 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 140/1000 finished. Total error: 0.012407 MSE: 0.0002815723419189453 Time per Epoch: 13.476\n",
      "  140/ 1000 //   295/  296 | Loss: 0.0004353, last_total_error: 0.012406648136675358, Maximum Accuracy inf last MSE 0.0002815723419189453 Max MSE 0.00023831186990719289 lr:3.2297e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 141/1000 finished. Total error: 0.011987 MSE: 0.0002838578075170517 Time per Epoch: 13.912\n",
      "  141/ 1000 //   295/  296 | Loss: 3.775e-05, last_total_error: 0.01198700163513422, Maximum Accuracy inf last MSE 0.0002838578075170517 Max MSE 0.00023831186990719289 lr:3.1845e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 142/1000 finished. Total error: 0.015939 MSE: 0.0004075114557053894 Time per Epoch: 13.588\n",
      "  142/ 1000 //   295/  296 | Loss: 6.266e-05, last_total_error: 0.015938593074679375, Maximum Accuracy inf last MSE 0.0004075114557053894 Max MSE 0.00023831186990719289 lr:3.1845e-06,Time per Batch: 0.043 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 143/1000 finished. Total error: 0.011978 MSE: 0.0002721258788369596 Time per Epoch: 14.015\n",
      "  143/ 1000 //   295/  296 | Loss: 0.000223, last_total_error: 0.011978146620094776, Maximum Accuracy inf last MSE 0.0002721258788369596 Max MSE 0.00023831186990719289 lr:3.1845e-06,Time per Batch: 0.03 seconds       \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 144/1000 finished. Total error: 0.012067 MSE: 0.0002684783248696476 Time per Epoch: 13.805\n",
      "  144/ 1000 //   295/  296 | Loss: 0.0001725, last_total_error: 0.01206683274358511, Maximum Accuracy inf last MSE 0.0002684783248696476 Max MSE 0.00023831186990719289 lr:3.1845e-06,Time per Batch: 0.026 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 145/1000 finished. Total error: 0.013853 MSE: 0.00034000337473116815 Time per Epoch: 13.462\n",
      "  145/ 1000 //   295/  296 | Loss: 0.0001622, last_total_error: 0.013853087089955807, Maximum Accuracy inf last MSE 0.00034000337473116815 Max MSE 0.00023831186990719289 lr:3.1845e-06,Time per Batch: 0.021 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 146/1000 finished. Total error: 0.011578 MSE: 0.00024852872593328357 Time per Epoch: 13.169\n",
      "  146/ 1000 //   295/  296 | Loss: 0.0001019, last_total_error: 0.011578082107007504, Maximum Accuracy inf last MSE 0.00024852872593328357 Max MSE 0.00023831186990719289 lr:3.1399e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 147/1000 finished. Total error: 0.01312 MSE: 0.0002905833534896374 Time per Epoch: 13.951\n",
      "  147/ 1000 //   295/  296 | Loss: 0.000262, last_total_error: 0.013120396994054317, Maximum Accuracy inf last MSE 0.0002905833534896374 Max MSE 0.00023831186990719289 lr:3.1399e-06,Time per Batch: 0.023 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 148/1000 finished. Total error: 0.015324 MSE: 0.00037131604040041566 Time per Epoch: 13.891\n",
      "  148/ 1000 //   295/  296 | Loss: 0.0001262, last_total_error: 0.015324482694268227, Maximum Accuracy inf last MSE 0.00037131604040041566 Max MSE 0.00023831186990719289 lr:3.1399e-06,Time per Batch: 0.034 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 149/1000 finished. Total error: 0.015856 MSE: 0.0003933096013497561 Time per Epoch: 13.156\n",
      "  149/ 1000 //   295/  296 | Loss: 2.807e-05, last_total_error: 0.015856124460697174, Maximum Accuracy inf last MSE 0.0003933096013497561 Max MSE 0.00023831186990719289 lr:3.1399e-06,Time per Batch: 0.026 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 150/1000 finished. Total error: 0.011146 MSE: 0.00023212170344777405 Time per Epoch: 13.317\n",
      "  150/ 1000 //   295/  296 | Loss: 8.448e-05, last_total_error: 0.011145597323775291, Maximum Accuracy inf last MSE 0.00023212170344777405 Max MSE 0.00023212170344777405 lr:3.1399e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 151/1000 finished. Total error: 0.012206 MSE: 0.0002560768916737288 Time per Epoch: 13.775\n",
      "  151/ 1000 //   295/  296 | Loss: 0.0001621, last_total_error: 0.012206302024424076, Maximum Accuracy inf last MSE 0.0002560768916737288 Max MSE 0.00023212170344777405 lr:3.0959e-06,Time per Batch: 0.03 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 152/1000 finished. Total error: 0.012566 MSE: 0.00027283886447548866 Time per Epoch: 13.845\n",
      "  152/ 1000 //   295/  296 | Loss: 0.0002845, last_total_error: 0.012566180899739265, Maximum Accuracy inf last MSE 0.00027283886447548866 Max MSE 0.00023212170344777405 lr:3.0959e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 153/1000 finished. Total error: 0.01581 MSE: 0.00040082354098558426 Time per Epoch: 13.414\n",
      "  153/ 1000 //   295/  296 | Loss: 4.525e-05, last_total_error: 0.015810493379831314, Maximum Accuracy inf last MSE 0.00040082354098558426 Max MSE 0.00023212170344777405 lr:3.0959e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 154/1000 finished. Total error: 0.016144 MSE: 0.0004059811762999743 Time per Epoch: 13.515\n",
      "  154/ 1000 //   295/  296 | Loss: 7.202e-05, last_total_error: 0.01614363119006157, Maximum Accuracy inf last MSE 0.0004059811762999743 Max MSE 0.00023212170344777405 lr:3.0959e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 155/1000 finished. Total error: 0.012191 MSE: 0.0002742990618571639 Time per Epoch: 13.686\n",
      "  155/ 1000 //   295/  296 | Loss: 0.0002549, last_total_error: 0.012190746143460274, Maximum Accuracy inf last MSE 0.0002742990618571639 Max MSE 0.00023212170344777405 lr:3.0959e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 156/1000 finished. Total error: 0.013417 MSE: 0.0003137693856842816 Time per Epoch: 13.642\n",
      "Epoch 00156: reducing learning rate of group 0 to 2.1368e-06.r: 0.013416999019682407, Maximum Accuracy inf last MSE 0.0003137693856842816 Max MSE 0.00023212170344777405 lr:3.0526e-06,Time per Batch: 0.023 seconds     \n",
      "\n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 157/1000 finished. Total error: 0.012085 MSE: 0.00026163176517002285 Time per Epoch: 13.212\n",
      "  157/ 1000 //   295/  296 | Loss: 5.193e-05, last_total_error: 0.0120854452252388, Maximum Accuracy inf last MSE 0.00026163176517002285 Max MSE 0.00023212170344777405 lr:3.0526e-06,Time per Batch: 0.021 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 158/1000 finished. Total error: 0.012451 MSE: 0.0002737175964284688 Time per Epoch: 13.268\n",
      "  158/ 1000 //   295/  296 | Loss: 0.000134, last_total_error: 0.012450783513486385, Maximum Accuracy inf last MSE 0.0002737175964284688 Max MSE 0.00023212170344777405 lr:2.1368e-06,Time per Batch: 0.045 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 159/1000 finished. Total error: 0.011448 MSE: 0.000228311590035446 Time per Epoch: 13.426\n",
      "  159/ 1000 //   295/  296 | Loss: 6.771e-05, last_total_error: 0.011448469012975693, Maximum Accuracy inf last MSE 0.000228311590035446 Max MSE 0.000228311590035446 lr:2.1368e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 160/1000 finished. Total error: 0.013926 MSE: 0.00031001155730336905 Time per Epoch: 13.707\n",
      "  160/ 1000 //   295/  296 | Loss: 0.0003151, last_total_error: 0.013926261104643345, Maximum Accuracy inf last MSE 0.00031001155730336905 Max MSE 0.000228311590035446 lr:2.1368e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 161/1000 finished. Total error: 0.010566 MSE: 0.00021048428607173264 Time per Epoch: 14.009\n",
      "  161/ 1000 //   295/  296 | Loss: 0.0002994, last_total_error: 0.01056613214313984, Maximum Accuracy inf last MSE 0.00021048428607173264 Max MSE 0.00021048428607173264 lr:2.1069e-06,Time per Batch: 0.033 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 162/1000 finished. Total error: 0.014076 MSE: 0.00032890375587157905 Time per Epoch: 13.561\n",
      "  162/ 1000 //   295/  296 | Loss: 0.0001945, last_total_error: 0.01407554280012846, Maximum Accuracy inf last MSE 0.00032890375587157905 Max MSE 0.00021048428607173264 lr:2.1069e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 163/1000 finished. Total error: 0.012184 MSE: 0.0002718944742809981 Time per Epoch: 13.681\n",
      "  163/ 1000 //   295/  296 | Loss: 0.0001041, last_total_error: 0.01218391116708517, Maximum Accuracy inf last MSE 0.0002718944742809981 Max MSE 0.00021048428607173264 lr:2.1069e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 164/1000 finished. Total error: 0.015122 MSE: 0.0003634328895714134 Time per Epoch: 13.455\n",
      "  164/ 1000 //   295/  296 | Loss: 0.0001216, last_total_error: 0.015122456476092339, Maximum Accuracy inf last MSE 0.0003634328895714134 Max MSE 0.00021048428607173264 lr:2.1069e-06,Time per Batch: 0.021 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 165/1000 finished. Total error: 0.014127 MSE: 0.00032765764626674354 Time per Epoch: 13.775\n",
      "  165/ 1000 //   295/  296 | Loss: 0.0001634, last_total_error: 0.014126511290669441, Maximum Accuracy inf last MSE 0.00032765764626674354 Max MSE 0.00021048428607173264 lr:2.1069e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 166/1000 finished. Total error: 0.015291 MSE: 0.0003563380450941622 Time per Epoch: 13.466\n",
      "  166/ 1000 //   295/  296 | Loss: 7.257e-05, last_total_error: 0.015290860086679459, Maximum Accuracy inf last MSE 0.0003563380450941622 Max MSE 0.00021048428607173264 lr:2.0774e-06,Time per Batch: 0.03 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 167/1000 finished. Total error: 0.013978 MSE: 0.0003098393208347261 Time per Epoch: 13.515\n",
      "  167/ 1000 //   295/  296 | Loss: 0.0003473, last_total_error: 0.01397844310849905, Maximum Accuracy inf last MSE 0.0003098393208347261 Max MSE 0.00021048428607173264 lr:2.0774e-06,Time per Batch: 0.022 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 168/1000 finished. Total error: 0.011131 MSE: 0.00023255070846062154 Time per Epoch: 13.762\n",
      "  168/ 1000 //   295/  296 | Loss: 0.0003049, last_total_error: 0.011131362058222294, Maximum Accuracy inf last MSE 0.00023255070846062154 Max MSE 0.00021048428607173264 lr:2.0774e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 169/1000 finished. Total error: 0.016926 MSE: 0.00043371313950046897 Time per Epoch: 13.806\n",
      "  169/ 1000 //   295/  296 | Loss: 0.0003124, last_total_error: 0.016925524920225143, Maximum Accuracy inf last MSE 0.00043371313950046897 Max MSE 0.00021048428607173264 lr:2.0774e-06,Time per Batch: 0.021 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 170/1000 finished. Total error: 0.012669 MSE: 0.00028453816776163876 Time per Epoch: 13.573\n",
      "  170/ 1000 //   295/  296 | Loss: 0.0001921, last_total_error: 0.012669033370912075, Maximum Accuracy inf last MSE 0.00028453816776163876 Max MSE 0.00021048428607173264 lr:2.0774e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 171/1000 finished. Total error: 0.015795 MSE: 0.0003869434876833111 Time per Epoch: 13.466\n",
      "  171/ 1000 //   295/  296 | Loss: 0.0003396, last_total_error: 0.0157953891903162, Maximum Accuracy inf last MSE 0.0003869434876833111 Max MSE 0.00021048428607173264 lr:2.0483e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 172/1000 finished. Total error: 0.011734 MSE: 0.00024875139934010804 Time per Epoch: 13.93\n",
      "  172/ 1000 //   295/  296 | Loss: 0.0002153, last_total_error: 0.011733664199709892, Maximum Accuracy inf last MSE 0.00024875139934010804 Max MSE 0.00021048428607173264 lr:2.0483e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 173/1000 finished. Total error: 0.015409 MSE: 0.00035640597343444824 Time per Epoch: 13.246\n",
      "  173/ 1000 //   295/  296 | Loss: 0.0003067, last_total_error: 0.01540860254317522, Maximum Accuracy inf last MSE 0.00035640597343444824 Max MSE 0.00021048428607173264 lr:2.0483e-06,Time per Batch: 0.035 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 174/1000 finished. Total error: 0.011744 MSE: 0.00024136107822414488 Time per Epoch: 13.578\n",
      "  174/ 1000 //   295/  296 | Loss: 6.585e-05, last_total_error: 0.011743667535483837, Maximum Accuracy inf last MSE 0.00024136107822414488 Max MSE 0.00021048428607173264 lr:2.0483e-06,Time per Batch: 0.049 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 175/1000 finished. Total error: 0.015307 MSE: 0.00035425019450485706 Time per Epoch: 14.012\n",
      "  175/ 1000 //   295/  296 | Loss: 5.244e-05, last_total_error: 0.015306842513382435, Maximum Accuracy inf last MSE 0.00035425019450485706 Max MSE 0.00021048428607173264 lr:2.0483e-06,Time per Batch: 0.031 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 176/1000 finished. Total error: 0.010431 MSE: 0.00020593490626197308 Time per Epoch: 13.176\n",
      "  176/ 1000 //   295/  296 | Loss: 0.0001061, last_total_error: 0.010430986061692238, Maximum Accuracy inf last MSE 0.00020593490626197308 Max MSE 0.00020593490626197308 lr:2.0196e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 177/1000 finished. Total error: 0.013504 MSE: 0.00030543809407390654 Time per Epoch: 13.845\n",
      "  177/ 1000 //   295/  296 | Loss: 0.0001076, last_total_error: 0.013504043221473694, Maximum Accuracy inf last MSE 0.00030543809407390654 Max MSE 0.00020593490626197308 lr:2.0196e-06,Time per Batch: 0.03 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 178/1000 finished. Total error: 0.015913 MSE: 0.00039032945642247796 Time per Epoch: 13.445\n",
      "  178/ 1000 //   295/  296 | Loss: 0.0001177, last_total_error: 0.015913087874650955, Maximum Accuracy inf last MSE 0.00039032945642247796 Max MSE 0.00020593490626197308 lr:2.0196e-06,Time per Batch: 0.025 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 179/1000 finished. Total error: 0.012115 MSE: 0.0002777471672743559 Time per Epoch: 13.249\n",
      "  179/ 1000 //   295/  296 | Loss: 4.453e-05, last_total_error: 0.012115038000047207, Maximum Accuracy inf last MSE 0.0002777471672743559 Max MSE 0.00020593490626197308 lr:2.0196e-06,Time per Batch: 0.04 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 180/1000 finished. Total error: 0.011054 MSE: 0.00022305786842480302 Time per Epoch: 13.684\n",
      "  180/ 1000 //   295/  296 | Loss: 6.008e-05, last_total_error: 0.011054063215851784, Maximum Accuracy inf last MSE 0.00022305786842480302 Max MSE 0.00020593490626197308 lr:2.0196e-06,Time per Batch: 0.023 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 181/1000 finished. Total error: 0.014033 MSE: 0.0003219368227291852 Time per Epoch: 12.875\n",
      "  181/ 1000 //   295/  296 | Loss: 5.504e-05, last_total_error: 0.01403286587446928, Maximum Accuracy inf last MSE 0.0003219368227291852 Max MSE 0.00020593490626197308 lr:1.9914e-06,Time per Batch: 0.024 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 182/1000 finished. Total error: 0.011339 MSE: 0.00023244565818458796 Time per Epoch: 13.227\n",
      "  182/ 1000 //   295/  296 | Loss: 5.97e-05, last_total_error: 0.011338562704622746, Maximum Accuracy inf last MSE 0.00023244565818458796 Max MSE 0.00020593490626197308 lr:1.9914e-06,Time per Batch: 0.028 seconds      \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 183/1000 finished. Total error: 0.01234 MSE: 0.0002664134372025728 Time per Epoch: 14.747\n",
      "  183/ 1000 //   295/  296 | Loss: 6.5e-05, last_total_error: 0.01234026625752449, Maximum Accuracy inf last MSE 0.0002664134372025728 Max MSE 0.00020593490626197308 lr:1.9914e-06,Time per Batch: 0.025 seconds       \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 184/1000 finished. Total error: 0.01069 MSE: 0.0002060868573607877 Time per Epoch: 15.961\n",
      "  184/ 1000 //   295/  296 | Loss: 0.0001098, last_total_error: 0.010689647868275642, Maximum Accuracy inf last MSE 0.0002060868573607877 Max MSE 0.00020593490626197308 lr:1.9914e-06,Time per Batch: 0.032 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 185/1000 finished. Total error: 0.014672 MSE: 0.0003358139656484127 Time per Epoch: 17.863\n",
      "  185/ 1000 //   295/  296 | Loss: 8.421e-05, last_total_error: 0.014672067947685719, Maximum Accuracy inf last MSE 0.0003358139656484127 Max MSE 0.00020593490626197308 lr:1.9914e-06,Time per Batch: 0.027 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 186/1000 finished. Total error: 0.011749 MSE: 0.00024063658202067018 Time per Epoch: 22.939\n",
      "  186/ 1000 //   295/  296 | Loss: 0.0001367, last_total_error: 0.01174855325371027, Maximum Accuracy inf last MSE 0.00024063658202067018 Max MSE 0.00020593490626197308 lr:1.9635e-06,Time per Batch: 0.035 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 187/1000 finished. Total error: 0.012643 MSE: 0.0002856217324733734 Time per Epoch: 15.512\n",
      "Epoch 00187: reducing learning rate of group 0 to 1.3744e-06.r: 0.012642975896596909, Maximum Accuracy inf last MSE 0.0002856217324733734 Max MSE 0.00020593490626197308 lr:1.9635e-06,Time per Batch: 0.027 seconds     \n",
      "\n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 188/1000 finished. Total error: 0.016575 MSE: 0.00043540733167901635 Time per Epoch: 16.173\n",
      "  188/ 1000 //   295/  296 | Loss: 0.0001796, last_total_error: 0.016575295478105545, Maximum Accuracy inf last MSE 0.00043540733167901635 Max MSE 0.00020593490626197308 lr:1.9635e-06,Time per Batch: 0.035 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 189/1000 finished. Total error: 0.011495 MSE: 0.0002334663731744513 Time per Epoch: 16.324\n",
      "  189/ 1000 //   295/  296 | Loss: 8.821e-05, last_total_error: 0.011495433747768402, Maximum Accuracy inf last MSE 0.0002334663731744513 Max MSE 0.00020593490626197308 lr:1.3744e-06,Time per Batch: 0.026 seconds     \n",
      "SAVING MODEL\n",
      "\n",
      "Epoch 190/1000 finished. Total error: 0.012715 MSE: 0.0002820913796313107 Time per Epoch: 16.029\n",
      "  190/ 1000 //   147/  296 | Loss: 0.0001822, last_total_error: 0.012714875862002373, Maximum Accuracy inf last MSE 0.0002820913796313107 Max MSE 0.00020593490626197308 lr:1.3744e-06,Time per Batch: 0.088 seconds     \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m config\u001b[39m.\u001b[39mstart_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39misoformat()\n\u001b[0;32m     11\u001b[0m config\u001b[39m.\u001b[39msavename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbest_model_state_dict_at_for\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39mrun_name\u001b[39m}\u001b[39;00m\u001b[39m_stime_\u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39mstart_time\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m__acc_max_acc__auc_auc.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m train_eval_model(wandb\u001b[39m.\u001b[39;49mconfig,nadam\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[10], line 17\u001b[0m, in \u001b[0;36mtrain_eval_model\u001b[1;34m(config, adam, nadam)\u001b[0m\n\u001b[0;32m     15\u001b[0m outputs \u001b[39m=\u001b[39m model(sg)\n\u001b[0;32m     16\u001b[0m loss \u001b[39m=\u001b[39m lossfn(outputs,params)\n\u001b[1;32m---> 17\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     18\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39mif\u001b[39;00m adam \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     19\u001b[0m optimizer1\u001b[39m.\u001b[39mstep() \u001b[39mif\u001b[39;00m nadam \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:484\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    476\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    477\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    482\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    483\u001b[0m     )\n\u001b[1;32m--> 484\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    485\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    486\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb.init(project = \"simple_vision_transformer_regressor\")\n",
    "config = wandb.config\n",
    "config.run_name = wandb.run._run_id\n",
    "config = wandb.config\n",
    "config.epochs = 1000\n",
    "config.inx = 400\n",
    "config.iny = 400\n",
    "config.lr = startlr     \n",
    "config.best_model = OrderedDict()\n",
    "config.start_time = datetime.datetime.now().isoformat()\n",
    "config.savename = f\"best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__acc_max_acc__auc_auc.pt\"\n",
    "\n",
    "train_eval_model(wandb.config,nadam=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(config.best_model,\n",
    "           f\"./saved_models/ViT/best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}_BEST_MODEL.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
