{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from CoRe_Dataloader_From_Files_With_OvGN import (\n",
    "#     get_new_train_validation_test_datasets,\n",
    "#     get_new_train_validation_test_dataloaders,\n",
    "# )\n",
    "from CoRe_Dataloader_From_File_With_Random_From_Tensors import (\n",
    "    get_new_train_validation_test_datasets,\n",
    "    get_new_train_validation_test_dataloaders,\n",
    ")\n",
    "from CoRe_Dataloader_ECSG import dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "import torchinfo\n",
    "import time\n",
    "import numpy as np\n",
    "import wandb\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "from torch import autograd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as metrics\n",
    "import pandas as pd\n",
    "\n",
    "mae = metrics.MeanAbsoluteError()\n",
    "mse = metrics.MeanSquaredError()\n",
    "combined = metrics.MetricCollection(\n",
    "    [mae, mse, metrics.MeanAbsolutePercentageError(), metrics.MeanSquaredLogError()]\n",
    ")\n",
    "\n",
    "\n",
    "def get_df_from_rdict(rdict):\n",
    "    return pd.DataFrame(pd.Series(rdict).map(lambda x: x.cpu().item())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vit\n",
    "# import vit_pytorch\n",
    "from vit_pytorch import vit_for_small_dataset as vit_sd\n",
    "from vit_pytorch import vit as simple_vit\n",
    "from vit_pytorch.deepvit import DeepViT\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    # return simple_vit.ViT(image_size=400,\n",
    "    #                patch_size=20,\n",
    "    #                num_classes=19,\n",
    "    #                dim=int(1024/2),\n",
    "    #                depth=2,\n",
    "    #                heads=8,\n",
    "    #                mlp_dim=int(2048/2),\n",
    "    #                channels=1).to(\"cuda:0\")\n",
    "    # return vit_sd.ViT(image_size=400,\n",
    "    #                patch_size=20,\n",
    "    #                num_classes=19,\n",
    "    #                dim=1024,\n",
    "    #                depth=4,\n",
    "    #                heads=16,\n",
    "    #                mlp_dim=int(2048/2),\n",
    "    #                dropout = 0.1,\n",
    "    #                emb_dropout = 0,\n",
    "    #                channels=1).to(\"cuda:0\")\n",
    "    return DeepViT(\n",
    "        image_size=400,\n",
    "        patch_size=20,\n",
    "        num_classes=2,\n",
    "        dim=1024,\n",
    "        depth=4,\n",
    "        heads=16,\n",
    "        mlp_dim=int(2048 / 2),\n",
    "        dropout=0.1,\n",
    "        emb_dropout=0.1,\n",
    "        channels=1,\n",
    "    ).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumstring = \" \"\n",
    "\n",
    "\n",
    "def calc_metrics(model: torch.nn.Module, dl: DataLoader):\n",
    "    model.eval()\n",
    "    raw_output = []\n",
    "    parameters = []\n",
    "    with torch.no_grad():\n",
    "        for batch, (sg, params) in enumerate(dl):\n",
    "            sg = sg.to(\"cuda:0\").float()\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "\n",
    "            params = params[:, 1:3].to(\"cuda:0\")\n",
    "            raw_output.append(model(sg).detach().cpu())\n",
    "            parameters.append(params.cpu())\n",
    "            print(f\"{batch+1} / {len(dl)} { dumstring  * 20 }\", end=\"\\r\")\n",
    "    model.train()\n",
    "    output = torch.vstack(raw_output)\n",
    "    parameters = torch.concat(parameters, dim=0)\n",
    "    return combined(output.cpu(), parameters.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, testds = get_new_train_validation_test_datasets(0.1, 0.1)\n",
    "testdl = DataLoader(testds, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 253\n",
    "plt.imshow(testds[n][0].cpu())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(testds[n][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogCoshLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n",
    "\n",
    "\n",
    "class XTanhLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(ey_t * torch.tanh(ey_t))\n",
    "\n",
    "\n",
    "class XSigmoidLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, y_t, y_prime_t):\n",
    "        ey_t = y_t - y_prime_t\n",
    "        return torch.mean(2 * ey_t / (1 + torch.exp(-ey_t)) - ey_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "startlr = 3e-5\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=startlr)\n",
    "optimizer1 = optim.NAdam(params=model.parameters(), lr=startlr)\n",
    "step_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[1, 2, 3, 4], gamma=0.5\n",
    ")\n",
    "# at the end of 600 epochs, the learning rate is 0.000,002,62\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
    "scheduler_pl = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer, mode=\"max\", factor=0.7, patience=35, verbose=True\n",
    ")\n",
    "l1 = nn.L1Loss(reduction=\"sum\")\n",
    "l2 = nn.MSELoss(reduction=\"sum\")\n",
    "lcosh = LogCoshLoss()\n",
    "ltanh = XTanhLoss()\n",
    "xsig = XSigmoidLoss()\n",
    "lossfn = lambda x, y: l1(x, y) + l2(x, y) + lcosh(x, y) + ltanh(x, y) + xsig(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds(s):\n",
    "    return f\"{s//3600}H:{(s%3600)//60}M:{round(s%60,3)}S\"\n",
    "\n",
    "\n",
    "def ismult(n, div):\n",
    "    return bool(1 >> (n % div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(best_model, config, m1, m2, m1name=\"l1\", m2name=\"l2\"):\n",
    "    try:\n",
    "        torch.save(\n",
    "            best_model,\n",
    "            f\"./saved_models/ViT/WithNoise/best_model_state_dict_ViT_regressor_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__{m1name}_{m1}__{m2name}_{m2}.pt\",\n",
    "        )\n",
    "        print(\"\\nSAVING MODEL\")\n",
    "    except:\n",
    "        wandb.alert(level=\"warning\", title=\"OUT OF MEMORY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(config, train_dl, test_dl, adam=True, nadam=False):\n",
    "    min_mae, min_mse = float(\"inf\"), float(\"inf\")\n",
    "    ldl = len(train_dl)\n",
    "    results = pd.DataFrame()\n",
    "    best_model = OrderedDict()\n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        print(\"Pre-Evaluation Finished; Starting Training\")\n",
    "        etime = time.time()\n",
    "        for batch, (sg, params) in enumerate(train_dl):\n",
    "            stime = time.time()\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.to(\"cuda:0\").to(torch.float).view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "            params = params[:, 1:3].to(\"cuda:0\").to(torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sg)\n",
    "            loss = lossfn(outputs, params)\n",
    "            loss.backward()\n",
    "            optimizer.step() if adam else None\n",
    "            optimizer1.step() if nadam else None\n",
    "            #\n",
    "            torch.cuda.empty_cache()\n",
    "            #\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"loss\": loss.item(),\n",
    "                    \"batch_mae\": mae(outputs.to(\"cpu\"), params.to(\"cpu\")),\n",
    "                    \"batch_mse\": mse(outputs.to(\"cpu\"), params.to(\"cpu\")),\n",
    "                    \"lr\": scheduler.get_last_lr()[0],\n",
    "                    \"epoch\": epoch,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"{epoch:5}/{config.epochs:5} // {batch:5}/{ldl:5} | Loss: {loss.item():2.4},batch_mae:{mae(outputs.to('cpu'),params.to('cpu')):3.4}, lr:{scheduler.get_last_lr()[0]:1.5}, Time per Batch: {time.time()-stime:.3} seconds, Accumulated Time {to_seconds(round(time.time()-etime,3))}    \",\n",
    "                end=\"\\r\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "            if (batch - 1) % 5000 == 0:\n",
    "                epoch_results = calc_metrics(model, test_dl)\n",
    "                results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "                min_mae = min(results[\"MeanAbsoluteError\"])\n",
    "                min_mse = min(results[\"MeanSquaredError\"])\n",
    "                #\n",
    "                if epoch_results[\"MeanAbsoluteError\"] <= min_mae:\n",
    "                    best_model = model.state_dict()\n",
    "                    save_model(\n",
    "                        best_model,\n",
    "                        config,\n",
    "                        list(epoch_results.values())[0],\n",
    "                        list(epoch_results.values())[1],\n",
    "                    )\n",
    "\n",
    "                wandb.log(\n",
    "                    {\"epoch\": epoch, \"lr\": scheduler.get_last_lr()[0]}\n",
    "                    | epoch_results\n",
    "                    | {\"MinimumMAE\": min_mae, \"MinimumMSE\": min_mse}\n",
    "                    | {\"EpochTime\": time.time() - etime}\n",
    "                )\n",
    "        #\n",
    "        epoch_results = calc_metrics(model, test_dl)\n",
    "        results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "        #\n",
    "        min_mae = min(results[\"MeanAbsoluteError\"])\n",
    "        min_mse = min(results[\"MeanSquaredError\"])\n",
    "        #\n",
    "        scheduler.step()\n",
    "        step_scheduler.step()\n",
    "        scheduler_pl.step(min_mae)\n",
    "\n",
    "        if epoch_results[\"MeanAbsoluteError\"] <= min_mae:\n",
    "            best_model = model.state_dict()\n",
    "            save_model(\n",
    "                best_model,\n",
    "                config,\n",
    "                list(epoch_results.values())[0],\n",
    "                list(epoch_results.values())[1],\n",
    "            )\n",
    "        #\n",
    "\n",
    "        wandb.log(\n",
    "            {\"epoch\": epoch, \"lr\": scheduler.get_last_lr()[0]}\n",
    "            | epoch_results\n",
    "            | {\"MinimumMAE\": min_mae, \"MinimumMSE\": min_mse}\n",
    "            | {\"EpochTime\": time.time() - etime}\n",
    "        )\n",
    "\n",
    "    epoch_results = calc_metrics(model, test_dl)\n",
    "    results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "    return min_mae, min_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for training\n",
    "results = []\n",
    "trials = 1\n",
    "for i in range(trials):\n",
    "    wandb.init(\n",
    "        project=\"ViT-Regressor-With-Noise\",\n",
    "    )\n",
    "    config = wandb.config\n",
    "    config.run_name = wandb.run._run_id\n",
    "    config = wandb.config\n",
    "    config.epochs = 3\n",
    "    config.inx = 400\n",
    "    config.iny = 400\n",
    "    config.lr = startlr\n",
    "    config.trial = i + 1\n",
    "    config.total_trials = trials\n",
    "    config.best_model = OrderedDict()\n",
    "    config.start_time = datetime.datetime.now().isoformat()\n",
    "    config.savename = f\"best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__acc_max_acc__auc_auc.pt\"\n",
    "    train_dl, valid_dl, test_dl = get_new_train_validation_test_dataloaders()\n",
    "    train_eval_model(wandb.config, train_dl, valid_dl, nadam=True)\n",
    "    results.append(calc_metrics(model, test_dl))  # type: ignore\n",
    "    if i != (trials - 1):\n",
    "        model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    f\"./saved_models/ViT/WithNoise/best_model_state_dict_ViT_regressor_11_07_2023\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldl = test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "totout = []\n",
    "with torch.no_grad():\n",
    "    for batch, (sg, params) in enumerate(evaldl):\n",
    "        sg = sg.to(\"cuda:0\").to(torch.float)\n",
    "        sgsh = sg.shape\n",
    "        sg = sg.view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "        modelout = model(sg).detach().cpu()\n",
    "        params = params.to(\"cpu\").to(torch.float)\n",
    "        comb = torch.concat([modelout, params], dim=1)\n",
    "        print(comb[1], modelout[1], params[1])\n",
    "        print(batch, \"finished\")\n",
    "        totout.append(comb)\n",
    "model.train()\n",
    "print(len(totout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = torch.cat(totout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_params.numpy())\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        0: \"PM1\",\n",
    "        1: \"PM2\",\n",
    "        2: \"EOS\",\n",
    "        3: \"M1\",\n",
    "        4: \"M2\",\n",
    "        # 5: \"SHFT\",\n",
    "        5: \"SNR\"\n",
    "    }\n",
    ")\n",
    "df[\"combined\"] = df[\"M1\"] + df[\"M2\"]\n",
    "df[\"DiffM1\"] = abs(df[\"M1\"] - df[\"PM1\"])\n",
    "df[\"DiffM2\"] = abs(df[\"M2\"] - df[\"PM2\"])\n",
    "df[\"totDiff\"] = df[\"DiffM1\"] + df[\"DiffM2\"]\n",
    "df[\"avgDiff\"] = df[\"totDiff\"] / 2\n",
    "df.to_csv(\"results.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffhist = sns.histplot(df[\"avgDiff\"])\n",
    "diffhist.set(\n",
    "    title=\"Difference between predicted and actual masses\",\n",
    "    xlabel=\"Difference (solar masses)\",\n",
    "    ylabel=\"Count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df[\"combined\"], y=df[\"avgDiff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df[\"M1\"], y=df[\"DiffM1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=df[\"M2\"], y=df[\"DiffM2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sns.regplot(data = df, x = \"DiffM1\", y = \"DiffM2\")\n",
    "a.set(\n",
    "    title = \"Correalation betweeen the Difference in M1 and Difference in M2\",\n",
    "    xlabel = \"Difference in Mass 1\",\n",
    "    ylabel = \"Diference in Mass 2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temparray = pd.melt(\n",
    "    df[[\"SNR\", \"DiffM2\", \"DiffM1\", \"avgDiff\"]].rename(\n",
    "        columns={\n",
    "            \"SNR\": \"Signal to Noise Ratio\",\n",
    "            \"DiffM2\": \"Difference between predicted and actual for Mass 2\",\n",
    "            \"DiffM1\": \"Difference between predicted and actual for Mass 1\",\n",
    "            \"avgDiff\": \"Average Difference between predicted and actual for both masses\",\n",
    "        }\n",
    "    ),\n",
    "    id_vars=[\"Signal to Noise Ratio\"],\n",
    ")\n",
    "a = sns.lineplot(data=temparray, x=\"Signal to Noise Ratio\", y=\"value\", hue=\"variable\")\n",
    "a.set(\n",
    "    title=\"Difference between predicted and actual masses\",\n",
    "    xlabel=\"Signal to Noise Ratio\",\n",
    "    ylabel=\"Difference between predicted and actual (solar masses)\",\n",
    ")\n",
    "new_title = \"Legend:\"\n",
    "# replace labels\n",
    "plt.legend(title=\"Legend\", loc=\"upper right\")\n",
    "sns.set(rc={\"figure.figsize\": (16, 9)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sns.lineplot(\n",
    "    data=pd.melt(df[[\"combined\", \"DiffM2\", \"DiffM1\", \"avgDiff\"]], id_vars=[\"combined\"]),\n",
    "    x=\"combined\",\n",
    "    y=\"value\",\n",
    "    hue=\"variable\",\n",
    ")\n",
    "a.set(\n",
    "    title=\"Difference between predicted and actual masses\",\n",
    "    xlabel=\"Combined Mass (solar masses)\",\n",
    "    ylabel=\"Difference between predicted and actual (solar masses)\",\n",
    ")\n",
    "sns.set(rc={\"figure.figsize\": (16, 9)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sns.violinplot(x=df[\"EOS\"], y=df[\"avgDiff\"])\n",
    "a.set(\n",
    "    title=\"Difference between predicted and actual masses vs EOS\",\n",
    "    xlabel=\"Equation of State\",\n",
    "    ylabel=\"Difference between predicted and actual (solar masses)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temparray = pd.melt(\n",
    "    df[[\"SHFT\", \"DiffM2\", \"DiffM1\", \"avgDiff\"]].rename(\n",
    "        columns={\n",
    "            \"SHFT\": \"Left and Right Shift\",\n",
    "            \"DiffM2\": \"Difference between predicted and actual for Mass 2\",\n",
    "            \"DiffM1\": \"Difference between predicted and actual for Mass 1\",\n",
    "            \"avgDiff\": \"Average Difference between predicted and actual for both masses\",\n",
    "        }\n",
    "    ),\n",
    "    id_vars=[\"Left and Right Shift\"],\n",
    ")\n",
    "a = sns.lineplot(data=temparray, x=\"Left and Right Shift\", y=\"value\", hue=\"variable\")\n",
    "a.set(\n",
    "    title=\"Difference between predicted and actual masses\",\n",
    "    xlabel=\"Left and Right Shift\",\n",
    "    ylabel=\"Difference between predicted and actual (solar masses)\",\n",
    ")\n",
    "new_title = \"Legend:\"\n",
    "# replace labels\n",
    "plt.legend(title=\"Legend\", loc=\"upper right\")\n",
    "sns.set(rc={\"figure.figsize\": (16, 9)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(dataset.eosmap.items()):\n",
    "    print(i[0], i[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
