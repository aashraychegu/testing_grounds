{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sinexpDL import *\n",
    "from torch.utils.data import DataLoader\n",
    "runnum = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where the actual ML algo starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import LeakyReLU\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Tanh\n",
    "from torch.nn import Sigmoid\n",
    "from torch import flatten\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorOld(nn.Module):\n",
    "    def __init__(self, latent_dim=100, batchnorm=True):\n",
    "        super(GeneratorOld, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batchnorm = batchnorm\n",
    "        # first set of CONVT => RELU => BN\n",
    "        self.linear1 = nn.Linear(self.latent_dim, 256*7*7, bias=False)\n",
    "        self.bn1d1 = nn.BatchNorm1d(256*7*7) if self.batchnorm else None\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "        # Convolutions\n",
    "        self.conv1 = nn.ConvTranspose2d(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "                bias=False)\n",
    "        self.bn2d1 = nn.BatchNorm2d(128) if self.batchnorm else None\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False)\n",
    "        self.bn2d2 = nn.BatchNorm2d(64) if self.batchnorm else None\n",
    "\n",
    "        self.conv2dot5 = nn.ConvTranspose2d(\n",
    "                in_channels=64,\n",
    "                out_channels=32,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False)\n",
    "        self.bn2d2dot5 = nn.BatchNorm2d(32) if self.batchnorm else None\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(\n",
    "                in_channels=32,\n",
    "                out_channels=16,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "        )\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=1,\n",
    "            kernel_size=2,\n",
    "            padding=1\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"Forward pass; map latent vectors to samples.\"\"\"\n",
    "        intermediate = self.linear1(input_tensor)\n",
    "        intermediate = self.bn1d1(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = intermediate.view((-1, 256, 7, 7))\n",
    "\n",
    "        intermediate = self.conv1(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d1(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv2(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d2(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv2dot5(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d2dot5(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv3(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.conv4(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.conv5(intermediate)\n",
    "        output_tensor = self.sigmoid(intermediate)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"A discriminator for discerning real from generated images.\n",
    "        Images must be single-channel and 28x28 pixels.\n",
    "        Output activation is Sigmoid.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self._init_modules()\n",
    "\n",
    "    def _init_modules(self):\n",
    "        \"\"\"Initialize the modules.\"\"\"\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=64,\n",
    "                kernel_size=5,\n",
    "                stride=2,\n",
    "                padding=2,\n",
    "                bias=True)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "        self.dropout_2d = nn.Dropout2d(0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=5,\n",
    "                stride=2,\n",
    "                padding=2,\n",
    "                bias=True)\n",
    "\n",
    "        self.linear1 = nn.Linear(128*16*16, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"Forward pass; map samples to confidence they are real [0, 1].\"\"\"\n",
    "        # print(input_tensor.shape)\n",
    "        intermediate = self.conv1(input_tensor)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.dropout_2d(intermediate)\n",
    "        # print(intermediate.shape)\n",
    "        intermediate = self.conv2(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.dropout_2d(intermediate)\n",
    "        # print(intermediate.shape)\n",
    "        intermediate = intermediate.view((-1, 128*16*16))\n",
    "        # print(intermediate.shape)\n",
    "        intermediate = self.linear1(intermediate)\n",
    "        output_tensor = self.sigmoid(intermediate)\n",
    "        # print(output_tensor.shape,\"\\n\")\n",
    "\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu,latent_dim = 1,ngf = 64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # turns the 'interesting and 'informative' ' 2 parameters into slightly more informative 128 parameters\n",
    "        self.lin1 = nn.Linear(latent_dim, 128)\n",
    "        self.lin2 = nn.Linear(128, (ngf*16)*16*16)\n",
    "        # input is Z, going into a convolution\n",
    "        self.btn0 = nn.BatchNorm2d(ngf*16)\n",
    "        self.ctp1 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf*16,\n",
    "            out_channels=ngf * 8,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.btn1 = nn.BatchNorm2d(ngf * 8)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        # state size. (ngf*8) x 4 x 4\n",
    "        self.ctp2 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf * 8,\n",
    "            out_channels=ngf * 4,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.btn2 = nn.BatchNorm2d(ngf * 4)\n",
    "        # nn.ReLU(True),\n",
    "        # state size. (ngf*4) x 8 x 8\n",
    "        self.ctp3 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf * 4,\n",
    "            out_channels=ngf * 2,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.btn3 = nn.BatchNorm2d(ngf * 2)\n",
    "        # state size. (ngf*2) x 16 x 16\n",
    "        self.ctp4 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf * 2,\n",
    "            out_channels=ngf,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.btn4 = nn.BatchNorm2d(ngf)\n",
    "        # state size. (ngf) x 32 x 32\n",
    "        self.ctp5 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf,\n",
    "            out_channels=1,\n",
    "            kernel_size=4,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.tanh = nn.Tanh()\n",
    "        # state size. (nc) x 64 x 64\n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp = inp.to(self.device).float() \n",
    "        # print(f\"IN {inp.shape = }\")\n",
    "        inm = self.lin1(inp)\n",
    "        # print(f\"T1 {inm.shape = }\")\n",
    "        inm = self.relu(inm)\n",
    "        inm = self.lin2(inm)\n",
    "        # print(f\"T2 {inm.shape = }\")\n",
    "        inm = self.relu(inm)\n",
    "        inm = inm.view((-1, 64*16, 16, 16))\n",
    "        # print(f\"RV {inm.shape = }\")\n",
    "\n",
    "        inm = self.ctp1(inm)\n",
    "        inm = self.btn1(inm)\n",
    "        inm = self.relu(inm)\n",
    "        # print(f\"C1 {inm.shape = }\")\n",
    "\n",
    "        inm = self.ctp2(inm)\n",
    "        inm = self.btn2(inm)\n",
    "        inm = self.relu(inm)\n",
    "        # print(f\"C2 {inm.shape = }\")\n",
    "\n",
    "        inm = self.ctp3(inm)\n",
    "        inm = self.btn3(inm)\n",
    "        inm = self.relu(inm)\n",
    "        # print(f\"C3 {inm.shape = }\")\n",
    "\n",
    "        inm = self.ctp4(inm)\n",
    "        inm = self.btn4(inm)\n",
    "        inm = self.relu(inm)\n",
    "        # print(f\"C4 {inm.shape = }\")\n",
    "\n",
    "        inm = self.ctp5(inm)\n",
    "        fin = self.relu(inm)\n",
    "        # print(f\"OT {fin.shape = }\",\"\\n\")\n",
    "        return fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self, latent_dim, noise_fn, dataloader,\n",
    "                 batch_size=32, device='cpu', lr_d=1e-3, lr_g=2e-4):\n",
    "        \"\"\"A very basic DCGAN class for generating MNIST digits\n",
    "        Args:\n",
    "            generator: a Ganerator network\n",
    "            discriminator: A Discriminator network\n",
    "            noise_fn: function f(num: int) -> pytorch tensor, (latent vectors)\n",
    "            dataloader: a pytorch dataloader for loading images\n",
    "            batch_size: training batch size. Must match that of dataloader\n",
    "            device: cpu or CUDA\n",
    "            lr_d: learning rate for the discriminator\n",
    "            lr_g: learning rate for the generator\n",
    "        \"\"\"\n",
    "        self.generator = Generator(latent_dim).to(device)\n",
    "        self.discriminator = Discriminator().to(device)\n",
    "        self.noise_fn = noise_fn\n",
    "        self.dataloader = dataloader\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optim_d = optim.Adam(self.discriminator.parameters(),\n",
    "                                  lr=lr_d, betas=(0.5, 0.999))\n",
    "        self.optim_g = optim.Adam(self.generator.parameters(),\n",
    "                                  lr=lr_g, betas=(0.5, 0.999))\n",
    "        self.target_ones = torch.ones((batch_size, 1), device=device)\n",
    "        self.target_zeros = torch.zeros((batch_size, 1), device=device)\n",
    "\n",
    "    def generate_samples(self, latent_vec=None, num=None):\n",
    "        \"\"\"Sample images from the generator.\n",
    "        Images are returned as a 4D tensor of values between -1 and 1.\n",
    "        Dimensions are (number, channels, height, width). Returns the tensor\n",
    "        on cpu.\n",
    "        Args:\n",
    "            latent_vec: A pytorch latent vector or None\n",
    "            num: The number of samples to generate if latent_vec is None\n",
    "        If latent_vec and num are None then use self.batch_size\n",
    "        random latent vectors.\n",
    "        \"\"\"\n",
    "        num = self.batch_size if num is None else num\n",
    "        latent_vec = self.noise_fn(num) if latent_vec is None else latent_vec\n",
    "        with torch.no_grad():\n",
    "            samples = self.generator(latent_vec)\n",
    "        samples = samples.cpu()  # move images to cpu\n",
    "        return samples,latent_vec\n",
    "\n",
    "    def train_step_generator(self):\n",
    "        \"\"\"Train the generator one step and return the loss.\"\"\"\n",
    "        self.generator.zero_grad()\n",
    "\n",
    "        latent_vec = self.noise_fn(self.batch_size)\n",
    "        generated = self.generator(latent_vec)\n",
    "        classifications = self.discriminator(generated)\n",
    "        loss = self.criterion(classifications, self.target_ones)\n",
    "        loss.backward()\n",
    "        self.optim_g.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def train_step_discriminator(self, real_samples):\n",
    "        \"\"\"Train the discriminator one step and return the losses.\"\"\"\n",
    "        local_batch_size = real_samples.shape[0]\n",
    "        target_ones = torch.ones((local_batch_size, 1), device=self.device)\n",
    "        target_zeros = torch.zeros(\n",
    "            (local_batch_size, 1), device=self.device)\n",
    "        \n",
    "        self.discriminator.zero_grad()\n",
    "        # real samples\n",
    "        pred_real = self.discriminator(real_samples)\n",
    "        # print(real_samples.shape, pred_real.shape,target_ones.shape)\n",
    "        loss_real = self.criterion(pred_real, target_ones)\n",
    "        \n",
    "        # generated samples\n",
    "        latent_vec = self.noise_fn(local_batch_size)\n",
    "        with torch.no_grad():\n",
    "            fake_samples = self.generator(latent_vec)\n",
    "        # print(f\"{fake_samples.shape = }\")\n",
    "        pred_fake = self.discriminator(fake_samples)\n",
    "        loss_fake = self.criterion(pred_fake, target_zeros)\n",
    "        \n",
    "        # combine\n",
    "        loss = (loss_real + loss_fake) / 2\n",
    "        loss.backward()\n",
    "        self.optim_d.step()\n",
    "        return loss_real.item(), loss_fake.item()\n",
    "\n",
    "    def train_epoch(self, print_frequency=10, max_steps=0):\n",
    "        \"\"\"Train both networks for one epoch and return the losses.\n",
    "        Args:\n",
    "            print_frequency (int): print stats every `print_frequency` steps.\n",
    "            max_steps (int): End epoch after `max_steps` steps, or set to 0\n",
    "                             to do the full epoch.\n",
    "        \"\"\"\n",
    "        loss_g_running, loss_d_real_running, loss_d_fake_running = 0, 0, 0\n",
    "        for batch, real_samples in enumerate(self.dataloader):\n",
    "            real_samples = real_samples.to(self.device)\n",
    "            ldr_, ldf_ = self.train_step_discriminator(real_samples)\n",
    "            loss_d_real_running += ldr_\n",
    "            loss_d_fake_running += ldf_\n",
    "            loss_g_running += self.train_step_generator()\n",
    "            if print_frequency and (batch+1) % print_frequency == 0:\n",
    "                print(f\"{batch+1}/{len(self.dataloader)}:\"\n",
    "                      f\" G={loss_g_running / (batch+1):.3f},\"\n",
    "                      f\" Dr={loss_d_real_running / (batch+1):.3f},\"\n",
    "                      f\" Df={loss_d_fake_running / (batch+1):.3f}\",\n",
    "                      end='\\r',\n",
    "                      flush=True)\n",
    "            if max_steps and batch == max_steps:\n",
    "                break\n",
    "        if print_frequency:\n",
    "            print()\n",
    "        loss_g_running /= batch\n",
    "        loss_d_real_running /= batch\n",
    "        loss_d_fake_running /= batch\n",
    "        return (loss_g_running, (loss_d_real_running, loss_d_fake_running))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnum += 1\n",
    "print(runnum)\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "batch_size = 16\n",
    "latent_dim = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "end,step = 30000, 1/5000\n",
    "expend = end*step\n",
    "dataloader = DataLoader(specGds(100000,1/30000,.5),\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,drop_last=False\n",
    "                        )\n",
    "\n",
    "\n",
    "def noise_fn(x): return torch.abs(torch.randn((x, latent_dim), device=device)*expend)\n",
    "gan = DCGAN(latent_dim, noise_fn, dataloader,device=device, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "epochs = 20\n",
    "prevlapsed = start\n",
    "for i in range(epochs):\n",
    "    gan.train_epoch()\n",
    "    ctime = time()\n",
    "    print(f\"Epoch {i+1}; Elapsed time = {int(ctime - start)}s / {int(ctime - start)/60} minutes; Time for this epoch: {ctime-prevlapsed}s / {(ctime-prevlapsed)/60} minutes;\")\n",
    "    prevlapsed = ctime\n",
    "\n",
    "images,vec = gan.generate_samples()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"module://matplotlib_inline.backend_inline\")\n",
    "for i,v in zip(images,vec):\n",
    "    print(v,\":\")\n",
    "    plot_sg(i[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"module://matplotlib_inline.backend_inline\")\n",
    "images = gan.generate_samples()\n",
    "print(images.shape)\n",
    "for i in images:\n",
    "    plot_sg(i[0])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
