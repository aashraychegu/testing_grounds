{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sinexpDL import *\n",
    "runnum = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where the actual ML algo starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import LeakyReLU\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Tanh\n",
    "from torch.nn import Sigmoid\n",
    "from torch import flatten\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorOld(nn.Module):\n",
    "    def __init__(self, latent_dim=100, batchnorm=True):\n",
    "        super(GeneratorOld, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batchnorm = batchnorm\n",
    "        # first set of CONVT => RELU => BN\n",
    "        self.linear1 = nn.Linear(self.latent_dim, 256*7*7, bias=False)\n",
    "        self.bn1d1 = nn.BatchNorm1d(256*7*7) if self.batchnorm else None\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "        # Convolutions\n",
    "        self.conv1 = nn.ConvTranspose2d(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "                bias=False)\n",
    "        self.bn2d1 = nn.BatchNorm2d(128) if self.batchnorm else None\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False)\n",
    "        self.bn2d2 = nn.BatchNorm2d(64) if self.batchnorm else None\n",
    "\n",
    "        self.conv2dot5 = nn.ConvTranspose2d(\n",
    "                in_channels=64,\n",
    "                out_channels=32,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False)\n",
    "        self.bn2d2dot5 = nn.BatchNorm2d(32) if self.batchnorm else None\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(\n",
    "                in_channels=32,\n",
    "                out_channels=16,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=8,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "        )\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=1,\n",
    "            kernel_size=2,\n",
    "            padding=1\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"Forward pass; map latent vectors to samples.\"\"\"\n",
    "        intermediate = self.linear1(input_tensor)\n",
    "        intermediate = self.bn1d1(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = intermediate.view((-1, 256, 7, 7))\n",
    "\n",
    "        intermediate = self.conv1(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d1(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv2(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d2(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv2dot5(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d2dot5(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv3(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.conv4(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.conv5(intermediate)\n",
    "        output_tensor = self.sigmoid(intermediate)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"A discriminator for discerning real from generated images.\n",
    "        Images must be single-channel and 28x28 pixels.\n",
    "        Output activation is Sigmoid.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self._init_modules()\n",
    "\n",
    "    def _init_modules(self):\n",
    "        \"\"\"Initialize the modules.\"\"\"\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=64,\n",
    "                kernel_size=5,\n",
    "                stride=2,\n",
    "                padding=2,\n",
    "                bias=True)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "        self.dropout_2d = nn.Dropout2d(0.4)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=5,\n",
    "                stride=2,\n",
    "                padding=2,\n",
    "                bias=True)\n",
    "\n",
    "        self.linear1 = nn.Linear(128*16*16, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"Forward pass; map samples to confidence they are real [0, 1].\"\"\"\n",
    "        # print(input_tensor.shape)\n",
    "        intermediate = self.conv1(input_tensor)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.dropout_2d(intermediate)\n",
    "        # print(intermediate.shape)\n",
    "        intermediate = self.conv2(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.dropout_2d(intermediate)\n",
    "        # print(intermediate.shape)\n",
    "        intermediate = intermediate.view((-1, 128*16*16))\n",
    "        # print(intermediate.shape)\n",
    "        intermediate = self.linear1(intermediate)\n",
    "        output_tensor = self.sigmoid(intermediate)\n",
    "        # print(output_tensor.shape,\"\\n\")\n",
    "\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu,latent_dim = 1,ngf = 64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # turns the 'interesting and 'informative' ' 2 parameters into slightly more informative 128 parameters\n",
    "        self.lin1 = nn.Linear(latent_dim, 128)\n",
    "        self.lin2 = nn.Linear(128, (ngf*16)*16*16)\n",
    "        # input is Z, going into a convolution\n",
    "        self.btn0 = nn.BatchNorm2d(ngf*16)\n",
    "        self.ctp1 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf*16,\n",
    "            out_channels=ngf * 8,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.btn1 = nn.BatchNorm2d(ngf * 8)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        # state size. (ngf*8) x 4 x 4\n",
    "        self.ctp2 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf * 8,\n",
    "            out_channels=ngf * 4,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.btn2 = nn.BatchNorm2d(ngf * 4)\n",
    "        # nn.ReLU(True),\n",
    "        # state size. (ngf*4) x 8 x 8\n",
    "        self.ctp3 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf * 4,\n",
    "            out_channels=ngf * 2,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.btn3 = nn.BatchNorm2d(ngf * 2)\n",
    "        # state size. (ngf*2) x 16 x 16\n",
    "        self.ctp4 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf * 2,\n",
    "            out_channels=ngf,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.btn4 = nn.BatchNorm2d(ngf)\n",
    "        # state size. (ngf) x 32 x 32\n",
    "        self.ctp5 = nn.ConvTranspose2d(\n",
    "            in_channels=ngf,\n",
    "            out_channels=1,\n",
    "            kernel_size=4,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.tanh = nn.Tanh()\n",
    "        # state size. (nc) x 64 x 64\n",
    "\n",
    "    def forward(self, inp):\n",
    "        inp = inp.to(self.device).float() \n",
    "        # print(f\"IN {inp.shape = }\")\n",
    "        inm = self.lin1(inp)\n",
    "        # print(f\"T1 {inm.shape = }\")\n",
    "        inm = self.relu(inm)\n",
    "        inm = self.lin2(inm)\n",
    "        # print(f\"T2 {inm.shape = }\")\n",
    "        inm = self.relu(inm)\n",
    "        inm = inm.view((-1, 64*16, 16, 16))\n",
    "        # print(f\"RV {inm.shape = }\")\n",
    "\n",
    "        inm = self.ctp1(inm)\n",
    "        inm = self.btn1(inm)\n",
    "        inm = self.relu(inm)\n",
    "        # print(f\"C1 {inm.shape = }\")\n",
    "\n",
    "        inm = self.ctp2(inm)\n",
    "        inm = self.btn2(inm)\n",
    "        inm = self.relu(inm)\n",
    "        # print(f\"C2 {inm.shape = }\")\n",
    "\n",
    "        inm = self.ctp3(inm)\n",
    "        inm = self.btn3(inm)\n",
    "        inm = self.relu(inm)\n",
    "        # print(f\"C3 {inm.shape = }\")\n",
    "\n",
    "        inm = self.ctp4(inm)\n",
    "        inm = self.btn4(inm)\n",
    "        inm = self.relu(inm)\n",
    "        # print(f\"C4 {inm.shape = }\")\n",
    "\n",
    "        inm = self.ctp5(inm)\n",
    "        fin = self.relu(inm)\n",
    "        # print(f\"OT {fin.shape = }\",\"\\n\")\n",
    "        return fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self, latent_dim, noise_fn, dataloader,\n",
    "                 batch_size=32, device='cpu', lr_d=1e-3, lr_g=2e-4):\n",
    "        \"\"\"A very basic DCGAN class for generating MNIST digits\n",
    "        Args:\n",
    "            generator: a Ganerator network\n",
    "            discriminator: A Discriminator network\n",
    "            noise_fn: function f(num: int) -> pytorch tensor, (latent vectors)\n",
    "            dataloader: a pytorch dataloader for loading images\n",
    "            batch_size: training batch size. Must match that of dataloader\n",
    "            device: cpu or CUDA\n",
    "            lr_d: learning rate for the discriminator\n",
    "            lr_g: learning rate for the generator\n",
    "        \"\"\"\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.generator = Generator(latent_dim).to(device)\n",
    "        self.discriminator = Discriminator().to(device)\n",
    "        self.noise_fn = noise_fn\n",
    "        self.dataloader = dataloader\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optim_d = optim.Adam(self.discriminator.parameters(),\n",
    "                                  lr=lr_d, betas=(0.5, 0.999))\n",
    "        self.optim_g = optim.Adam(self.generator.parameters(),\n",
    "                                  lr=lr_g, betas=(0.5, 0.999))\n",
    "        self.target_ones = torch.ones((batch_size, 1), device=device)\n",
    "        self.target_zeros = torch.zeros((batch_size, 1), device=device)\n",
    "\n",
    "    def generate_samples(self, latent_vec=None, num=None):\n",
    "        \"\"\"Sample images from the generator.\n",
    "        Images are returned as a 4D tensor of values between -1 and 1.\n",
    "        Dimensions are (number, channels, height, width). Returns the tensor\n",
    "        on cpu.\n",
    "        Args:\n",
    "            latent_vec: A pytorch latent vector or None\n",
    "            num: The number of samples to generate if latent_vec is None\n",
    "        If latent_vec and num are None then use self.batch_size\n",
    "        random latent vectors.\n",
    "        \"\"\"\n",
    "        num = self.batch_size if num is None else num\n",
    "        latent_vec = self.noise_fn(num) if latent_vec is None else latent_vec\n",
    "        with torch.no_grad():\n",
    "            samples = self.generator(latent_vec)\n",
    "        samples = samples.cpu()  # move images to cpu\n",
    "        return samples,latent_vec\n",
    "\n",
    "    def train_step_generator(self):\n",
    "        \"\"\"Train the generator one step and return the loss.\"\"\"\n",
    "        self.generator.zero_grad()\n",
    "\n",
    "        latent_vec = self.noise_fn(self.batch_size)\n",
    "        generated = self.generator(latent_vec)\n",
    "        classifications = self.discriminator(generated)\n",
    "        loss = self.criterion(classifications, self.target_ones)\n",
    "        loss.backward()\n",
    "        self.optim_g.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def train_step_discriminator(self, real_samples):\n",
    "        \"\"\"Train the discriminator one step and return the losses.\"\"\"\n",
    "        local_batch_size = real_samples.shape[0]\n",
    "        target_ones = torch.ones((local_batch_size, 1), device=self.device)\n",
    "        target_zeros = torch.zeros(\n",
    "            (local_batch_size, 1), device=self.device)\n",
    "        \n",
    "        self.discriminator.zero_grad()\n",
    "        # real samples\n",
    "        pred_real = self.discriminator(real_samples)\n",
    "        # print(real_samples.shape, pred_real.shape,target_ones.shape)\n",
    "        loss_real = self.criterion(pred_real, target_ones)\n",
    "        \n",
    "        # generated samples\n",
    "        latent_vec = self.noise_fn(local_batch_size)\n",
    "        with torch.no_grad():\n",
    "            fake_samples = self.generator(latent_vec)\n",
    "        # print(f\"{fake_samples.shape = }\")\n",
    "        pred_fake = self.discriminator(fake_samples)\n",
    "        loss_fake = self.criterion(pred_fake, target_zeros)\n",
    "        \n",
    "        # combine\n",
    "        loss = (loss_real + loss_fake) / 2\n",
    "        loss.backward()\n",
    "        self.optim_d.step()\n",
    "        return loss_real.item(), loss_fake.item()\n",
    "\n",
    "    def train_epoch(self, print_frequency=10, max_steps=0):\n",
    "        \"\"\"Train both networks for one epoch and return the losses.\n",
    "        Args:\n",
    "            print_frequency (int): print stats every `print_frequency` steps.\n",
    "            max_steps (int): End epoch after `max_steps` steps, or set to 0\n",
    "                             to do the full epoch.\n",
    "        \"\"\"\n",
    "        loss_g_running, loss_d_real_running, loss_d_fake_running = 0, 0, 0\n",
    "        for batch, real_samples in enumerate(self.dataloader):\n",
    "            real_samples = real_samples.to(self.device)\n",
    "\n",
    "            #! This is the important step\n",
    "            ldr_, ldf_ = self.train_step_discriminator(real_samples)\n",
    "            loss_g_running += self.train_step_generator()\n",
    "            \n",
    "            loss_d_real_running += ldr_\n",
    "            loss_d_fake_running += ldf_\n",
    "            print(f\"{batch+1}/{len(self.dataloader)}:\"\n",
    "                  f\" G={loss_g_running / (batch+1):.3f},\"\n",
    "                  f\" Dr={loss_d_real_running / (batch+1):.3f},\"\n",
    "                  f\" Df={loss_d_fake_running / (batch+1):.3f}\",\n",
    "                  end='\\r',\n",
    "                  flush=True)\n",
    "        if print_frequency:\n",
    "            print()\n",
    "            \n",
    "        loss_g_running /= batch\n",
    "        loss_d_real_running /= batch\n",
    "        loss_d_fake_running /= batch\n",
    "        return (loss_g_running, (loss_d_real_running, loss_d_fake_running))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnum += 1\n",
    "print(runnum)\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "batch_size = 16\n",
    "latent_dim = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "pstart = 1\n",
    "pend = 2\n",
    "ds = specGds(\"cuda:0\", pstart, pend)\n",
    "dataloader = DataLoader(ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "                                            \n",
    "\n",
    "def noise_fn(x):\n",
    "    return torch.abs(torch.normal(mean = (pstart+pend)/2, std = (pend - pstart)/8, size = (x,latent_dim)))\n",
    "\n",
    "\n",
    "gan = DCGAN(latent_dim, noise_fn, dataloader, device=device, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "epochs = 1\n",
    "prevlapsed = start\n",
    "for i in range(epochs):\n",
    "    gan.train_epoch()\n",
    "    ctime = time()\n",
    "    print(f\"Epoch {i+1}; Elapsed time = {int(ctime - start)}s / {int(ctime - start)/60} minutes; Time for this epoch: {ctime-prevlapsed}s / {(ctime-prevlapsed)/60} minutes;\")\n",
    "    prevlapsed = ctime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7200])\n",
      "tensor([1.2971])\n",
      "tensor([1.6664])\n",
      "tensor([1.3158])\n",
      "tensor([1.4864])\n",
      "tensor([1.6761])\n",
      "tensor([1.6438])\n",
      "tensor([2.1675])\n",
      "tensor([1.8424])\n",
      "tensor([1.3766])\n",
      "tensor([1.2620])\n",
      "tensor([1.6931])\n",
      "tensor([1.6717])\n",
      "tensor([1.0396])\n",
      "tensor([0.8918])\n",
      "tensor([1.4124])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images,vec = gan.generate_samples()\n",
    "for i,v in zip(images,vec):\n",
    "    print(v)\n",
    "    plt.pcolormesh(i[0].cpu().detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
