{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fft\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_data(expmod = 1.0,len_in_pis = 3,return_values=False):\n",
    "    start = int(np.random.uniform(0, 200))\n",
    "    end = start + int(np.pi*1000*len_in_pis)\n",
    "    x = np.arange(start,end)/1000\n",
    "    y = np.sin(np.expm1(x)*expmod)\n",
    "    if return_values:\n",
    "        return y, start, end\n",
    "    return y\n",
    "data = None\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(rand_data())\n",
    "# for i in range(0,20):\n",
    "#     data = rand_data(expmod=i/5)\n",
    "runnum = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "print(mp.get_backend())\n",
    "%matplotlib inline\n",
    "# f, t, Sxx = signal.spectrogram(data,)\n",
    "# plt.pcolormesh(t, fftshift(f), fftshift(Sxx, axes=0))\n",
    "# for i in range(1,5):    \n",
    "#     print(i)\n",
    "#     data = data + rand_data(i/1)\n",
    "data = rand_data(0.5,len_in_pis=3)\n",
    "plt.switch_backend(\"module://matplotlib_inline.backend_inline\")\n",
    "powerSpectrum, frequenciesFound, time, imageAxis = plt.specgram(data,NFFT=256*2,noverlap = 190,sides=\"onesided\",pad_to=54)\n",
    "plt.show()\n",
    "print(f\"{time.shape[0] = } | {frequenciesFound.shape[0] = } | {powerSpectrum.shape = }\")\n",
    "plt.pcolormesh(powerSpectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_sg(a,b):\n",
    "    data = rand_data(a,len_in_pis=b)\n",
    "    plt.switch_backend(\"agg\")\n",
    "    powerSpectrum, frequenciesFound, time, _ = plt.specgram(\n",
    "        data, NFFT=256*2, noverlap=190, sides=\"onesided\", pad_to=54)\n",
    "    return powerSpectrum\n",
    "def plot_sg(data):\n",
    "    plt.pcolormesh(data)\n",
    "    plt.xlim(0,data.shape[0])\n",
    "    # plt.colorbar(plt.gca().get_cmap(\"\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import datasets\n",
    "# from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class specGds(Dataset):\n",
    "    def __init__(self,num_samples:int,scale_factor:float,numpis = 3):\n",
    "        self.slist = np.arange(1,num_samples+1,1,dtype=np.float64)\n",
    "        self.slist *= scale_factor\n",
    "        self.numpis = numpis\n",
    "        print(self.__str__())\n",
    "    def __len__(self):\n",
    "        return len(self.slist)\n",
    "    def __getitem__(self, index):\n",
    "        np.random.seed(index)\n",
    "        return torch.tensor(return_sg(self.slist[index], self.numpis), dtype=torch.float).view((1, 28, 28))\n",
    "    def plotitem(self,index):\n",
    "        plt.switch_backend(\"module://matplotlib_inline.backend_inline\")\n",
    "        plot_sg(self.__getitem__(index)[0])\n",
    "        plt.show()\n",
    "    def __str__(self) -> str:\n",
    "        return f\"{self.slist.shape = } | {self.numpis = } | {self.__len__() = }\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = specGds(1000,1/3000)\n",
    "data.plotitem(1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(specGds(10000,1/3000),shuffle = True, batch_size=32)\n",
    "plt.switch_backend(\"module://matplotlib_inline.backend_inline\")\n",
    "a = next(iter(dl))\n",
    "print(a.shape)\n",
    "del plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"module://matplotlib_inline.backend_inline\")\n",
    "plt.pcolormesh(a[0][0])\n",
    "plt.plot()\n",
    "# x = a.view((32,1,28,28))\n",
    "# print(x.shape,x[0][0].shape)\n",
    "# plt.pcolormesh(x[0][0])\n",
    "# plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import LeakyReLU\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Tanh\n",
    "from torch.nn import Sigmoid\n",
    "from torch import flatten\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, batchnorm=True):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batchnorm = batchnorm\n",
    "        # first set of CONVT => RELU => BN\n",
    "        self.linear1 = nn.Linear(self.latent_dim, 256*7*7, bias=False)\n",
    "        self.bn1d1 = nn.BatchNorm1d(256*7*7) if self.batchnorm else None\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "        # Convolutions\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "                bias=False)\n",
    "        self.bn2d1 = nn.BatchNorm2d(128) if self.batchnorm else None\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False)\n",
    "        self.bn2d2 = nn.BatchNorm2d(64) if self.batchnorm else None\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(\n",
    "                in_channels=64,\n",
    "                out_channels=1,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"Forward pass; map latent vectors to samples.\"\"\"\n",
    "        intermediate = self.linear1(input_tensor)\n",
    "        intermediate = self.bn1d1(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = intermediate.view((-1, 256, 7, 7))\n",
    "\n",
    "        intermediate = self.conv1(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d1(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv2(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d2(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv3(intermediate)\n",
    "        output_tensor = self.tanh(intermediate)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"A discriminator for discerning real from generated images.\n",
    "        Images must be single-channel and 28x28 pixels.\n",
    "        Output activation is Sigmoid.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        \"\"\"Initialize the modules.\"\"\"\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=64,\n",
    "            kernel_size=5,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            bias=True)\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "        self.dropout_2d = nn.Dropout2d(0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=128,\n",
    "            kernel_size=5,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            bias=True)\n",
    "\n",
    "        self.linear1 = nn.Linear(128*7*7, 1, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"Forward pass; map samples to confidence they are real [0, 1].\"\"\"\n",
    "        intermediate = self.conv1(input_tensor)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.dropout_2d(intermediate)\n",
    "\n",
    "        intermediate = self.conv2(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.dropout_2d(intermediate)\n",
    "\n",
    "        intermediate = intermediate.view((-1, 128*7*7))\n",
    "        intermediate = self.linear1(intermediate)\n",
    "        output_tensor = self.sigmoid(intermediate)\n",
    "\n",
    "        return output_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self, latent_dim, noise_fn, dataloader,\n",
    "                 batch_size=32, device='cpu', lr_d=1e-3, lr_g=2e-4):\n",
    "        \"\"\"A very basic DCGAN class for generating MNIST digits\n",
    "        Args:\n",
    "            generator: a Ganerator network\n",
    "            discriminator: A Discriminator network\n",
    "            noise_fn: function f(num: int) -> pytorch tensor, (latent vectors)\n",
    "            dataloader: a pytorch dataloader for loading images\n",
    "            batch_size: training batch size. Must match that of dataloader\n",
    "            device: cpu or CUDA\n",
    "            lr_d: learning rate for the discriminator\n",
    "            lr_g: learning rate for the generator\n",
    "        \"\"\"\n",
    "        self.generator = Generator(latent_dim).to(device)\n",
    "        self.discriminator = Discriminator().to(device)\n",
    "        self.noise_fn = noise_fn\n",
    "        self.dataloader = dataloader\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optim_d = optim.Adam(self.discriminator.parameters(),\n",
    "                                  lr=lr_d, betas=(0.5, 0.999))\n",
    "        self.optim_g = optim.Adam(self.generator.parameters(),\n",
    "                                  lr=lr_g, betas=(0.5, 0.999))\n",
    "        self.target_ones = torch.ones((batch_size, 1), device=device)\n",
    "        self.target_zeros = torch.zeros((batch_size, 1), device=device)\n",
    "\n",
    "    def generate_samples(self, latent_vec=None, num=None):\n",
    "        \"\"\"Sample images from the generator.\n",
    "        Images are returned as a 4D tensor of values between -1 and 1.\n",
    "        Dimensions are (number, channels, height, width). Returns the tensor\n",
    "        on cpu.\n",
    "        Args:\n",
    "            latent_vec: A pytorch latent vector or None\n",
    "            num: The number of samples to generate if latent_vec is None\n",
    "        If latent_vec and num are None then use self.batch_size\n",
    "        random latent vectors.\n",
    "        \"\"\"\n",
    "        num = self.batch_size if num is None else num\n",
    "        latent_vec = self.noise_fn(num) if latent_vec is None else latent_vec\n",
    "        with torch.no_grad():\n",
    "            samples = self.generator(latent_vec)\n",
    "        samples = samples.cpu()  # move images to cpu\n",
    "        return samples\n",
    "\n",
    "    def train_step_generator(self):\n",
    "        \"\"\"Train the generator one step and return the loss.\"\"\"\n",
    "        self.generator.zero_grad()\n",
    "\n",
    "        latent_vec = self.noise_fn(self.batch_size)\n",
    "        generated = self.generator(latent_vec)\n",
    "        classifications = self.discriminator(generated)\n",
    "        loss = self.criterion(classifications, self.target_ones)\n",
    "        loss.backward()\n",
    "        self.optim_g.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def train_step_discriminator(self, real_samples):\n",
    "        \"\"\"Train the discriminator one step and return the losses.\"\"\"\n",
    "        local_batch_size = real_samples.shape[0]\n",
    "        target_ones = torch.ones((local_batch_size, 1), device=self.device)\n",
    "        target_zeros = torch.zeros(\n",
    "            (local_batch_size, 1), device=self.device)\n",
    "        \n",
    "        self.discriminator.zero_grad()\n",
    "        # real samples\n",
    "        pred_real = self.discriminator(real_samples)\n",
    "        \n",
    "        loss_real = self.criterion(pred_real, target_ones)\n",
    "        # generated samples\n",
    "        latent_vec = self.noise_fn(local_batch_size)\n",
    "        with torch.no_grad():\n",
    "            fake_samples = self.generator(latent_vec)\n",
    "        pred_fake = self.discriminator(fake_samples)\n",
    "        \n",
    "        loss_fake = self.criterion(pred_fake, target_zeros)\n",
    "        # combine\n",
    "        loss = (loss_real + loss_fake) / 2\n",
    "        loss.backward()\n",
    "        self.optim_d.step()\n",
    "        return loss_real.item(), loss_fake.item()\n",
    "\n",
    "    def train_epoch(self, print_frequency=10, max_steps=0):\n",
    "        \"\"\"Train both networks for one epoch and return the losses.\n",
    "        Args:\n",
    "            print_frequency (int): print stats every `print_frequency` steps.\n",
    "            max_steps (int): End epoch after `max_steps` steps, or set to 0\n",
    "                             to do the full epoch.\n",
    "        \"\"\"\n",
    "        loss_g_running, loss_d_real_running, loss_d_fake_running = 0, 0, 0\n",
    "        for batch, real_samples in enumerate(self.dataloader):\n",
    "            real_samples = real_samples.to(self.device)\n",
    "            # print(real_samples.shape)\n",
    "            ldr_, ldf_ = self.train_step_discriminator(real_samples)\n",
    "            loss_d_real_running += ldr_\n",
    "            loss_d_fake_running += ldf_\n",
    "            loss_g_running += self.train_step_generator()\n",
    "            if print_frequency and (batch+1) % print_frequency == 0:\n",
    "                print(f\"{batch+1}/{len(self.dataloader)}:\"\n",
    "                      f\" G={loss_g_running / (batch+1):.3f},\"\n",
    "                      f\" Dr={loss_d_real_running / (batch+1):.3f},\"\n",
    "                      f\" Df={loss_d_fake_running / (batch+1):.3f}\",\n",
    "                      end='\\r',\n",
    "                      flush=True)\n",
    "            if max_steps and batch == max_steps:\n",
    "                break\n",
    "        if print_frequency:\n",
    "            print()\n",
    "        loss_g_running /= batch\n",
    "        loss_d_real_running /= batch\n",
    "        loss_d_fake_running /= batch\n",
    "        return (loss_g_running, (loss_d_real_running, loss_d_fake_running))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "cpu\n",
      "self.slist.shape = (10000,) | self.numpis = 3 | self.__len__() = 10000\n",
      "Epoch 1; Elapsed time = 0s\n",
      "620/625: G=41.947, Dr=0.075, Df=0.082\n",
      "Epoch 2; Elapsed time = 66s\n",
      "620/625: G=84.244, Dr=0.035, Df=0.046\n",
      "Epoch 3; Elapsed time = 131s\n",
      "620/625: G=99.508, Dr=0.000, Df=0.000\n",
      "Epoch 4; Elapsed time = 196s\n",
      "620/625: G=97.802, Dr=0.001, Df=0.001\n",
      "Epoch 5; Elapsed time = 264s\n",
      "620/625: G=99.791, Dr=0.000, Df=0.000\n",
      "Epoch 6; Elapsed time = 329s\n",
      "620/625: G=99.639, Dr=0.000, Df=0.000\n",
      "Epoch 7; Elapsed time = 396s\n",
      "520/625: G=99.502, Dr=0.000, Df=0.002\r"
     ]
    }
   ],
   "source": [
    "runnum += 1\n",
    "print(runnum)\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "latent_dim = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "dataloader = DataLoader(specGds(10000,1/3000),\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,drop_last=False\n",
    "                        )\n",
    "\n",
    "\n",
    "def noise_fn(x): return torch.randn((x, latent_dim), device=device)\n",
    "gan = DCGAN(latent_dim, noise_fn, dataloader,device=device, batch_size=batch_size)\n",
    "start = time()\n",
    "for i in range(epochs):\n",
    "    print(f\"Epoch {i+1}; Elapsed time = {int(time() - start)}s\")\n",
    "    gan.train_epoch()\n",
    "images = gan.generate_samples() * -1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
