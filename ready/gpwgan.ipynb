{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sinexpDL import *\n",
    "from pathlib import Path\n",
    "runnum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch\n",
    "from datetime import date, datetime\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "device = \"cuda:0\" if cuda else \"cpu\"\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "class OPT(object):\n",
    "    def __init__(self,) -> None:\n",
    "        self.n_epochs = 200\n",
    "        self.batch_size = 64\n",
    "        self.lr = 0.0002\n",
    "        self.b1 = 0.5\n",
    "        self.b2 = 0.999\n",
    "        self.n_cpu = 8\n",
    "        self.latent_dim = 1\n",
    "        self.img_size = 64\n",
    "        self.channels = 1\n",
    "        self.img_shape = (1, self.img_size, self.img_size)\n",
    "opt = OPT()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            layers.append(nn.Tanh())\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(opt.img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.shape[0], *opt.img_shape)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(opt.img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weight for gradient penalty\n",
    "lambda_gp = 10\n",
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    # print(alpha.shape,real_samples.shape,fake_samples.shape)\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.pspace.shape = (1000,) | self.__len__() = 1000\n"
     ]
    }
   ],
   "source": [
    "pstart = 1\n",
    "pend = 2\n",
    "ds = specGds(\"cuda:0\", pstart, pend)\n",
    "dataloader = DataLoader(ds,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "def noise_fn(x = opt.batch_size):\n",
    "    return Variable(torch.abs(torch.normal(mean = (pstart+pend)/2, std = (pend - pstart)/8, size = (x,opt.latent_dim),device=device)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2749],\n",
       "        [1.5173],\n",
       "        [1.4179],\n",
       "        [1.7979],\n",
       "        [1.5083],\n",
       "        [1.6503],\n",
       "        [1.4887],\n",
       "        [1.4980],\n",
       "        [1.4873],\n",
       "        [1.4741],\n",
       "        [1.3566],\n",
       "        [1.3339],\n",
       "        [1.4950],\n",
       "        [1.6004],\n",
       "        [1.3664],\n",
       "        [1.6646],\n",
       "        [1.4335],\n",
       "        [1.4499],\n",
       "        [1.5366],\n",
       "        [1.5127],\n",
       "        [1.6863],\n",
       "        [1.4747],\n",
       "        [1.7779],\n",
       "        [2.0387],\n",
       "        [1.4958],\n",
       "        [1.4699],\n",
       "        [1.6177],\n",
       "        [1.4969],\n",
       "        [1.5950],\n",
       "        [1.3773],\n",
       "        [1.5648],\n",
       "        [1.5504],\n",
       "        [1.3643],\n",
       "        [1.7023],\n",
       "        [1.5942],\n",
       "        [1.2785],\n",
       "        [1.6205],\n",
       "        [1.6449],\n",
       "        [1.8177],\n",
       "        [1.4590],\n",
       "        [1.4755],\n",
       "        [1.3722],\n",
       "        [1.4485],\n",
       "        [1.6235],\n",
       "        [1.2992],\n",
       "        [1.3833],\n",
       "        [1.3918],\n",
       "        [1.5737],\n",
       "        [1.4129],\n",
       "        [1.8895],\n",
       "        [1.3592],\n",
       "        [1.4550],\n",
       "        [1.5421],\n",
       "        [1.2978],\n",
       "        [1.5169],\n",
       "        [1.3409],\n",
       "        [1.4120],\n",
       "        [1.6120],\n",
       "        [1.4471],\n",
       "        [1.5102],\n",
       "        [1.5657],\n",
       "        [1.5405],\n",
       "        [1.5804],\n",
       "        [1.4799]], device='cuda:0')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/16] [D loss: -0.16562] [G loss: 0.14891]      \n",
      "[Epoch 1/200] [Batch 0/16] [D loss: 0.94202] [G loss: -0.79241]        \n",
      "[Epoch 2/200] [Batch 0/16] [D loss: 0.8898] [G loss: -0.21785]       \n",
      "[Epoch 3/200] [Batch 0/16] [D loss: -1.2014] [G loss: 1.116]        \n",
      "[Epoch 4/200] [Batch 0/16] [D loss: -0.3646] [G loss: 0.22923]        \n",
      "[Epoch 5/200] [Batch 0/16] [D loss: 2.9663] [G loss: -0.18656]          \n",
      "[Epoch 6/200] [Batch 0/16] [D loss: 0.78224] [G loss: -0.87613]       \n",
      "[Epoch 7/200] [Batch 0/16] [D loss: 1.379] [G loss: -0.98574]       \n",
      "[Epoch 8/200] [Batch 0/16] [D loss: -1.3134] [G loss: 1.2237]         \n",
      "[Epoch 9/200] [Batch 0/16] [D loss: -0.4239] [G loss: 0.28393]        \n",
      "[Epoch 10/200] [Batch 0/16] [D loss: 0.98439] [G loss: -0.16558]        \n",
      "[Epoch 11/200] [Batch 0/16] [D loss: 0.52995] [G loss: -0.6979]        \n",
      "[Epoch 12/200] [Batch 0/16] [D loss: 1.5588] [G loss: -1.6622]        \n",
      "[Epoch 13/200] [Batch 0/16] [D loss: 2.8895] [G loss: -2.4734]       \n",
      "[Epoch 14/200] [Batch 0/16] [D loss: -2.9796] [G loss: 3.1777]       \n",
      "[Epoch 15/200] [Batch 0/16] [D loss: -1.1568] [G loss: 1.0328]       \n",
      "[Epoch 16/200] [Batch 0/16] [D loss: -0.27001] [G loss: 0.11754]       \n",
      "[Epoch 17/200] [Batch 0/16] [D loss: 0.35573] [G loss: -0.36405]         \n",
      "[Epoch 18/200] [Batch 0/16] [D loss: 1.0632] [G loss: -1.208]          \n",
      "[Epoch 19/200] [Batch 0/16] [D loss: 2.0548] [G loss: -2.0618]       \n",
      "[Epoch 20/200] [Batch 0/16] [D loss: -1.6636] [G loss: 2.1909]         \n",
      "[Epoch 21/200] [Batch 0/16] [D loss: -1.2686] [G loss: 1.2238]       \n",
      "[Epoch 22/200] [Batch 0/16] [D loss: 0.13412] [G loss: 0.033362]        \n",
      "[Epoch 23/200] [Batch 0/16] [D loss: 0.91427] [G loss: -0.14172]         \n",
      "[Epoch 24/200] [Batch 0/16] [D loss: 0.89591] [G loss: -0.84789]       \n",
      "[Epoch 25/200] [Batch 0/16] [D loss: 0.65635] [G loss: 2.9773]       \n",
      "[Epoch 26/200] [Batch 0/16] [D loss: -0.82412] [G loss: 0.64881]       \n",
      "[Epoch 27/200] [Batch 0/16] [D loss: 0.03503] [G loss: -0.10878]          \n",
      "[Epoch 28/200] [Batch 0/16] [D loss: 0.46517] [G loss: -0.41962]       \n",
      "[Epoch 29/200] [Batch 0/16] [D loss: 1.4548] [G loss: -1.5734]        \n",
      "[Epoch 30/200] [Batch 0/16] [D loss: 2.8791] [G loss: -2.7324]       \n",
      "[Epoch 31/200] [Batch 0/16] [D loss: -3.2398] [G loss: 3.8003]        \n",
      "[Epoch 32/200] [Batch 0/16] [D loss: -1.8681] [G loss: 1.7591]       \n",
      "[Epoch 33/200] [Batch 0/16] [D loss: -0.69988] [G loss: 0.51135]       \n",
      "[Epoch 34/200] [Batch 0/16] [D loss: 0.59726] [G loss: -0.12967]          \n",
      "[Epoch 35/200] [Batch 0/16] [D loss: 1.1538] [G loss: -0.29418]        \n",
      "[Epoch 36/200] [Batch 0/16] [D loss: 1.1889] [G loss: -1.2968]         \n",
      "[Epoch 37/200] [Batch 0/16] [D loss: 2.1032] [G loss: -2.0524]       \n",
      "[Epoch 38/200] [Batch 0/16] [D loss: -1.918] [G loss: 2.1521]          \n",
      "[Epoch 39/200] [Batch 0/16] [D loss: -0.99993] [G loss: 0.85741]      \n",
      "[Epoch 40/200] [Batch 0/16] [D loss: -0.053465] [G loss: -0.011045]      \n",
      "[Epoch 41/200] [Batch 0/16] [D loss: 1.0036] [G loss: -0.33722]          \n",
      "[Epoch 42/200] [Batch 0/16] [D loss: 1.2882] [G loss: -1.1176]         \n",
      "[Epoch 43/200] [Batch 0/16] [D loss: -0.48722] [G loss: 1.5002]         \n",
      "[Epoch 44/200] [Batch 0/16] [D loss: -0.74466] [G loss: 0.5489]        \n",
      "[Epoch 45/200] [Batch 0/16] [D loss: 0.2321] [G loss: -0.2358]            \n",
      "[Epoch 46/200] [Batch 0/16] [D loss: 0.81469] [G loss: -1.0359]        \n",
      "[Epoch 47/200] [Batch 0/16] [D loss: 2.3487] [G loss: -2.3742]       \n",
      "[Epoch 48/200] [Batch 0/16] [D loss: -3.1308] [G loss: 3.1849]       \n",
      "[Epoch 49/200] [Batch 0/16] [D loss: -1.0699] [G loss: 0.83775]       \n",
      "[Epoch 50/200] [Batch 0/16] [D loss: -0.14175] [G loss: -0.10256]        \n",
      "[Epoch 51/200] [Batch 0/16] [D loss: 0.87192] [G loss: -0.25057]        \n",
      "[Epoch 52/200] [Batch 0/16] [D loss: 1.6788] [G loss: -0.30061]         \n",
      "[Epoch 53/200] [Batch 0/16] [D loss: 0.55176] [G loss: -0.77077]       \n",
      "[Epoch 54/200] [Batch 0/16] [D loss: 1.6511] [G loss: -1.2271]        \n",
      "[Epoch 55/200] [Batch 0/16] [D loss: 1.3153] [G loss: -1.3546]       \n",
      "[Epoch 56/200] [Batch 0/16] [D loss: -1.7197] [G loss: 1.7028]         \n",
      "[Epoch 57/200] [Batch 0/16] [D loss: -0.81704] [G loss: 0.58298]       \n",
      "[Epoch 58/200] [Batch 0/16] [D loss: -0.26256] [G loss: 0.065175]      \n",
      "[Epoch 59/200] [Batch 0/16] [D loss: 0.21487] [G loss: -0.23688]          \n",
      "[Epoch 60/200] [Batch 0/16] [D loss: 2.6717] [G loss: -0.37957]        \n",
      "[Epoch 61/200] [Batch 0/16] [D loss: 1.0104] [G loss: -1.1637]         \n",
      "[Epoch 62/200] [Batch 0/16] [D loss: 1.5483] [G loss: -1.6834]       \n",
      "[Epoch 63/200] [Batch 0/16] [D loss: -2.1483] [G loss: 2.0765]        \n",
      "[Epoch 64/200] [Batch 0/16] [D loss: -0.71344] [G loss: 0.43135]       \n",
      "[Epoch 65/200] [Batch 0/16] [D loss: 0.077929] [G loss: -0.2849]         \n",
      "[Epoch 66/200] [Batch 0/16] [D loss: 0.98205] [G loss: -0.90584]       \n",
      "[Epoch 67/200] [Batch 0/16] [D loss: 2.61] [G loss: -2.6622]          \n",
      "[Epoch 68/200] [Batch 0/16] [D loss: -3.3706] [G loss: 3.5773]         \n",
      "[Epoch 69/200] [Batch 0/16] [D loss: -1.0843] [G loss: 0.81369]       \n",
      "[Epoch 70/200] [Batch 0/16] [D loss: -0.072325] [G loss: -0.16788]       \n",
      "[Epoch 71/200] [Batch 0/16] [D loss: 1.0289] [G loss: -0.64418]         \n",
      "[Epoch 72/200] [Batch 0/16] [D loss: 2.4033] [G loss: -2.0781]        \n",
      "[Epoch 73/200] [Batch 0/16] [D loss: -1.9083] [G loss: 1.74]           \n",
      "[Epoch 74/200] [Batch 0/16] [D loss: -0.10208] [G loss: -0.15491]        \n",
      "[Epoch 75/200] [Batch 0/16] [D loss: 3.2553] [G loss: -0.46641]         \n",
      "[Epoch 76/200] [Batch 0/16] [D loss: 1.4465] [G loss: -1.1916]        \n",
      "[Epoch 77/200] [Batch 0/16] [D loss: 2.1199] [G loss: -1.6407]       \n",
      "[Epoch 78/200] [Batch 0/16] [D loss: -2.5988] [G loss: 2.5443]         \n",
      "[Epoch 79/200] [Batch 0/16] [D loss: -0.55008] [G loss: 0.26235]       \n",
      "[Epoch 80/200] [Batch 0/16] [D loss: 1.4208] [G loss: -0.31867]           \n",
      "[Epoch 81/200] [Batch 0/16] [D loss: 1.006] [G loss: -1.1286]          \n",
      "[Epoch 82/200] [Batch 0/16] [D loss: 1.7405] [G loss: -1.8306]       \n",
      "[Epoch 83/200] [Batch 0/16] [D loss: -1.8198] [G loss: 1.6917]        \n",
      "[Epoch 84/200] [Batch 0/16] [D loss: -0.60067] [G loss: 0.30872]       \n",
      "[Epoch 85/200] [Batch 0/16] [D loss: 0.21348] [G loss: -0.23112]         \n",
      "[Epoch 86/200] [Batch 0/16] [D loss: 0.22492] [G loss: -0.4265]         \n",
      "[Epoch 87/200] [Batch 0/16] [D loss: 0.76671] [G loss: -0.89794]       \n",
      "[Epoch 88/200] [Batch 0/16] [D loss: 0.98653] [G loss: -1.247]        \n",
      "[Epoch 89/200] [Batch 0/16] [D loss: -0.81458] [G loss: 0.95203]        \n",
      "[Epoch 90/200] [Batch 0/16] [D loss: -0.79093] [G loss: 0.53019]       \n",
      "[Epoch 91/200] [Batch 0/16] [D loss: 0.058895] [G loss: -0.27163]        \n",
      "[Epoch 92/200] [Batch 0/16] [D loss: 0.36592] [G loss: -0.68134]       \n",
      "[Epoch 93/200] [Batch 0/16] [D loss: 1.1134] [G loss: -1.1504]        \n",
      "[Epoch 94/200] [Batch 0/16] [D loss: 0.46304] [G loss: -0.30185]       \n",
      "[Epoch 95/200] [Batch 0/16] [D loss: -1.5791] [G loss: 1.434]           \n",
      "[Epoch 96/200] [Batch 0/16] [D loss: -0.28949] [G loss: -0.00027632]      \n",
      "[Epoch 97/200] [Batch 0/16] [D loss: 0.58275] [G loss: -0.53475]       \n",
      "[Epoch 98/200] [Batch 0/16] [D loss: 1.1672] [G loss: -1.2664]         \n",
      "[Epoch 99/200] [Batch 0/16] [D loss: 0.68549] [G loss: -0.52953]       \n",
      "[Epoch 100/200] [Batch 0/16] [D loss: -1.3754] [G loss: 1.1139]       \n",
      "[Epoch 101/200] [Batch 0/16] [D loss: -0.049233] [G loss: -0.23308]        \n",
      "[Epoch 102/200] [Batch 0/16] [D loss: 0.87855] [G loss: -0.40369]        \n",
      "[Epoch 103/200] [Batch 0/16] [D loss: 0.57137] [G loss: -0.43797]       \n",
      "[Epoch 104/200] [Batch 0/16] [D loss: 0.31213] [G loss: -0.61001]       \n",
      "[Epoch 105/200] [Batch 0/16] [D loss: 1.3419] [G loss: -1.571]        \n",
      "[Epoch 106/200] [Batch 0/16] [D loss: -1.7182] [G loss: 1.8797]         \n",
      "[Epoch 107/200] [Batch 0/16] [D loss: -0.57898] [G loss: 0.24936]       \n",
      "[Epoch 108/200] [Batch 0/16] [D loss: -0.017114] [G loss: -0.29732]       \n",
      "[Epoch 109/200] [Batch 0/16] [D loss: 0.92121] [G loss: -0.54613]       \n",
      "[Epoch 110/200] [Batch 0/16] [D loss: 1.5486] [G loss: -1.7583]        \n",
      "[Epoch 111/200] [Batch 0/16] [D loss: -0.42766] [G loss: 0.9189]        \n",
      "[Epoch 112/200] [Batch 0/16] [D loss: -1.0688] [G loss: 0.75807]       \n",
      "[Epoch 113/200] [Batch 0/16] [D loss: 0.1598] [G loss: -0.26076]          \n",
      "[Epoch 114/200] [Batch 0/16] [D loss: 0.97537] [G loss: -0.66927]        \n",
      "[Epoch 115/200] [Batch 0/16] [D loss: 1.2393] [G loss: -1.2411]        \n",
      "[Epoch 116/200] [Batch 0/16] [D loss: -1.1287] [G loss: 1.3889]         \n",
      "[Epoch 117/200] [Batch 0/16] [D loss: -0.88348] [G loss: 0.57166]       \n",
      "[Epoch 118/200] [Batch 0/16] [D loss: 0.059709] [G loss: -0.18062]        \n",
      "[Epoch 119/200] [Batch 0/16] [D loss: 0.70691] [G loss: -0.32948]        \n",
      "[Epoch 120/200] [Batch 0/16] [D loss: 0.14425] [G loss: -0.41096]       \n",
      "[Epoch 121/200] [Batch 0/16] [D loss: 0.79287] [G loss: -0.64002]       \n",
      "[Epoch 122/200] [Batch 0/16] [D loss: 0.94634] [G loss: -1.2608]       \n",
      "[Epoch 123/200] [Batch 0/16] [D loss: 0.46262] [G loss: -0.43802]       \n",
      "[Epoch 124/200] [Batch 0/16] [D loss: -1.5546] [G loss: 1.3088]         \n",
      "[Epoch 125/200] [Batch 0/16] [D loss: 0.20983] [G loss: -0.15836]         \n",
      "[Epoch 126/200] [Batch 0/16] [D loss: 0.20201] [G loss: -0.35306]        \n",
      "[Epoch 127/200] [Batch 0/16] [D loss: 1.7646] [G loss: -0.42468]        \n",
      "[Epoch 128/200] [Batch 0/16] [D loss: 0.50607] [G loss: -0.62732]       \n",
      "[Epoch 129/200] [Batch 0/16] [D loss: 0.82178] [G loss: -0.87916]       \n",
      "[Epoch 130/200] [Batch 0/16] [D loss: 0.36522] [G loss: -0.54189]       \n",
      "[Epoch 131/200] [Batch 0/16] [D loss: -1.2543] [G loss: 1.2339]          \n",
      "[Epoch 132/200] [Batch 0/16] [D loss: -0.32853] [G loss: 0.012161]      \n",
      "[Epoch 133/200] [Batch 0/16] [D loss: 0.1465] [G loss: -0.26039]         \n",
      "[Epoch 134/200] [Batch 0/16] [D loss: 0.48444] [G loss: -0.82237]         \n",
      "[Epoch 135/200] [Batch 0/16] [D loss: 1.612] [G loss: -1.7792]         \n",
      "[Epoch 136/200] [Batch 0/16] [D loss: -1.6985] [G loss: 1.4691]        \n",
      "[Epoch 137/200] [Batch 0/16] [D loss: -0.1213] [G loss: -0.20125]         \n",
      "[Epoch 138/200] [Batch 0/16] [D loss: 0.39669] [G loss: -0.38093]        \n",
      "[Epoch 139/200] [Batch 0/16] [D loss: 1.2047] [G loss: -0.55309]        \n",
      "[Epoch 140/200] [Batch 0/16] [D loss: 1.157] [G loss: -1.3609]         \n",
      "[Epoch 141/200] [Batch 0/16] [D loss: 0.2611] [G loss: -0.17745]        \n",
      "[Epoch 142/200] [Batch 0/16] [D loss: -1.2437] [G loss: 1.0356]        \n",
      "[Epoch 143/200] [Batch 0/16] [D loss: -0.17218] [G loss: -0.12223]       \n",
      "[Epoch 144/200] [Batch 0/16] [D loss: 0.43344] [G loss: -0.32808]        \n",
      "[Epoch 145/200] [Batch 0/16] [D loss: 1.0942] [G loss: -1.4129]         \n",
      "[Epoch 146/200] [Batch 0/16] [D loss: 2.1495] [G loss: -2.1714]       \n",
      "[Epoch 147/200] [Batch 0/16] [D loss: -2.1368] [G loss: 1.8627]          \n",
      "[Epoch 148/200] [Batch 0/16] [D loss: -0.30048] [G loss: -0.050389]      \n",
      "[Epoch 149/200] [Batch 0/16] [D loss: 1.5152] [G loss: -0.31305]         \n",
      "[Epoch 150/200] [Batch 0/16] [D loss: 1.4929] [G loss: -0.84758]        \n",
      "[Epoch 151/200] [Batch 0/16] [D loss: 2.4502] [G loss: -2.3728]        \n",
      "[Epoch 152/200] [Batch 0/16] [D loss: -2.4201] [G loss: 2.2113]       \n",
      "[Epoch 153/200] [Batch 0/16] [D loss: -0.12439] [G loss: -0.23989]        \n",
      "[Epoch 154/200] [Batch 0/16] [D loss: 0.31591] [G loss: -0.31152]        \n",
      "[Epoch 155/200] [Batch 0/16] [D loss: 1.0334] [G loss: -0.34649]         \n",
      "[Epoch 156/200] [Batch 0/16] [D loss: 0.06189] [G loss: -0.38638]        \n",
      "[Epoch 157/200] [Batch 0/16] [D loss: 1.8092] [G loss: -0.91779]        \n",
      "[Epoch 158/200] [Batch 0/16] [D loss: 1.9899] [G loss: -2.0816]       \n",
      "[Epoch 159/200] [Batch 0/16] [D loss: -2.3645] [G loss: 2.5683]          \n",
      "[Epoch 160/200] [Batch 0/16] [D loss: -0.72397] [G loss: 0.38241]       \n",
      "[Epoch 161/200] [Batch 0/16] [D loss: 0.89183] [G loss: -0.41945]        \n",
      "[Epoch 162/200] [Batch 0/16] [D loss: 0.84358] [G loss: -0.59881]       \n",
      "[Epoch 163/200] [Batch 0/16] [D loss: 1.06] [G loss: -1.2181]          \n",
      "[Epoch 164/200] [Batch 0/16] [D loss: 0.70046] [G loss: -0.8015]        \n",
      "[Epoch 165/200] [Batch 0/16] [D loss: -1.0798] [G loss: 0.95369]         \n",
      "[Epoch 166/200] [Batch 0/16] [D loss: -0.72565] [G loss: 0.44315]       \n",
      "[Epoch 167/200] [Batch 0/16] [D loss: -0.18972] [G loss: -0.1437]         \n",
      "[Epoch 168/200] [Batch 0/16] [D loss: 0.74645] [G loss: -1.089]          \n",
      "[Epoch 169/200] [Batch 0/16] [D loss: 0.83392] [G loss: -0.64317]      \n",
      "[Epoch 170/200] [Batch 0/16] [D loss: -0.93095] [G loss: 0.5008]        \n",
      "[Epoch 171/200] [Batch 0/16] [D loss: 1.238] [G loss: -0.43751]           \n",
      "[Epoch 172/200] [Batch 0/16] [D loss: 0.21598] [G loss: -0.5508]        \n",
      "[Epoch 173/200] [Batch 0/16] [D loss: 0.99295] [G loss: -0.80666]       \n",
      "[Epoch 174/200] [Batch 0/16] [D loss: 1.1942] [G loss: -1.2132]        \n",
      "[Epoch 175/200] [Batch 0/16] [D loss: -0.65573] [G loss: 0.60712]        \n",
      "[Epoch 176/200] [Batch 0/16] [D loss: -0.77621] [G loss: 0.41679]       \n",
      "[Epoch 177/200] [Batch 0/16] [D loss: 1.3154] [G loss: -0.37339]          \n",
      "[Epoch 178/200] [Batch 0/16] [D loss: 0.039335] [G loss: -0.42903]       \n",
      "[Epoch 179/200] [Batch 0/16] [D loss: 0.13608] [G loss: -0.52275]        \n",
      "[Epoch 180/200] [Batch 0/16] [D loss: 0.50299] [G loss: -0.73263]       \n",
      "[Epoch 181/200] [Batch 0/16] [D loss: 0.40009] [G loss: -0.79227]       \n",
      "[Epoch 182/200] [Batch 0/16] [D loss: 0.57919] [G loss: -0.90086]       \n",
      "[Epoch 183/200] [Batch 0/16] [D loss: -1.4135] [G loss: 1.2011]         \n",
      "[Epoch 184/200] [Batch 0/16] [D loss: -0.30266] [G loss: -0.15307]         \n",
      "[Epoch 185/200] [Batch 0/16] [D loss: 0.4444] [G loss: -0.49476]          \n",
      "[Epoch 186/200] [Batch 0/16] [D loss: 0.70564] [G loss: -0.87604]       \n",
      "[Epoch 187/200] [Batch 0/16] [D loss: 1.2267] [G loss: -1.5209]        \n",
      "[Epoch 188/200] [Batch 0/16] [D loss: -1.3495] [G loss: 1.1044]            \n",
      "[Epoch 189/200] [Batch 0/16] [D loss: -0.31592] [G loss: -0.065347]       \n",
      "[Epoch 190/200] [Batch 0/16] [D loss: 0.05025] [G loss: -0.37632]         \n",
      "[Epoch 191/200] [Batch 0/16] [D loss: 0.38039] [G loss: -0.54594]         \n",
      "[Epoch 192/200] [Batch 0/16] [D loss: 1.223] [G loss: -1.591]          \n",
      "[Epoch 193/200] [Batch 0/16] [D loss: 1.8784] [G loss: -1.9369]       \n",
      "[Epoch 194/200] [Batch 0/16] [D loss: -2.1203] [G loss: 1.7483]         \n",
      "[Epoch 195/200] [Batch 0/16] [D loss: -0.27923] [G loss: -0.17885]        \n",
      "[Epoch 196/200] [Batch 0/16] [D loss: 0.13152] [G loss: -0.40754]        \n",
      "[Epoch 197/200] [Batch 0/16] [D loss: 1.1359] [G loss: -0.45807]         \n",
      "[Epoch 198/200] [Batch 0/16] [D loss: 0.17657] [G loss: -0.49302]        \n",
      "[Epoch 199/200] [Batch 0/16] [D loss: 0.37936] [G loss: -0.75434]       \n",
      "[Epoch 199/200] [Batch 15/16] [D loss: 1.2257] [G loss: -1.5023]       \r"
     ]
    }
   ],
   "source": [
    "batches_done = 0\n",
    "timestarted = datetime.now()\n",
    "timestarted = str(timestarted.hour) + \" \" + str(timestarted.minute) + \" \" +  str(timestarted.second)\n",
    "dloss = []\n",
    "gloss = []\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = noise_fn(imgs.shape[0])\n",
    "\n",
    "        # Generate a batch of images\n",
    "        fake_imgs = generator(z)\n",
    "\n",
    "        # Real images\n",
    "        real_validity = discriminator(real_imgs)\n",
    "        # Fake images\n",
    "        fake_validity = discriminator(fake_imgs)\n",
    "        # Gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "        # Adversarial loss\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        # Generate a batch of images\n",
    "        fake_imgs = generator(z)\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        # Train on fake images\n",
    "        fake_validity = discriminator(fake_imgs)\n",
    "        g_loss = -torch.mean(fake_validity)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {epoch}/{opt.n_epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item():.5}] [G loss: {g_loss.item():.5}] {' '*5}\", flush=True, end = \"\\r\"\n",
    "        )\n",
    "        dloss.append(d_loss.item())\n",
    "        gloss.append(g_loss.item())\n",
    "        if i%16 == 0:\n",
    "            print()\n",
    "\n",
    "        if batches_done % 5 == 0:\n",
    "            path = Path(f\"./images/{date.today()}/{timestarted}/{runnum}/\")\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "            save_image(fake_imgs.data[:], f\"images/{date.today().isoformat()}/{timestarted}/{runnum}/{batches_done}.png\", nrow=8, normalize=True)\n",
    "        \n",
    "        batches_done += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuiUlEQVR4nO3dd3xUVfrH8c+TTkgoISFAICShCKFDpAkIAiqgICKuura1oIuKZZu77rrFn7ur69oRRHTtILYFEUUFqdIChN5CKAkBEgIBQkg/vz/OqCxdMpk75Xm/Xvc17TL3YRi+9865554jxhiUUkr5vyCnC1BKKeUZGvhKKRUgNPCVUipAaOArpVSA0MBXSqkAEeJ0AWcTGxtrkpKSnC5DKaV8xsqVKw8YY+JO95pXB35SUhLp6elOl6GUUj5DRHad6TVt0lFKqQChga+UUgFCA18ppQKEBr5SSgUIDXyllAoQGvhKKRUgNPCVUipAeHU/fHUauathx0KolwgxKRCTDOHRTlellPIBGvi+ZO2HMH0sVJb97/O146B+sg3/mBTXfdfOILIBiDhTr1LKq2jg+wJjYP7TMO/vkNQXrpkAxw/BwSw4tAMO7rD3d30Ha6cBJ0xqE14H6ifZHUBsK2iYapcGLSFY//mVCiT6P97bVZTCjHGwdip0ugmufgFCwqBeM2jc8dT1y0ugcPepO4N962DTZ2Aq7XrBYRB7EcSnQsO20LCdvV8nQX8RKOWnNPC9WfFB+OBm2LUYBvwR+v363GEcGgFxre1ysvISOLAV8jZB3gbYvxF2LoK1H/y4TnhduwOIT/3x10DtOAgJh5AI1204BIdDkJ7zV8qXaOB7q4Lt8N5oOJwNo16HDtdV/z1DI+yvgpN/GRwv/HEnkLfJ7gjWfwwlb5z9/YLD7E7g+9sfdgphEFobWl8OXW6ByJjq166Uqjbx5knM09LSTECOlrlrCUy9yd6/cQok9vR8DcbA0b2Qt9HuECpKoaLE3laW/u/jH25PuH8sD/augZBa0HE0dL8HGrX3/N9DqQAjIiuNMWmne02P8L3N9z1x6iXCTdOgQQtn6hCBOk3scqH2rYPlk+zfadXbkNgbeoyBNldBcKj7alVKnRc9wvcWJ/bEad4HfvaO/zSFFB+E1e/CitfsCeXoJnDxHdD1dog67TwNSqkLdLYjfLecdRORN0QkT0TWn+H1/iJyWEQyXMvj7tiu36gohU/vtWHf6Ua45VP/CXuwf5dLxsG4DLhhij2hPPf/4LlU+/fes8rpCpUKCO5q0nkTeBl4+yzrLDTGXOWm7fmP/+mJ8xj0+43/dosMCoY2Q+2SvwWWvwZrptglIQ163AOp19iTvkopt3PLEb4xZgFw0B3vFVAKtsPkQZCzwvbEufS3/hv2J4u7CIY9A49sgiFPQ0khfHI3PNfONm0dK3C6QqX8jic7UvcSkTUi8oWItDvTSiIyRkTSRSQ9Pz/fg+V52N61NuyPH4JbZ7in26Uviqhjj+zvWwE3fwyNO8G3T9rmns8egvytTleolN9w20lbEUkCZhpjTul7JyJ1gCpjTJGIDAVeMMa0Otd7+u1J28pymNQfigvg9s+d64njrfI2w9JXYM1U2wW09ZXQ6z47rESg/AJS6gLV+EnbczHGHDHGFLnuzwJCRSTWE9v2SksnwP71MPRfGvan07ANDH8RHt4A/X8POenw1tXwaj9Y8wFUlJ37PZRSp/BI4ItIIxF7aCYi3V3bDcxG2sLdMO8f0HqI7Y+uziwqDvo/aoP/6hddvZnGwAsdYeGztjlMKXXe3NJLR0SmAP2BWBHJAf4MhAIYYyYC1wG/FJEK4Dhwg/HmCwBqijEw67f2/tCntXnifIVGQLfb7DAN2+fAkpdhzl9hwb+gy83Q85d2NFCl1FnphVeetOkz2wVz8BO2X7q6cPvWwZJXYN2HUFUBKf3tMNBRDe1gb98v3z+OqKs7WBUQztaGr4HvKaVHYXwPqFUfxszToQXc5eg+O3zDli+gKM+eCOc03+ngMNdOIBZqN3TtCGLtEBZNukB8ezv4m1I+TsfS8Qbf/gOO5MLotzTs3Sm6EQx83C4AlRU29I/l2wHcivJ/vH/sgN0pHMuzg8IV5UFVuf1zQaF2SOgmXe0OIKErxLXRfyvlVzTwPWHvGlg2AbrdDs0udroa/xYcAtHxdjkXY+zw07mrf1w2fAIr/2NfD4mARh3sDuD7HUFsK3vFsFI+SJt0alpVpb3A6nA23L/CNuko72WMnSHsxJ1AbgaUH7Ovh0XZi8OS+kKH0RDb0tFylTqZNuk4Kf0NyF0F107WsPcFIvbaiAYtfrz6uaoSDmz7cQewZyXMfwrm/xMSukGH66H9tfa8gFJeTI/wa9KRvTC+u20PvuW/2kvEnxzJtbOCrZ0G+9aCBEOLAdDxZ9BmGITVdrpCFaD0CN8ps/9gLxYa9qyGvb+p0wR6P2CXvM2wbpqd6OWTuyE00l5U1/F6SBlgzyso5QX0m1hTMr+xJwAHPKbDJ/i7hm1sL6EBf4Tspfaof8OndidQOw7aXWuP/BO66o5fOUqbdGpC+XF4paft6vfLxdq/OxBVlNqd/toPYMuXdhC4mBbQ9VbbW6tWPacrVH5Km3Q8bcG/4NBOuO0zDftAFRJu2/LbDIOSw7Bxhh3985s/2+9H11uhx71Qv7nTlaoA4snx8AND3mZY/KKdqjC5n9PVKG8QURe63gK/+BzuWWB3AssnwYud4cPbIWel0xWqAKGB705VVTDzYQiPgsv/z+lqlDdq3AmunQQProVe90PmXJh8GbwxBDZ/br9DStUQDXx3WvM+7P4OBv/NjtOi1JnUTYDLn4BHNsAV/4DDOTD1Jng5DVZMhrJipytUfkgD312OFcBXf4JmPaHzzU5Xo3xFeDT0GgvjVsN1/7HNP5//ys7tO/dJO96PUm6ige8uX/8JSo/A1c9DkH6s6icKDrFX6949F37xBST2sid3n2sP0+/XuX2VW2gvHXfYuQgy3oM+D0PDtk5Xo3yZCDTvbZcDmXZu34z3YfW79mRvn0egaTenq1Q+SvvhV1dFKUzsY2/HLoWwSKcrUv7m2AFY9qrt2VNSaAdu6/MwtLhML+RSp3B8EnO/tuxVOLAVhj6jYa9qRu1YuOwxeHg9XP4kFGTCu9faSd3Xf2IHd1PqPGjgV8exAljwDLQcDK0vd7oa5e/Co6H3/fDgGhj+MpQXw0e/sD170v9jf2UqdRYa+NUx/ykoK9I+98qzQsLthVz3LYfr37E9e2Y+BM93hMUvQMkRpytUXsotgS8ib4hInoisP8PrIiIvikimiKwVka7u2K6jDmyD9Neh22128CylPC0oGFKHw93fwq0z7Pfw68dtz545f9MuneoU7jrCfxO48iyvDwFauZYxwAQ3bdc5Xz8OIbWg/x+crkQFOhFIuRRunW7Dv0V/WPisDf5pt8Kmz7S5RwFu6pZpjFkgIklnWWUE8LaxXYKWikg9EWlsjNnrju173I6FsGWWHRI3Ks7papT6UUJXuP5t26Vz+SQ7RPfG6RBe1/4a6DAakvrovLwBylP98BOA7BMe57ieOyXwRWQM9lcAiYmJHinuJ6mqgq8eg7rNoOdYp6tR6vRiW8LQp+GKv8OOebDuIztG/+p3ILoxtB9lp3Bs3Fm7dgYQr7vwyhgzCZgEth++w+Wcau0HsHeNnaM2tJbT1Sh1dsEh0HKQXYY9C1u/tOG/7FVY8jI0aGWP+jtcpxP1BABPBf4eoNkJj5u6nvMtZcX2ZFiTrvYISSlfEhZph29ofy0UH4RNM2z4z/sHzPu7/V53vN7O0BUd73S1qgZ4qlvmDOBWV2+dnsBhn2y/X/IyHM21P5N1vBzlyyJj7Mxbt8+0F3QNfgKqKuDLR+H59rZTgnbv9DtuOcIXkSlAfyBWRHKAPwOhAMaYicAsYCiQCRQDv3DHdj3q6D5Y9Dy0vRqa93K6GqXcp25TuGScXfK32O/54hcgYwoM/BN0/rme5PUTOpbO+ZrxgP0PcN8ybetU/m/PSvjy95C9DBp1hCFP2QHdlNfTsXSqa/8GO1ph9zEa9iowJHSDO2bDqNehuAD+MwSm3QaHdjldmaoGDfxzMQZmPwbhdaDfr52uRinPEbG9d+5Ph/6/h62z4eWLYc4TUFrkdHXqAmjgn0vmN5D1LVz6O3uiS6lAExYJ/R+FB9LtxVsLn7EDtmVM0Tl4fYwG/tlUVsBXf4SYFLj4LqerUcpZdZvCqMlw59f24q3/3guvD4Ls5U5Xps6TBv7ZrH4b8jfbSclDwpyuRinv0Kw73DUHrpkIh/fA64Ph47vsROzKq2ngn0nJEfj275DYG9pc5XQ1SnmXoCDofCM8sBL6/ho2zoCXutnzXccKnK5OnYEG/pksfh6O5cMVT+pYI0qdSXiU7at//wp7he7SV+CFjjD3SSg57HR16iQa+KdTmA1LxkOH6+3og0qps6vfHEZOsPM6txwIC562E7IsfBbKjjldnXLRwD+dOX+ztwMfd7YOpXxN3EV2eOZ7Fti2/jl/hRc628HadEx+x2ngn2zPSlg3DXrdB/WanXt9pdSpGneCn39oL96KbQ1f/Na28a96x/Z+U47QwD+RMTD7j1A7Dvo87HQ1Svm+xJ52gLZbPrX/r2bcD6/0sKN0ah9+j9PAP9HmmbD7OxjwBwiPdroapfyDCLS4DO6eCz97D4LD4OM74dW+sOULe6ClPEID/3uV5XZI2Lg20OVWp6tRyv+IQNur4N5FdgKh8mKYcgNMuhTWfAAVZU5X6Pc08L+37iM4mAWD/mpnCVJK1YygYOg4Gu5bDle/aCcW+nSM7c654Bntx1+DNPDBtiUufgEatoPWVzhdjVKBITgUut1mg//nH9lf13OfgOdS4bMH7dj8yq30UBZg21eQvwlGTtKLrJTytKAgaDXYLvs3wrIJdmC2lW9Ci4HQa6y91f+b1aZH+GCP7us2s3N9KqWcE58Kw1+CRzbCgD/C/vXw7igY3wPS/wPlx52u0Kdp4Gcvtz1zet1nf2IqpZxXOxYu/Q08tA5Gvgoh4TDzIXg21Y7Hf8T3psT2Bhr4i56HWvWhq/bMUcrrhIRDpxvslbu3f26nWVz4b3i+A/x3LBzY5nSFPiWw2/Dzt8KWz+3kJmG1na5GKXUmIpDUxy4Hs2DpRFj1NmS8D+2usSN2NmrvdJVezy1H+CJypYhsEZFMEXn0NK/fLiL5IpLhWrxjNpHvXoCQWnauWqWUb4hJgaFP2+aePg/Btm9g4iXw/g2Qk+50dV6t2oEvIsHAeGAIkArcKCKpp1n1A2NMZ9cyubrbrbYjufZijy432/ZCpZRviYqDQX+Bh9dB/z9A9lKYPBDeHgE7F+kVvKfhjiP87kCmMSbLGFMGTAVGuOF9a9bSCWAqoff9TleilKqOWvWh/+/sEf/gJ2zXzjeHwRtXwravNfhP4I7ATwCyT3ic43ruZKNEZK2IfCQiZxyGUkTGiEi6iKTn5+e7obzTOF5ou3i1Gwn1k2pmG0opzwqPhkvGwUNrYegzdsrF966zQzdsnKGDteG5XjqfAUnGmI7A18BbZ1rRGDPJGJNmjEmLi4urmWpW/gfKjsIlD9bM+yulnBNaC7rfDeNWw/CXofQoTLsFJvSyzbgBPDyzOwJ/D3DiEXtT13M/MMYUGGO+n/1gMtDNDdu9MOUltjknZYAds1sp5Z9CwqDrLXB/Oox6HSTIjtnzYhdY8ordEQQYdwT+CqCViCSLSBhwAzDjxBVEpPEJD4cDm9yw3QuzdioU7bdn95VS/i8oGDpcB/cuhhum2ImNZv8enm1nR8g9kut0hR5T7X74xpgKEbkfmA0EA28YYzaIyN+AdGPMDGCciAwHKoCDwO3V3e4FqaqE716Cxp0h+VJHSlBKOSQoCNoMtUvOSljyks2DJeOh/XW2A0ejDk5XWaPEePEZ7LS0NJOe7sZ+tRtn2La86/6j4+YopeDQzh8v4io/Bin9ofcDPj1Ym4isNMakne61wBlawRhY/DzUT4ZU7+81qpTygPpJMOSf8MgG26c/b7MdrG1Cb1j9nt9NvB44gb9rsZ2gvPcDtk1PKaW+V6u+ncf6oXVwzQRAYPpYeL4jLHwWjh9yukK3CJzAX/S8nUS5801OV6KU8lYhYTYjfrkYbv4EGraFOX+1J3hnPmwv6vJhgTF42r71kPk1XPZH20dXKaXORgRaDrTLvnW2K/fq9yD9DWjex/bzbzPM54ZUD4wj/O9ehNDakHan05UopXxNow5wzSvwyCY75/Xh3fDhbXaI5vlPw9H9Tld43vw/8At32wnKu90OkTFOV6OU8lW1G9jrd8ZlwI1TbXPPt0/Cc+3gozth9zKvH7fH/5t0loy3P896jXW6EqWUPwgKhouG2OVAJqyYbMflX/+R/TXQfYzt1x8W6XSlp/DvI/zig7Z/bYfRULep09UopfxNbEtXt86NcNVzdoC2GQ/As21h9mNwcIfTFf4P/w785a9BebEOkqaUqlnhUZB2h+3dc/ssewHX0gl23J4pN8GOhV7R3OO/TTplxbD8VWh9pW1rU0qpmiYCSZfY5Uiu7dWT/oadSjW+A/T8pR3XJyTckfL89wg/4z0oLtCje6WUM+o0sV3BH94AV78IVRX2Yq7n2sG8f0JRnsdL8svAr6oox3z3IjTtDom9nC5HKRXIQmtBt9tg7BK45b/QpCvM+4cN/v/eZ/v5e4jfBf7h4nKefeFppHC3Pbr30QGQlFJ+RgRaDICfT7Nj9He9FTZ8AhP7wJtXweZZNT4rl98Ffp2IYK4r+ZgsEihoOtDpcpRS6lSxrWDYv23vnkF/hYNZMPVGeLkbLHu1xiZn8bvAl7IiYpu2YmLF1TzzdabT5Sil1JnVqm8v5npwjR22PbIBfPFb27unvMTtm/O/XjoRdYi67QOiZ27kjcU7uKl7Ih2a1nW6KqWUOrPgUDtHR/trIXsF7F8HoRFu34zfHeF/78FBrWhQO4w/z1hPVZXz/V+VUuq8NLvY9umvAX4b+HUiQvntlW1YtbuQT1fvOfcfUEopP+e3gQ9wXdemdG5Wj398sZmjJeVOl6OUUo5yS+CLyJUiskVEMkXk0dO8Hi4iH7heXyYiSe7Y7rkEBQl/Hd6OgmOlvDRXT+AqpQJbtQNfRIKB8cAQIBW4UURST1rtTuCQMaYl8BzwVHW3e746NavH9d2a8caiHWTmFXlqs0op5XXccYTfHcg0xmQZY8qAqcDJs4SPAN5y3f8IGCjiuSuifnPlRdQKC+avn23AeMEARkop5QR3BH4CkH3C4xzXc6ddxxhTARwGGrhh2+clNiqchwe1ZuG2A3y10Xdmp1FKKXfyupO2IjJGRNJFJD0/P99t73tLr+a0jo/iiZkbKSmvdNv7KqWUr3BH4O8Bmp3wuKnrudOuIyIhQF2g4HRvZoyZZIxJM8akxcXFuaE8KzQ4iL8Mb0fOoeNMWpDltvdVSilf4Y7AXwG0EpFkEQkDbgBmnLTODOA21/3rgLnGgcb03i1iGdahMa/MyyTnULGnN6+UUo6qduC72uTvB2YDm4BpxpgNIvI3ERnuWu11oIGIZAKPAKd03fSUPwyzk6H8fdYmp0pQSilHuGUsHWPMLGDWSc89fsL9EmC0O7ZVXQn1ajG2f0ue/Xor32UeoHfLWKdLUkopj/C6k7aeMKZfCs1iavGXzzZQXlmz408rpZS3CMjAjwgN5k/DUtm6v4h3luxyuhyllPKIgAx8gMGp8fRrHcdz32zlQFGp0+UopVSNC9jAFxEevyqV42WV/OvLLU6Xo5RSNS5gAx+gZcMo7uiTzLSV2azJLnS6HKWUqlEBHfgAD1zWktiocB6fsUEnSlFK+bWAD/zoiFB+P6QNa7IL+WhVjtPlKKVUjQn4wAcY2SWBron1ePrLzRzRiVKUUn5KAx97AvdvI9pzoKiMyQt3OF2OUkrVCA18l/YJdRmcGs/bS3ZSXFbhdDlKKeV2GvgnuPfSFhQWlzN1efa5V1ZKKR+jgX+Cbs3r0z05hskLs3TIBaWU39HAP8kvL21B7uESZmTkOl2KUkq5lQb+SfpfFEebRtFMnL9d++UrpfyKBv5JRIR7L23Btrwi5m7Oc7ocpZRyGw3807iqY2MS6tVi4vztTpeilFJuo4F/GiHBQYzpl0L6rkOs2HnQ6XKUUsotNPDP4Pq0ZsTUDmPiPD3KV0r5Bw38M6gVFsxtvZKYszmPLfuOOl2OUkpVmwb+WdzaqzmRYcG8qm35Sik/UK3AF5EYEflaRLa5buufYb1KEclwLTOqs01Pql87jBsuTmTGmlxyDhU7XY5SSlVLdY/wHwXmGGNaAXNcj0/nuDGms2sZXs1tetRdfZMBdFA1pZTPq27gjwDect1/C7immu/ndZrUq8WIzgl8sCKbQ8fKnC5HKaUuWHUDP94Ys9d1fx8Qf4b1IkQkXUSWisg1Z3tDERnjWjc9Pz+/muW5x72XpnC8vJK3lux0uhSllLpg5wx8EflGRNafZhlx4nrGGAOcaSyC5saYNOAm4HkRaXGm7RljJhlj0owxaXFxcT/l71JjWsVHM6htPG9+p0MnK6V81zkD3xgzyBjT/jTLdGC/iDQGcN2ediwCY8we120WMA/o4ra/gYf8sn8KhcXlfLBCh05WStWskvLKGnnf6jbpzABuc92/DZh+8goiUl9Ewl33Y4FLgI3V3K7HdWseQ/ekGCYv3KFDJyul3M4Yw3fbD3DXWysY+cp32EYT96pu4P8TGCwi24BBrseISJqITHat0xZIF5E1wLfAP40xPhf4APf2T2FP4XE+W6NDJyul3KO0opKPVuYw7MVF3PTaMlbtLmRw24aU1cCBpdTEXsRd0tLSTHp6utNl/MAYw5XPL8Rg+PLBfgQFidMlKaV8VEFRKe8t2807S3eRf7SUVg2juLNPMtd0SSAiNPiC31dEVrrOmZ4i5ILfNQCJCPf2T+HhD9bw7ZY8BrY9U6ckpZQ6va37j/LGoh18unoPpRVVXNo6jjtHJ9O3VSwiNXsQqYH/E13VsQnPzN7KxPnbNfCVUuelqsqwYFs+ry/awcJtBwgPCeLark25s08SLRtGe6wODfyfKDQ4iLv7JvOXzzaSvvMgaUkxTpeklPJSx8sq+WR1Dv9ZvJPMvCIaRofzmysu4sbuicTUDvN4PRr4F+D6i5vxwpxtTJy/ncka+Eqpk+wuKOa95buYtiKbQ8XltE+ow3M/68SwDk0IC3FuzEoN/AsQGRbC7b2Tee6brWzdf5TW8Z77SaaU8k6VVYa5m/N4d+kuFmzLJ0iEQW0bcsclyXRPjqnx9vnzoYF/gW7t1ZyJ87czcf52nr2+s9PlKKUckne0hA+WZzNl+W5yD5cQXyeccZe14sbuiTSqG+F0ef9DA/8C1a8dxg3dm/HOkl386vKLSKhXy+mSlFIeYoxhSVYB7y3dzewN+6ioMvRpGcvjV6cysG08ocHeOdWIBn413NU3hXeW7GLywiz+fHU7p8tRStWww8XlfLQqh/eW7SIr/xj1IkP5xSVJ3NSjOcmxtZ0u75w08KshoV4thnduwtTl2Yy7rBX1HTjrrpSqeWtzCnlnyS4+W5tLSXkVXRLr8e/RnRjWsXG1LpLyNA38arr30hZ8smoPb363k4cHt3a6HKWUm5RWVPL52r28tWQXa7ILiQwLZmSXptzcM5F2Teo6Xd4F0cCvptbx0QxOtUMn390vhahw/UiV8mV7Dx/nvaW7mbJ8NwXHykiJq81fh7djZNcE6kSEOl1etWg6ucHY/i34euN+pizbzd39UpwuRyn1ExljWL7jIG8t2cnsDfupMoaBbeK5rXdz+rSs+SEPPEUD3w26JNbnkpYNeG1hFrf2bk54iO+06SkVyIrLKpiekctb3+1k876j1K0Vyl19krm5Z3OaxUQ6XZ7baeC7ydj+Lfn55GV8vHIPN/VIdLocpdRZ7C4o5u0lO5mWns2RkgraNq7DU6M6MLxTArXC/PeATQPfTXq3aECnZvV4dcF2rk9rSoiX9sNVKlAZY1i47QBvfreTb7fkESTCle0bcXvvJNKa1/ebZpuz0cB3ExFhbP8W3PPOSj5ft5cRnROcLkkphZ0ucHrGHiYv3MG2vCJio8J4YEBLburR3OuuhK1pGvhuNLhtPK0aRjFh3naGd2oSEEcMSnmrgqJS3l26m3eW7uRAURltG9fh36M7cVWnxgF7nk0D342CgoRf9m/BI9PWMHezTpCilBMy84p4fdEOPlmVQ2lFFQMuiuPuvin0atEg4A/CNPDd7OpOTXj2662M/zaTy9o0DPgvmFKeYIxhyfYCJi/awdzNeY5NMOLtNPDdLDQ4iHv6pfCn6RtYtuMgPVMaOF2SUn6rrKKKmWtzmbxwBxv3HiE2KoyHB7Xm5p6JNIgKd7o8r1OtriQiMlpENohIlYicdtJc13pXisgWEckUkUers01fMDqtGbFR4Yz/NtPpUpTyS4eLy3llXiZ9n57LI9PWUF5ZxVOjOrDod5fx4KBWGvZnUN0j/PXAtcCrZ1pBRIKB8cBgIAdYISIzjDEbq7ltrxURGsydfZJ56svNrMs5TIemvjnuhlLeJvtgMa8v2sG09GyKyyrp2yqWp0Z15NLWcdp8eh6qFfjGmE3AuT7o7kCmMSbLte5UYATgt4EPcHPPRF6Zl8kr8zKZcHM3p8tRyqdlZBfy2oIsvli/l+AgYXinBO7qm0zbxnWcLs2neKINPwHIPuFxDtDjTCuLyBhgDEBiou9esRodEcptvZIYPy+TzLwiWjaMcrokpXxKVZVhzuY8XluQxfKdB4mOCOGeS1twe+8k4usEVv95dzln4IvIN0Cj07z0mDFmursLMsZMAiYBpKWlGXe/vyf94pIkJi/KYuL87TwzupPT5SjlE0rKK/lk1R4mL8wi68AxEurV4vGrUrn+4mY6Gm01nfPTM8YMquY29gDNTnjc1PWc32sQFc4NFyfy7tJdPDy4tU6DqNRZFBSV8s7SXbyzZBcFx8rokFCXl27swpD2jXSoEjfxxO5yBdBKRJKxQX8DcJMHtusVxvRL4d2lu3htQRZ/Ga7TICp1sqx8e6HURyvthVID2zTk7n4p9EiO0ROxblatwBeRkcBLQBzwuYhkGGOuEJEmwGRjzFBjTIWI3A/MBoKBN4wxG6pduY9oUq8WI7skMHXFbu6/rCWx2l1MKYwxpO86xGsLsvh6035Cg4MY1TWBO/sk64VSNUiM8d5m8rS0NJOenu50GdW2Pb+IQc/OZ2z/FvzmijZOl6OUYyqrDLM37GPSgiwysgupFxnKLT2bc2uvJOKi9WDIHURkpTHmtNdF6RkQD2gRF8WQ9o14e8ku7rm0hc9Pk6bUT3WstIIP07N5ffEOsg8ep3mDSJ4Y0Y5R3ZoSGaYx5Cn6SXvI2P4tmbVuH+8u3cXY/i2dLkcpj8g7UsJbS3by7tLdHD5eTrfm9XlsaCqDU+MJDtL2eU/TwPeQ9gl16dc6jjcW7eCOS5KJCA3M4VlVYNi6/yivLchiekYu5VVVXJHaiLv7JdOteYzTpQU0DXwPuq9/C342aSnT0rO5tVeS0+Uo5Vbfj1g5aWEW87bkExEaxA3dm3HHJckkxdZ2ujyFBr5HdU+OoVvz+rw6P4sbuycSqn2LlR+orDLMWreXifO3syH3CLFR4fxqcGtu7tmc+rXDnC5PnUAD34NEhPsGtOCON9OZkZHLqG5NnS5JqQtWWWWYuTaXl+ba4UNaxNXmqVEdGNE5QZssvZQGvocNuKghbRpFM2H+dkZ2SSBIT1wpH1NRWcWMNbm8PDeTrAPHuCg+mvE3dWVI+0b6ffZyGvgeJiKMHdCScVNW89XG/VzZ/nTDFCnlfSoqq/hvRi4vz93GzoJie+Dy865c0U6D3ldo4DtgaPtG/LtBJK/My+Ty1Hj9z6K8WnllFZ+u2sPL32ay+2Ax7ZrU4dVbujG4rX53fY0GvgNCgoN44LJW/PrDNby2MIt7Lm3hdElKnaKsooqPV+Uw/ttMcg4dp0NCXV67NY1BbXWuZl+lge+QUV0TmLt5P0/P3kK35vVJS9L+yco7lFZU8mF6DhPmbWdP4XE6Na3L30a0Y8BFGvS+TgPfISLCP0d1ZEPuIu5/fzWfj+uj83AqR2XmFTFzbS7TVmSTe7iELon1eHJke50+0I9o4DuoTkQo42/qyrUTvuPhaWt48/aLtU1UedTOA8eYuTaXmWv3snnfUUSgZ3ID/jmqI31bxWrQ+xkNfIe1T6jLn69O5bFP1zNh/nbuG6Dj7KialX2wmJlr9/L5ulzW7zkCQLfm9fnz1akM7dBYpw/0Yxr4XuCm7oksyzrIv7/aQtfE+vRq0cDpkpSfyS08zqx1e/ls7V7WZBcC0KlZPf44rC1DOzSmic7GFhA08L2AiPD3azuwfs9hxk1dzaxxfXVscFVt+4+UMGvdXmau3cvKXYcAaJ9Qh99d2YarOjamWUykwxUqT9PA9xJR4SG8cnNXRry8mIc+WM3bd/TQ4WPVT1ZYXMYX6/cxIyOXpTsKMAbaNIrm15e3ZljHJiTrIGYBTQPfi7RpVIcnRrTntx+v5cU523h4cGunS1I+oLisgm825TEjYw/zt+ZTXmlIia3NuMtacXWnxjploPqBBr6XGZ3WlKU7Cnhx7jYuToqhT6tYp0tSXqisooqF2/KZnpHL1xv3c7y8kkZ1Iri9dxIjOifQrkkd7WGjTqGB72VEhP+7pj3rcg7z4NTVzHqwr/aaUABUVRmW7TjIjDW5fLF+L4XF5dSLDGVk1wSGd2pC96QY7darzqpagS8io4G/AG2B7saY0844LiI7gaNAJVBxpgl2lRUZFsIrP+/K8JcX88CU1bx/Vw9CdOz8gGSMYW3OYT5bY/vK7ztSQmRYMJenxjO8cxP6tIwjLES/G+r8VPcIfz1wLfDqeaw7wBhzoJrbCxit4qN5cmR7Hpm2hue+2cpvrmjjdEnKQ0rKK/lu+wG+2ZTHnE372X+klNBgof9FDXmsU1sGtm2oE3+rC1Ktb40xZhOgbYU15NquTVm+4yDjv91OWlIMAy5q6HRJqobkHS1h7qY8vtmUx6LMfErKq6gdFky/1nEMbBvP4Lbx1I0MdbpM5eM8dZhggK9ExACvGmMmnWlFERkDjAFITEz0UHne6y/D25GRXcgjH2Tw+bi+eoGMnzDGsGnvUb7ZtJ85m/azJucwAAn1avGztGYMbBtPj5QYwkN05ijlPmKMOfsKIt8Ap5ul4zFjzHTXOvOAX5+lDT/BGLNHRBoCXwMPGGMWnKu4tLQ0k55+2rcMKFn5RVz90iLaNK7D1DE9dS5cH1VSXsnSrALmuJpqcg+XANC5WT0GtW3IwLbxtGkUrb+YVbWIyMoznSc95xG+MWZQdQswxuxx3eaJyKdAd+Ccga+slLgo/jmqIw9MWc2/Zm/hD0PbOl2SOouDx8rYnl9EVn4RWfnHXPePsftgMRVVhlqhwfRpFcuDg1oxoE1DGkZrLyzlGTXepCMitYEgY8xR1/3Lgb/V9Hb9zdWdmrBsRwGTFmTRrXl9rminUyM6qbyyil0FxT+EeVZ+kb1/4BiFxeU/rBcWHERSbCSt46O5sn0j0pLq07tFrE7yrRxR3W6ZI4GXgDjgcxHJMMZcISJNgMnGmKFAPPCp62dqCPC+MebLatYdkP44LJWM7ELueWclFyfV57puTRnWsQlR4dpjoyZVVFaxdX8RGdmFZGQfIiO7kO35x6is+rE5NC46nJTY2gzt0JiU2Nq0iIsiJa42TetH6hAZymucsw3fSdqGf6rC4jLeX76bj1bmkJV/jFqhwQxp34jr0prSM7mBXnjjBvsOl5CRfYjV2YVk7C5k3Z7DFJdVAlA/MpROzerRrkkdV6jbYK8ToT1olHc4Wxu+Br6PMsawanchH63MYeaaXI6WVtC0fi1GdW3Kdd2aBtRIiEWlFRw6VkZwkPywhJxw3z4OIkhO7UJcXFbBupzDrqP3QlbvLmTfEXsyNTRYSG1Sly7N6tHZtTRvEKknVZVX08D3c8fLKvlq4z4+WpnDoswDGAM9kmMYndaMIe0bUdtHm3wqqwwHikrZd7iEfUdK2H+k5JT7+4+UUlRacd7v+T87BBGKyyt/aJpJjIn8Idg7J9YjtXEdbWtXPkcDP4DsKTzOp6ty+GhlDjsLiokMC2ZYh8Zc160p3ZNjvPbo9EhJObPX72PelnxyCo+z/3AJ+UWl/9NODhASJDSMDie+bgSN6kQQXyeCRnUjiIkMw2CoqDJUVdnbStdSccLtj69VUVkFUeHBdE6sR6em9XROYeUXNPADkDGG9F2H+DA9m8/X7uVYWSWxUeH0SImhZ3IMPVIa0KphlKM7gJLySuZuzmNGRi5zt+RRVlFFk7oRpMRF0ej7QHfd2vvhxNYO1/MUSp2FBn6AKy6rYPaGfczfks+yHQfZ67rgJ6Z2GN2TYuiREkOP5Aa0aRRd42FaUVnF4u0FTM/Yw1cb9lNUWkFsVDhXdWzMiM5N6Nysntf+ClHKF1Trwivl+yLDQhjZpSkjuzTFGEP2weMs3VHAsqyDLNtRwJcb9gFQt1YoFyfF0NO1A0htUsctXQqrqgyrdh9iekYus9btpeBYGdERIQzt0IjhnRLo1aKBdl1UygM08AOMiJDYIJLEBpFcn9YMsO3+y7J+3AF8s2k/ANHhIaQl1ad5g9pEhYcQFRFCdEQIUeH2Njoi1D4fHkKdiFBqhwf/MIzz92PFzFiTy2drctlTeJzwkCAGpcYzvFMT+l8Up+PEKOVh2qSjTrHvcAnLdhSwbMdBVuw4SN7RUo6WlFN1Hl+VWqHBREeEEBwk7D1cQnCQ0LdVLCM6N2FwaiO9SEypGqZNOuonaVQ3ghGdExjROeGH54wxHC+vpKikgiMlFRSVVlBUUkFRabl97HruaEk5RaUVFJdVkpYUw9D2jbT3i1JeQgNfnRcRITIshMiwEBrWcboapdSF0HF2lVIqQGjgK6VUgNDAV0qpAKGBr5RSAUIDXymlAoQGvlJKBQgNfKWUChAa+EopFSC8emgFEckHdl3gH48FDrixHH+gn8mp9DM5lX4mp/Klz6S5MSbudC94deBXh4ikn2k8iUCln8mp9DM5lX4mp/KXz0SbdJRSKkBo4CulVIDw58Cf5HQBXkg/k1PpZ3Iq/UxO5Refid+24SullPpf/nyEr5RS6gQa+EopFSD8LvBF5EoR2SIimSLyqNP1eAsR2Ski60QkQ0QCct5IEXlDRPJEZP0Jz8WIyNciss11W9/JGj3tDJ/JX0Rkj+u7kiEiQ52s0dNEpJmIfCsiG0Vkg4g86Hre578rfhX4IhIMjAeGAKnAjSKS6mxVXmWAMaazP/QnvkBvAlee9NyjwBxjTCtgjutxIHmTUz8TgOdc35XOxphZHq7JaRXAr4wxqUBP4D5Xjvj8d8WvAh/oDmQaY7KMMWXAVGCEwzUpL2GMWQAcPOnpEcBbrvtvAdd4sianneEzCWjGmL3GmFWu+0eBTUACfvBd8bfATwCyT3ic43pOgQG+EpGVIjLG6WK8SLwxZq/r/j4g3slivMj9IrLW1eTjc00X7iIiSUAXYBl+8F3xt8BXZ9bHGNMV29x1n4j0c7ogb2NsH2XtpwwTgBZAZ2Av8G9Hq3GIiEQBHwMPGWOOnPiar35X/C3w9wDNTnjc1PVcwDPG7HHd5gGfYpu/FOwXkcYArts8h+txnDFmvzGm0hhTBbxGAH5XRCQUG/bvGWM+cT3t898Vfwv8FUArEUkWkTDgBmCGwzU5TkRqi0j09/eBy4H1Z/9TAWMGcJvr/m3AdAdr8Qrfh5rLSALsuyIiArwObDLGPHvCSz7/XfG7K21dXcieB4KBN4wxTzpbkfNEJAV7VA8QArwfiJ+LiEwB+mOHut0P/Bn4LzANSMQOxX29MSZgTmKe4TPpj23OMcBO4J4T2q79noj0ARYC64Aq19N/wLbj+/R3xe8CXyml1On5W5OOUkqpM9DAV0qpAKGBr5RSAUIDXymlAoQGvlJKBQgNfKWUChAa+EopFSD+HzSxyPGCnm7BAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dloss)\n",
    "plt.plot(gloss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
