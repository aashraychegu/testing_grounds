{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoRe_Dataloader_From_File_With_Random_From_Tensors import (\n",
    "    get_new_ttv_dataloaders,\n",
    "    get_new_test_train_validation_datasets,\n",
    ")\n",
    "from CoRe_Dataloader_ECSG import dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "import torchinfo\n",
    "import time\n",
    "import numpy as np\n",
    "import wandb\n",
    "import datetime\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as metrics\n",
    "import pandas as pd\n",
    "\n",
    "mae = metrics.MeanAbsoluteError()\n",
    "mse = metrics.MeanSquaredError()\n",
    "combined = metrics.MetricCollection(\n",
    "    [mae, mse, metrics.MeanAbsolutePercentageError(), metrics.MeanSquaredLogError()]\n",
    ")\n",
    "combined.to(\"cuda:0\")\n",
    "\n",
    "\n",
    "def get_df_from_rdict(rdict):\n",
    "    return pd.DataFrame(pd.Series(rdict).map(lambda x: x.item())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(model: torch.nn.Module, dl: DataLoader):\n",
    "    model.eval()\n",
    "    raw_output = []\n",
    "    parameters = []\n",
    "    with torch.no_grad():\n",
    "        for batch, (sg, params) in enumerate(dl):\n",
    "            sg = sg.to(\"cuda:0\").to(torch.float)\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "\n",
    "            params = params[:, 1:3].to(\"cuda:0\").to(torch.long)\n",
    "\n",
    "            raw_output.append(model(sg).detach().cpu())\n",
    "            parameters.append(params.cpu())\n",
    "            print(f\"{batch} / {len(dl)} \\n\", end=\"\\r\\r\")\n",
    "    model.train()\n",
    "    output = torch.vstack(raw_output)\n",
    "    parameters = torch.hstack(parameters)\n",
    "    return combined(output, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vit\n",
    "# import vit_pytorch\n",
    "from vit_pytorch import vit_for_small_dataset as vit_sd\n",
    "from vit_pytorch import vit as simple_vit\n",
    "from vit_pytorch.deepvit import DeepViT\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    # return simple_vit.ViT(image_size=400,\n",
    "    #                patch_size=20,\n",
    "    #                num_classes=19,\n",
    "    #                dim=int(1024/2),\n",
    "    #                depth=2,\n",
    "    #                heads=8,\n",
    "    #                mlp_dim=int(2048/2),\n",
    "    #                channels=1).to(\"cuda:0\")\n",
    "    # return vit_sd.ViT(image_size=400,\n",
    "    #                patch_size=20,\n",
    "    #                num_classes=19,\n",
    "    #                dim=1024,\n",
    "    #                depth=4,\n",
    "    #                heads=16,\n",
    "    #                mlp_dim=int(2048/2),\n",
    "    #                dropout = 0.1,\n",
    "    #                emb_dropout = 0,\n",
    "    #                channels=1).to(\"cuda:0\")\n",
    "    return DeepViT(\n",
    "        image_size=400,\n",
    "        patch_size=20,\n",
    "        num_classes=2,\n",
    "        dim=1024,\n",
    "        depth=4,\n",
    "        heads=16,\n",
    "        mlp_dim=int(2048 / 2),\n",
    "        dropout=0.1,\n",
    "        emb_dropout=0.1,\n",
    "        channels=1,\n",
    "    ).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "\n",
    "startlr = 3e-5\n",
    "optimizer = optim.AdamW(params=model.parameters(), lr=startlr)\n",
    "optimizer1 = optim.NAdam(params=model.parameters(), lr=startlr)\n",
    "step_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[1, 2, 3, 4], gamma=0.5\n",
    ")\n",
    "# at the end of 600 epochs, the learning rate is 0.000,002,62\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
    "scheduler_pl = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer, mode=\"max\", factor=0.7, patience=35, verbose=True\n",
    ")\n",
    "l1 = nn.L1Loss(reduction=\"sum\")\n",
    "l2 = nn.MSELoss(reduction=\"sum\")\n",
    "lossfn = lambda x, y: l1(x, y) + l2(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds(s):\n",
    "    return f\"{s//3600}H:{(s%3600)//60}M:{round(s%60,3)}S\"\n",
    "\n",
    "\n",
    "def ismult(n, div):\n",
    "    return bool(1 >> (n % div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(best_model, config, m1, m2, m1name=\"l1\", m2name=\"l2\"):\n",
    "    try:\n",
    "        torch.save(\n",
    "            best_model,\n",
    "            f\"./saved_models/ViT/WithNoise/best_model_state_dict_ViT_regressor_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__{m1name}_{m1}__{m2name}_{m2}.pt\",\n",
    "        )\n",
    "        print(\"\\nSAVING MODEL\")\n",
    "    except:\n",
    "        wandb.alert(level=\"warning\", title=\"OUT OF MEMORY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(config, train_dl, test_dl, adam=True, nadam=False):\n",
    "    min_mae, min_mse = float(\"inf\"), float(\"inf\")\n",
    "    ldl = len(train_dl)\n",
    "    results = pd.DataFrame()\n",
    "    best_model = OrderedDict()\n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        print(\"Pre-Evaluation Finished; Starting Training\")\n",
    "        etime = time.time()\n",
    "        for batch, (sg, params) in enumerate(train_dl):\n",
    "            stime = time.time()\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.to(\"cuda:0\").to(torch.float).view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "            params = params[:, 1:3].to(\"cuda:0\").to(torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sg)\n",
    "            loss = lossfn(outputs, params)\n",
    "            loss.backward()\n",
    "            optimizer.step() if adam else None\n",
    "            optimizer1.step() if nadam else None\n",
    "            #\n",
    "            torch.cuda.empty_cache()\n",
    "            #\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"loss\": loss.item(),\n",
    "                    \"batch_mae\": mae(outputs.to(\"cpu\"), params.to(\"cpu\")),\n",
    "                    \"batch_mse\": mse(outputs.to(\"cpu\"), params.to(\"cpu\")),\n",
    "                    \"lr\": scheduler.get_last_lr()[0],\n",
    "                    \"epoch\": epoch,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"{epoch:5}/{config.epochs:5} // {batch:5}/{ldl:5} | Loss: {loss.item():2.4},batch_mae:{mae(outputs.to('cpu'),params.to('cpu')):3.4}, lr:{scheduler.get_last_lr()[0]:1.5}, Time per Batch: {time.time()-stime:.3} seconds, Accumulated Time {to_seconds(round(time.time()-etime,3))}    \",\n",
    "                end=\"\\r\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "            if (batch - 1) % 5000 == 0:\n",
    "                epoch_results = calc_metrics(model, test_dl)\n",
    "                results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "                min_mae = min(results[\"MeanAbsoluteError\"])\n",
    "                min_mse = min(results[\"MeanSquaredError\"])\n",
    "                #\n",
    "                if epoch_results[\"MeanAbsoluteError\"] == min_mae:\n",
    "                    best_model = model.state_dict()\n",
    "                    save_model(\n",
    "                        best_model,\n",
    "                        config,\n",
    "                        list(epoch_results.values())[0],\n",
    "                        list(epoch_results.values())[1],\n",
    "                    )\n",
    "\n",
    "                wandb.log(\n",
    "                    {\"epoch\": epoch, \"lr\": scheduler.get_last_lr()[0]}\n",
    "                    | epoch_results\n",
    "                    | {\"MinimumMAE\": min_mae, \"MinimumMSE\": min_mse}\n",
    "                    | {\"EpochTime\": time.time() - etime}\n",
    "                )\n",
    "        #\n",
    "        epoch_results = calc_metrics(model, test_dl)\n",
    "        results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "        #\n",
    "        min_mae = min(results[\"MeanAbsoluteError\"])\n",
    "        min_mse = min(results[\"MeanSquaredError\"])\n",
    "        #\n",
    "        scheduler.step()\n",
    "        step_scheduler.step()\n",
    "        scheduler_pl.step(min_mae)\n",
    "\n",
    "        if epoch_results[\"MeanAbsoluteError\"] == min_mae:\n",
    "            best_model = model.state_dict()\n",
    "            save_model(\n",
    "                best_model,\n",
    "                config,\n",
    "                list(epoch_results.values())[0],\n",
    "                list(epoch_results.values())[1],\n",
    "            )\n",
    "        #\n",
    "\n",
    "        wandb.log(\n",
    "            {\"epoch\": epoch, \"lr\": scheduler.get_last_lr()[0]}\n",
    "            | epoch_results\n",
    "            | {\"MinimumMAE\": min_mae, \"MinimumMSE\": min_mse}\n",
    "            | {\"EpochTime\": time.time() - etime}\n",
    "        )\n",
    "\n",
    "    epoch_results = calc_metrics(model, test_dl)\n",
    "    results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "    return min_mae, min_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for training\n",
    "results = []\n",
    "trials = 1\n",
    "for i in range(trials):\n",
    "    wandb.init(\n",
    "        project=\"ViT-Regressor-With-Noise\",\n",
    "    )\n",
    "    config = wandb.config\n",
    "    config.run_name = wandb.run._run_id\n",
    "    config = wandb.config\n",
    "    config.epochs = 3\n",
    "    config.inx = 400\n",
    "    config.iny = 400\n",
    "    config.lr = startlr\n",
    "    config.trial = i + 1\n",
    "    config.total_trials = trials\n",
    "    config.best_model = OrderedDict()\n",
    "    config.start_time = datetime.datetime.now().isoformat()\n",
    "    config.savename = f\"best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__acc_max_acc__auc_auc.pt\"\n",
    "    train_dl, valid_dl, test_dl = get_new_ttv_dataloaders()\n",
    "    train_eval_model(wandb.config, train_dl, valid_dl, nadam=True)\n",
    "    results.append(calc_metrics(model, test_dl))  # type: ignore\n",
    "    if i != (trials - 1):\n",
    "        model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaldl = test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "raw_output = []\n",
    "parameters = []\n",
    "with torch.no_grad():\n",
    "    for batch, (sg, params) in enumerate(evaldl):\n",
    "        sg = sg.to(\"cuda:0\").to(torch.float)\n",
    "        sgsh = sg.shape\n",
    "        sg = sg.view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "\n",
    "        params = params[:, 1:3].to(\"cuda:0\").to(torch.long)\n",
    "\n",
    "        raw_output.append(model(sg).detach().cpu())\n",
    "        parameters.append(params.cpu())\n",
    "        print(batch, \"finished\")\n",
    "model.train()\n",
    "output = torch.vstack(raw_output)\n",
    "parameters = torch.hstack(parameters)\n",
    "output = torch.argmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = metrics.ROC(task=\"multiclass\", num_classes=19)\n",
    "fpr, tpr, thresholds = roc(output, parameters)\n",
    "len(fpr)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(fpr)):\n",
    "    plt.plot(fpr[i], tpr[i])\n",
    "plt.show()\n",
    "torch.save([fpr, tpr, thresholds], \"roc.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparisons = torch.eq(output, parameters).to(torch.float)\n",
    "torch.mean(comparisons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.ConfusionMatrix(num_classes=19, task=\"multiclass\")\n",
    "cfm = confusion_matrix(output, parameters).requires_grad_(False)\n",
    "np_cfm = cfm.cpu().numpy()\n",
    "num_elements = torch.unique(parameters, return_counts=True)[1]\n",
    "plt.matshow(np_cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_in_col = torch.sum(cfm, dim=1)\n",
    "divide_by = torch.tensor(np.vstack([total_in_col for i in range(19)]))\n",
    "rescaled_cfm = cfm / divide_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(nn.functional.sigmoid(rescaled_cfm * 40))\n",
    "plt.title(\"Rescaled Confusion Matrix\")\n",
    "plt.xlabel(\"True Class\")\n",
    "plt.xticks(np.arange(19))\n",
    "plt.ylabel(\"Predicted Class\")\n",
    "plt.yticks(np.arange(19))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rescaled_cfm)\n",
    "plt.title(\"True Confusion Matrix\")\n",
    "plt.xlabel(\"True Class\")\n",
    "plt.xticks(np.arange(19))\n",
    "plt.ylabel(\"Predicted Class\")\n",
    "plt.yticks(np.arange(19))\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = []\n",
    "for batch, (sg, params) in enumerate(evaldl):\n",
    "    all_params.append(params.cpu())\n",
    "    print(batch, len(evaldl))\n",
    "all_params = torch.vstack(all_params)\n",
    "all_params.shape\n",
    "results = torch.cat((all_params, torch.unsqueeze(comparisons, dim=1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results.numpy())\n",
    "df = df.rename(columns={0: \"EOS\", 1: \"M1\", 2: \"M2\", 3: \"SNR\", 4: \"correct\"})\n",
    "df[\"combined\"] = df[\"M1\"] + df[\"M2\"]\n",
    "df = df.drop(\"M1\", axis=1).drop(\"M2\", axis=1)\n",
    "df = df.rename(columns={\"combined\": \"Masses\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnc = pd.DataFrame([df[\"Masses\"], df[\"correct\"]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massescounts = pd.DataFrame(mnc[\"Masses\"].value_counts())\n",
    "massescounts = massescounts.rename(columns={\"Masses\": \"counts\"})\n",
    "massescounts = massescounts.rename_axis(\"masses\")\n",
    "massescounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mnc[\"Masses\"], bins=10)\n",
    "plt.title(\"Histogram of Masses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnc[\"ewma1\"] = mnc[\"correct\"].ewm(span=1000).mean()\n",
    "plt.plot(df[\"Masses\"], df[\"ewma1\"])\n",
    "plt.title(\"Exponentially Weighted Moving Average of Correctness\")\n",
    "plt.xlabel(\"Masses\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=[\"Masses\"], inplace=True)\n",
    "plt.plot(df[\"Masses\"], df[\"correct\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1 :] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = moving_average(df[\"correct\"].to_numpy(), 5)\n",
    "plt.plot(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_eos_filter = {}\n",
    "for i in df[\"EOS\"].unique():\n",
    "    # print(df[df[\"EOS\"] == i].mean()[\"correct\"])\n",
    "    by_eos_filter[i] = [df[df[\"EOS\"] == i].mean()[\"correct\"]]\n",
    "\n",
    "eosdf = pd.DataFrame(by_eos_filter)\n",
    "eosdf = eosdf.reindex(sorted(eosdf.columns), axis=1)\n",
    "remapper = {value: key for key, value in dataset.eosmap.items()}\n",
    "eosdf = eosdf.rename(columns=remapper)\n",
    "eosdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_snr_filter = {}\n",
    "for i in df[\"SNR\"].unique():\n",
    "    # print(df[df[\"EOS\"] == i].mean()[\"correct\"])\n",
    "    by_snr_filter[i] = [df[df[\"SNR\"] == i].mean()[\"correct\"]]\n",
    "\n",
    "snrdf = pd.DataFrame(by_snr_filter)\n",
    "snrdf = snrdf.reindex(sorted(snrdf.columns), axis=1)\n",
    "# remapper = {value: key for key, value in dataset.eosmap.items()}\n",
    "# eosdf.rename(columns=remapper)\n",
    "# eosdf\n",
    "snrdf.rename(columns={0.000: -1}).T\n",
    "snrdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"total_corrects_and_factors.pd.csv\")\n",
    "eosdf.to_csv(\"accuracy_by_eos.pd.csv\")\n",
    "snrdf.to_csv(\"accuracy_by_signal-to-noise-ratio.pd.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
