{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoRe_Dataloader_ECSG import load_pth_file,load_raw_from_pth_file\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import math\n",
    "import torchinfo\n",
    "import time\n",
    "import numpy as np\n",
    "import wandb\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sgram_ds, raw_param_ds = load_raw_from_pth_file()\n",
    "def get_new_test_train(p = 0.3):\n",
    "    assert p < 1\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(raw_sgram_ds.cpu().numpy(),raw_param_ds.cpu().numpy(),test_size = p)\n",
    "    train_dataset = TensorDataset(torch.tensor(xtrain),torch.tensor(ytrain))\n",
    "    if p == 0:\n",
    "        test_dataset = TensorDataset(torch.tensor(xtrain),torch.tensor(ytrain))\n",
    "    else:\n",
    "        test_dataset = TensorDataset(torch.tensor(xtest), torch.tensor(ytest))\n",
    "    return DataLoader(train_dataset,batch_size = 8, shuffle = True), DataLoader(test_dataset,batch_size = 64,shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as metrics\n",
    "acc = metrics.Accuracy(task=\"multiclass\",num_classes=19).to(\"cuda:0\")\n",
    "auroc = metrics.AUROC(task = \"multiclass\",num_classes=19).to(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_accuracy(model:torch.nn.Module,dl:DataLoader):\n",
    "    model.eval()\n",
    "    raw_output = []\n",
    "    parameters = []\n",
    "    with torch.no_grad():\n",
    "        for batch,(sg,params) in enumerate(dl):\n",
    "            sg = sg.to(\"cuda:0\").to(torch.float)\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "\n",
    "            params = params[:,0].to(\"cuda:0\").to(torch.long)\n",
    "            \n",
    "            raw_output.append(model(sg).detach())\n",
    "            parameters.append(params)\n",
    "            \n",
    "    model.train()\n",
    "    output = torch.vstack(raw_output)\n",
    "    parameters = torch.hstack(parameters)\n",
    "    accuracy = acc(output,parameters)\n",
    "    auc = auroc(output,parameters)\n",
    "    return accuracy,auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vit\n",
    "# import vit_pytorch\n",
    "from vit_pytorch import vit_for_small_dataset as vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    return vit.ViT(image_size=400,\n",
    "                   patch_size=20,\n",
    "                   num_classes=19,\n",
    "                   dim=1024,\n",
    "                   depth=2,\n",
    "                   heads=16,\n",
    "                   mlp_dim=int(2048/2),\n",
    "                   dropout = 0.1,\n",
    "                   emb_dropout = 0.1,\n",
    "                   channels=1).to(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3697, -0.1882, -0.3220,  0.2802,  0.6521, -0.9650, -0.1339, -0.7992,\n",
      "          0.4796,  0.1362,  0.6529,  0.8297,  0.6034,  0.7285,  0.7743,  0.2377,\n",
      "         -0.7944,  0.6078,  1.1449]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\storage.py:315: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "ViT                                                [1, 19]                   411,648\n",
       "├─SPT: 1-1                                         [1, 40, 1024]             --\n",
       "│    └─Sequential: 2-1                             [1, 40, 1024]             --\n",
       "│    │    └─Rearrange: 3-1                         [1, 40, 2000]             --\n",
       "│    │    └─LayerNorm: 3-2                         [1, 40, 2000]             4,000\n",
       "│    │    └─Linear: 3-3                            [1, 40, 1024]             2,049,024\n",
       "├─Dropout: 1-2                                     [1, 41, 1024]             --\n",
       "├─Transformer: 1-3                                 [1, 41, 1024]             --\n",
       "│    └─ModuleList: 2-2                             --                        --\n",
       "│    │    └─ModuleList: 3-4                        --                        6,298,625\n",
       "│    │    └─ModuleList: 3-5                        --                        6,298,625\n",
       "├─Identity: 1-4                                    [1, 1024]                 --\n",
       "├─Sequential: 1-5                                  [1, 19]                   --\n",
       "│    └─LayerNorm: 2-3                              [1, 1024]                 2,048\n",
       "│    └─Linear: 2-4                                 [1, 19]                   19,475\n",
       "====================================================================================================\n",
       "Total params: 15,083,445\n",
       "Trainable params: 15,083,445\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 14.67\n",
       "====================================================================================================\n",
       "Input size (MB): 0.06\n",
       "Forward/backward pass size (MB): 6.35\n",
       "Params size (MB): 58.69\n",
       "Estimated Total Size (MB): 65.10\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_model()\n",
    "\n",
    "\n",
    "img = torch.randn(1,1, 400,400).to(\"cuda:0\")\n",
    "\n",
    "preds = model(img)  # (1, 1000)\n",
    "print(preds)\n",
    "torchinfo.summary(model, input_size=(1,1, 400, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "startlr = 3e-5\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=startlr)\n",
    "optimizer1 = optim.NAdam(params=model.parameters(), lr=startlr)\n",
    "step_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[250], gamma=0.9)\n",
    "# at the end of 600 epochs, the learning rate is 0.000,002,62\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=2, gamma=0.99)\n",
    "scheduler_pl = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', factor=0.7, patience=35, verbose=True)\n",
    "lossfn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(config,train_dl,test_dl,adam = True,nadam = False):\n",
    "    tot_acc,auc = new_accuracy(model=model,dl = test_dl)\n",
    "    max_acc = -1\n",
    "    max_auc = -1\n",
    "    for epoch in range(1,config.epochs+1):\n",
    "        btime = time.time()\n",
    "        ldl = len(train_dl)\n",
    "        for batch,(sg,params) in enumerate(train_dl):\n",
    "            stime = time.time()\n",
    "            sg = sg.to(\"cuda:0\").to(torch.float)\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.view(sgsh[0],1,sgsh[1],sgsh[2])\n",
    "            params = params[:,0].to(\"cuda:0\").to(torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sg)\n",
    "            loss = lossfn(outputs,params)\n",
    "            loss.backward()\n",
    "            optimizer.step() if adam else None\n",
    "            optimizer1.step() if nadam else None\n",
    "            wandb.log({\"loss\":loss.item(),\"batch_accuracy\":acc(outputs,params),\"lr\":scheduler.get_last_lr()[0],\"epoch\":epoch})\n",
    "            print(f\"{epoch:5}/{config.epochs:5} // {batch:5}/{ldl:5} | Loss: {loss.item():2.4},batch_accuracy:{acc(outputs,params):3.4}, last_total_accuracy: {tot_acc}, Maximum Accuracy {max_acc} last AUROC {auc} Max AUC {max_auc} lr:{scheduler.get_last_lr()[0]:1.5},Time per Batch: {time.time()-stime:1.2} seconds     \",end = \"\\r\",flush=True)\n",
    "            torch.cuda.empty_cache()\n",
    "        tot_acc, auc = new_accuracy(model=model, dl=test_dl)\n",
    "        scheduler.step()\n",
    "        step_scheduler.step()\n",
    "        scheduler_pl.step(tot_acc)\n",
    "        if(tot_acc > max_acc):\n",
    "            max_acc = tot_acc\n",
    "            config.best_model = model.state_dict()\n",
    "            try:\n",
    "                torch.save(config.best_model, f\"./saved_models/cnns/best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__acc_{max_acc}__auc_{auc}.pt\")\n",
    "            except:  pass    \n",
    "            print(\"\\nSAVING MODEL\")\n",
    "        max_auc = max(max_auc,auc)\n",
    "        print(f\"\\nEpoch {epoch+1}/{config.epochs} finished. Total accuracy: {tot_acc:3.5} AUROC: {auc} Time per Epoch: {time.time()-btime:1.5}\")\n",
    "\n",
    "        wandb.log({\"epoch\":epoch,\"accuracy\":tot_acc,\"max_accuracy\":max_acc,\"lr\":scheduler.get_last_lr()[0],\"auroc\":auc})\n",
    "    return max_acc,max_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "trials = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xnjqty63) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▁▃▄▅▆▆▇▇▇▇▇▇▇█▇▇██▇█▇███▇▇▇█████</td></tr><tr><td>auroc</td><td>▁▁▅▇▇▇█████████████████████▇█████</td></tr><tr><td>batch_accuracy</td><td>▁▃▃▂▅▅▅█▅▇▆▇▆▆▇▇▇▅▇▇▆██▇████████▆▇▇███▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆█▅▄▆▃▂▄▂▃▂▃▃▂▃▂▄▂▁▂▁▂▂▁▁▁▁▁▁▁▁▄▁▂▁▁▁▂▁</td></tr><tr><td>lr</td><td>█████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr><tr><td>max_accuracy</td><td>▁▁▃▄▅▆▆▇▇▇▇▇▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.83966</td></tr><tr><td>auroc</td><td>0.75977</td></tr><tr><td>batch_accuracy</td><td>1.0</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>loss</td><td>0.00637</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>max_accuracy</td><td>0.85654</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-voice-2</strong> at: <a href=\"https://wandb.ai/alabs/simple_vision_transformer_forsmalldatasets_validation_test/runs/xnjqty63\" target=\"_blank\">https://wandb.ai/alabs/simple_vision_transformer_forsmalldatasets_validation_test/runs/xnjqty63</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230308_185552-xnjqty63\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xnjqty63). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c65752ebd44e5c8a65e65659fb7ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\aashr\\Desktop\\research\\testing_grounds\\wandb\\run-20230308_191221-o9lxaevt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/alabs/simple_vision_transformer_forsmalldatasets_validation_test/runs/o9lxaevt\" target=\"_blank\">zesty-water-3</a></strong> to <a href=\"https://wandb.ai/alabs/simple_vision_transformer_forsmalldatasets_validation_test\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/alabs/simple_vision_transformer_forsmalldatasets_validation_test\" target=\"_blank\">https://wandb.ai/alabs/simple_vision_transformer_forsmalldatasets_validation_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/alabs/simple_vision_transformer_forsmalldatasets_validation_test/runs/o9lxaevt\" target=\"_blank\">https://wandb.ai/alabs/simple_vision_transformer_forsmalldatasets_validation_test/runs/o9lxaevt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(trials):\n",
    "    wandb.init(project=\"simple_vision_transformer_forsmalldatasets_validation_test\")\n",
    "    config = wandb.config\n",
    "    config.run_name = wandb.run._run_id\n",
    "    config = wandb.config\n",
    "    config.epochs = 500\n",
    "    config.inx = 400\n",
    "    config.iny = 400\n",
    "    config.lr = startlr     \n",
    "    config.trial = i+1\n",
    "    config.total_trials = trials\n",
    "    config.best_model = OrderedDict()\n",
    "    config.start_time = datetime.datetime.now().isoformat()\n",
    "    config.savename = f\"best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__acc_max_acc__auc_auc.pt\"\n",
    "    train_dl, test_dl = get_new_test_train(.05)\n",
    "    results.append(train_eval_model(wandb.config,train_dl,test_dl,nadam=True))\n",
    "    model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in results:\n",
    "    a.append([i[0].cpu().item(),i[1].cpu().item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(a)\n",
    "average_accuracy = np.average(results[:,0])\n",
    "average_auroc = np.average(results[:,1])\n",
    "print(average_accuracy,average_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(config.best_model,\n",
    "           f\"./saved_models/ViT/best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}_BEST_MODEL.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
