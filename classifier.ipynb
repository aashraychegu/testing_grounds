{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CoRe_Dataloader_ECSG import load_pth_file\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import math\n",
    "import torchinfo\n",
    "import time\n",
    "import numpy as np\n",
    "import wandb\n",
    "import datetime\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as metrics\n",
    "import pandas as pd\n",
    "acc = metrics.Accuracy(task=\"multiclass\", num_classes=19)\n",
    "combined = metrics.MetricCollection([\n",
    "    acc,\n",
    "    metrics.AUROC(task=\"multiclass\", num_classes=19),\n",
    "    metrics.Precision(task=\"multiclass\", num_classes=19),\n",
    "    metrics.Recall(task=\"multiclass\", num_classes=19),\n",
    "    metrics.F1Score(task=\"multiclass\", num_classes=19),\n",
    "    metrics.FBetaScore(task=\"multiclass\", num_classes=19)\n",
    "]).to(\"cuda:0\")\n",
    "\n",
    "\n",
    "def get_df_from_rdict(rdict):\n",
    "    return pd.DataFrame(pd.Series(rdict).map(lambda x: x.item())).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(model:torch.nn.Module,dl:DataLoader):\n",
    "    model.eval()\n",
    "    raw_output = []\n",
    "    parameters = []\n",
    "    with torch.no_grad():\n",
    "        for batch,(sg,params) in enumerate(dl):\n",
    "            sg = sg.to(\"cuda:0\").to(torch.float)\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.view(sgsh[0], 1, sgsh[1], sgsh[2])\n",
    "\n",
    "            params = params[:,0].to(\"cuda:0\").to(torch.long)\n",
    "            \n",
    "            raw_output.append(model(sg).detach())\n",
    "            parameters.append(params)\n",
    "            print(batch)\n",
    "    model.train()\n",
    "    output = torch.vstack(raw_output)\n",
    "    parameters = torch.hstack(parameters)\n",
    "    return combined(output,parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vit\n",
    "# import vit_pytorch\n",
    "from vit_pytorch import vit_for_small_dataset as vit_sd\n",
    "from vit_pytorch import vit as simple_vit\n",
    "from vit_pytorch.deepvit import DeepViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    # return simple_vit.ViT(image_size=400,\n",
    "    #                patch_size=20,\n",
    "    #                num_classes=19,\n",
    "    #                dim=int(1024/2),\n",
    "    #                depth=2,\n",
    "    #                heads=8,\n",
    "    #                mlp_dim=int(2048/2),\n",
    "    #                channels=1).to(\"cuda:0\")\n",
    "    # return vit_sd.ViT(image_size=400,\n",
    "    #                patch_size=20,\n",
    "    #                num_classes=19,\n",
    "    #                dim=1024,\n",
    "    #                depth=4,\n",
    "    #                heads=16,\n",
    "    #                mlp_dim=int(2048/2),\n",
    "    #                dropout = 0.1,\n",
    "    #                emb_dropout = 0,\n",
    "    #                channels=1).to(\"cuda:0\")\n",
    "    return DeepViT(image_size=400,\n",
    "                    patch_size=20,\n",
    "                    num_classes=19,\n",
    "                    dim=1024,\n",
    "                    depth=6,\n",
    "                    heads=12,\n",
    "                    mlp_dim=int(2048/2),\n",
    "                    dropout=0.1,\n",
    "                    emb_dropout=0,\n",
    "                    channels=1).to(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2062, -0.2337, -0.2809,  0.0452, -0.0513, -0.9020, -0.5145, -0.2299,\n",
      "         -0.2407,  0.1954,  0.2276, -0.5239,  0.2942,  0.1372,  0.5527,  0.2587,\n",
      "         -0.4038, -0.0835,  0.1712]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aashr\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\storage.py:315: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "DeepViT                                                      [1, 19]                   411,648\n",
       "├─Sequential: 1-1                                            [1, 40, 1024]             --\n",
       "│    └─Rearrange: 2-1                                        [1, 40, 400]              --\n",
       "│    └─LayerNorm: 2-2                                        [1, 40, 400]              800\n",
       "│    └─Linear: 2-3                                           [1, 40, 1024]             410,624\n",
       "│    └─LayerNorm: 2-4                                        [1, 40, 1024]             2,048\n",
       "├─Dropout: 1-2                                               [1, 41, 1024]             --\n",
       "├─Transformer: 1-3                                           [1, 41, 1024]             --\n",
       "│    └─ModuleList: 2-5                                       --                        --\n",
       "│    │    └─ModuleList: 3-1                                  --                        5,250,216\n",
       "│    │    └─ModuleList: 3-2                                  --                        5,250,216\n",
       "│    │    └─ModuleList: 3-3                                  --                        5,250,216\n",
       "│    │    └─ModuleList: 3-4                                  --                        5,250,216\n",
       "│    │    └─ModuleList: 3-5                                  --                        5,250,216\n",
       "│    │    └─ModuleList: 3-6                                  --                        5,250,216\n",
       "├─Identity: 1-4                                              [1, 1024]                 --\n",
       "├─Sequential: 1-5                                            [1, 19]                   --\n",
       "│    └─LayerNorm: 2-6                                        [1, 1024]                 2,048\n",
       "│    └─Linear: 2-7                                           [1, 19]                   19,475\n",
       "==============================================================================================================\n",
       "Total params: 32,347,939\n",
       "Trainable params: 32,347,939\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 31.94\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.06\n",
       "Forward/backward pass size (MB): 16.37\n",
       "Params size (MB): 127.74\n",
       "Estimated Total Size (MB): 144.18\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_model()\n",
    "img = torch.randn(1,1, 400,400).to(\"cuda:0\")\n",
    "preds = model(img)  # (1, 1000)\n",
    "print(preds)\n",
    "torchinfo.summary(model, input_size=(1,1, 400, 40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "startlr = 3e-5\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=startlr)\n",
    "optimizer1 = optim.NAdam(params=model.parameters(), lr=startlr)\n",
    "step_scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, milestones=[1,2,3,4], gamma=0.9)\n",
    "# at the end of 600 epochs, the learning rate is 0.000,002,62\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=1, gamma=0.9)\n",
    "scheduler_pl = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='max', factor=0.7, patience=35, verbose=True)\n",
    "lossfn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19866 377454\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m train_dl, test_dl \u001b[39m=\u001b[39m get_new_test_train_dataloaders(\u001b[39m.05\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m calc_metrics(model,test_dl)\n",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m, in \u001b[0;36mcalc_metrics\u001b[1;34m(model, dl)\u001b[0m\n\u001b[0;32m      4\u001b[0m parameters \u001b[39m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mfor\u001b[39;00m batch,(sg,params) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dl):\n\u001b[0;32m      7\u001b[0m         sg \u001b[39m=\u001b[39m sg\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m      8\u001b[0m         sgsh \u001b[39m=\u001b[39m sg\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\aashr\\Desktop\\research\\testing_grounds\\CoRe_Dataloader_From_File_With_Random_From_Tensors.py:60\u001b[0m, in \u001b[0;36mCoRe_Dataset_RNoise.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m---> 60\u001b[0m     sgindex, snr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex_map[index]\n\u001b[0;32m     61\u001b[0m     spectrogram \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspectrograms[sgindex]\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m     62\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[sgindex]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_dl, test_dl, valid_dl  = load_pth_file()\n",
    "calc_metrics(model,test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(config, train_dl, test_dl, adam=True, nadam=False):\n",
    "    ldl = len(train_dl)\n",
    "    pre_acc,max_acc,max_auc = 0,0,0\n",
    "    results = pd.DataFrame()\n",
    "    for epoch in range(1,config.epochs+1):\n",
    "        \n",
    "        print(\"preeval finished\")\n",
    "        etime = time.time()\n",
    "        for batch,(sg,params) in enumerate(train_dl):\n",
    "            stime = time.time()\n",
    "            sgsh = sg.shape\n",
    "            sg = sg.to(\"cuda:0\").to(torch.float).view(sgsh[0],1,sgsh[1],sgsh[2])\n",
    "            params = params[:,0].to(\"cuda:0\").to(torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sg)\n",
    "            loss = lossfn(outputs,params)\n",
    "            loss.backward()\n",
    "            optimizer.step() if adam else None\n",
    "            optimizer1.step() if nadam else None\n",
    "            #\n",
    "            torch.cuda.empty_cache()\n",
    "            #\n",
    "            wandb.log({\"loss\":loss.item(),\"batch_accuracy\":acc(outputs,params),\"lr\":scheduler.get_last_lr()[0],\"epoch\":epoch})\n",
    "            print(f\"{epoch:5}/{config.epochs:5} // {batch:5}/{ldl:5} | Loss: {loss.item():2.4},batch_accuracy:{acc(outputs,params):3.4}, lr:{scheduler.get_last_lr()[0]:1.5},Time per Batch: {time.time()-stime:1.2} seconds     \",end = \"\\r\",flush=True)\n",
    "        #\n",
    "        scheduler.step()\n",
    "        step_scheduler.step()\n",
    "        scheduler_pl.step(max_acc)\n",
    "        #\n",
    "        epoch_results = calc_metrics(model, test_dl)\n",
    "        results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "        max_acc = max(results[\"MulticlassAccuracy\"])\n",
    "        max_auc = max(results[\"MulticlassAUROC\"])\n",
    "        #\n",
    "        if pre_acc < max_acc:\n",
    "            try:\n",
    "                torch.save(config.best_model, f\"./saved_models/ViT/best_model_state_dict_ViT_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__acc_{max_acc}__auc_{max_auc}.pt\")\n",
    "                print(\"\\nSAVING MODEL\")\n",
    "            except:\n",
    "                wandb.alert(level=\"warning\",title=\"OUT OF MEMORY\")\n",
    "\n",
    "        wandb.log({\"epoch\":epoch,\"lr\":scheduler.get_last_lr()[0]} | epoch_results | {\"MaximumMulticlassAccuracy\": max_acc, \"MaximumMulticlassAUROC\":max_auc} | {\"EpochTime\": time.time()-etime})\n",
    "\n",
    "    epoch_results = calc_metrics(model, test_dl)\n",
    "    results = pd.concat([results, get_df_from_rdict(epoch_results)])\n",
    "    return max_acc,max_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "trials = 5\n",
    "for i in range(trials):\n",
    "    wandb.init(project=\"simple_vision_transformer_with_noise_classifier\")\n",
    "    config = wandb.config\n",
    "    config.run_name = wandb.run._run_id\n",
    "    config = wandb.config\n",
    "    config.epochs = 500\n",
    "    config.inx = 400\n",
    "    config.iny = 400\n",
    "    config.lr = startlr     \n",
    "    config.trial = i+1\n",
    "    config.total_trials = trials\n",
    "    config.best_model = OrderedDict()\n",
    "    config.start_time = datetime.datetime.now().isoformat()\n",
    "    config.savename = f\"best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}__acc_max_acc__auc_auc.pt\"\n",
    "    train_dl, test_dl, valid_dl  = load_pth_file()\n",
    "    results.append(train_eval_model(wandb.config,train_dl,test_dl,nadam=True))\n",
    "    model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in results:\n",
    "    a.append([i[0].cpu().item(),i[1].cpu().item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(a)\n",
    "average_accuracy = np.average(results[:,0])\n",
    "average_auroc = np.average(results[:,1])\n",
    "print(average_accuracy,average_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(config.best_model,\n",
    "           f\"./saved_models/ViT/best_model_state_dict_at_for{config.run_name}_stime_{config.start_time.replace(':', '-')}_BEST_MODEL.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
